Puesto,contenido,url,fuente,fecha_captura
Data Manager,"Descripción de la oferta de empleo  ´Te imaginas participando en la transformación de las principales organizaciones nacionales e internacionales?  En Deloitte estamos comprometidos con generar un impacto en la sociedad, en nuestros clientes y en ti.  Funciones Principales - Más de 6 años de experiencia como Data Engineer, trabajando con grandes volúmenes de datos en entornos cloud y on-premise. - Liderazgo técnico en proyectos y coordinación de equipos multidisciplinarios. - Dominio avanzado en procesamiento distribuido con PySpark, SparkSQL y Python. - Diseño y optimización de consultas SQL y NoSQL. - Sólida comprensión de modelado de datos y arquitectura de bases de datos. - Capacidad para definir estrategias de datos y colaborar con arquitectos en la construcción de soluciones escalables y seguras. - Inglés avanzado para comunicación con equipos y clientes internacionales en posibles colaboraciones en proyectos globales.  Stack Tecnológico - Plataformas y servicios de datos: Snowflake, Databricks, Cloudera Data Services. - Servicios cloud: Azure, AWS, GCP (incluyendo Fabric, Glue, Redshift, Dataproc, BigQuery). - Herramientas de integración y despliegue: conocimientos en DevOps (Azure Devops, Jenkins, Gitlab...), automatización y buenas prácticas de seguridad en la nube. - Deseable y valorable conocimientos en las siguientes tecnologías: DBT, PowerBI, Streamlit. - Certificaciones: se valoran certificaciones en las principales tecnologías mencionadas (Snowflake, Databricks, Azure, AWS, GCP).  Formación - Titulación en Ingeniería Informática, Telecomunicaciones o áreas afines.  Nivel de Inglés - Alto (B2 o superior).  ¿Cómo es trabajar en Deloitte? Proyectos de alto impacto donde tendrás un largo recorrido y aprendizaje  Un día a día híbrido-flexible: tendrás horario flexible y un buen equilibrio entre el teletrabajo y el trabajo en equipo en nuestras oficinas o las de nuestros clientes  Buen ambiente dentro y fuera de la oficina: disfrutarás de varios teambuildings al año, actividades culturales y deportivas... ¡y mucho más!  Bienestar integral: cuídate con nuestro programa de salud física, mental y financiera... ¡y con equipo médico en las oficinas!  Impacto social: Podrás apuntarte a una gran cantidad de voluntariados de alcance nacional e internacional y a proyectos pro-bono con los que poner tu tiempo y talento al servicio de quienes más lo necesitan  Cultura del feedback y aprendizaje continuo: crecerás en un entorno inclusivo donde la igualdad de oportunidades y tu plan personalizado de formación impulsarán tu desarrollo. ¿Ya te visualizas en la Deloitte University de París?  Beneficios exclusivos por ser parte de Deloitte: podrás disfrutar de un gran catálogo de beneficios y de un completo plan de retribución flexible  Si te gusta lo que lees, estos son tus próximos pasos: - Aplica a la oferta haciendo clic en ´Enviar candidatura ahora´ y completa tu perfil - Si encajas en el puesto, nuestro equipo de talento te contactará para conocerte mejor  ¡Comienza el proceso! Te iremos guiando por las diferentes fases hasta tu incorporación.",https://www.tecnoempleo.com/data-manager-deloitte/pyspark-sparksql/rf-d24f1b2252c85365d64e,Tecnoempleo,2026-01-20
Data Analyst & Reporting Services,"Descripción de la oferta de empleo  ¿Tienes experiencia trabajando con datos y herramientas de análisis? ¿Te apasiona transformar información en conocimiento útil para la toma de decisiones? ¡En Randstad estamos buscando personas como tú!  nuestro cliente  Multinacional tecnológica líder a nivel mundial, con más de 80 años de trayectoria. Con una plantilla de miles de profesionales en más de 170 países. Nuestro cliente se distingue por su compromiso con la innovación, la sostenibilidad y el bienestar de sus empleados, ofreciendo beneficios altamente valorados y un entorno de trabajo inclusivo y colaborativo.  tus funciones  - Proporcionar informes mensuales de la cantidad de productos reutilizados a los ejecutivos de la compañía. Este número se utilizará para calcular resultados de sostenibilidad. - Trabajar con diferentes organizaciones para recuperar los datos, asegurarse de que sean correctos, combinarlos y calcular lo que pesan, automatizar el proceso tanto como sea posible, ya que hoy en día es manual, ayudar en la recopilación de datos. - Asistencia a meetings. - Análisis y recopilación de datos de proveedores.  requisitos del puesto - Formación: Grado - Idiomas: Inglés: C1 - Conocimientos: data analysis, Data Analyst Developer , control y gestión de reportes, Analysis data - Experiencia: 2 años  - Familiarizado/a con métricas de desempeño ESG (Ambientales, Sociales y de Gobernanza) - Experiencia en visualización de datos y automatización de procesos - Experiencia en comunicación con terceros externos (proveedores) para resolver dudas o completar vacíos de información (data gaps) - Buscamos a una persona con capacidad organizativa, proactiva, ágil, rigurosa y con ganas - Nivel de inglés advanced o proficiency (hablado y escrito) - Excel avanzado y experiencia en análisis de datos, acostumbrada a trabajar con datos/ números - Power BI nivel alto y de otras herramientas de informes y de automatización de procesos - Se valorarán conocimientos de Pyton  tus beneficios  - CONTRATO ESTABLE - HORARIO FLEXIBLE: Inicio de 8-10h, salida de 17-19h - SALARIO: 28.000 euros brutos anuales (en 12 pagas) - Posición híbrida (2-3 días de teletrabajo)  ¿por qué con randstad?  Randstad, tu mejor elección  Trabajar con nosotros es poder elegir entre una amplísima variedad de ofertas de los mejores empleos y en las mejores empresas. Es elegir que te contraten con todas las garantías legales. Es poder firmar el contrato en remoto con todas las garantías y acceder a tu documentación de una manera rápida y sencilla, gracias a nuestra innovadora tecnología.  Siempre cerca de ti, realizamos un seguimiento personalizado de tu incorporación para facilitarte la adaptación a tu nuevo puesto de trabajo. Y cómo queremos que sigas creciendo, contaremos contigo para futuras oportunidades de empleo.  Elige trabajar con Randstad y te ayudaremos a encontrar ese empleo que mejor se adapta a ti.  somos empleo sostenible  La ambición de Randstad es ser la compañía de talento más equitativa y especializada del mundo. Ayudamos a las personas y a las organizaciones a desarrollar su verdadero potencial, buscando oportunidades que impulsen la sostenibilidad económica y prioricen el bienestar de las personas y el planeta.  empleo inclusivo  Nuestra convicción de que todas las personas, independientemente de su procedencia, tienen las mismas oportunidades de éxito se demuestra en nuestros procesos, donde promovemos la equidad laboral a través equipos diversos e inclusivos.  compromiso NetZero  Reforzamos nuestro compromiso ambiental para lograr la neutralidad de carbono en 2050 a través de la iniciativa Science Based Targets (SBTi).",https://www.tecnoempleo.com/data-analyst-reporting-services-randstad-es/data/rf-2c86146012d0a3fcb54a,Tecnoempleo,2026-01-20
Senior Data Scientist Credit Modelling,"Descripción de la oferta de empleo  GROUP BNP PARIBAS  BNP Paribas Group is the top bank in the European Union and a major international banking establishment. It has close to 185,000 employees in 65 countries. In Spain we are more than 5,100 employees within 13 business lines.  RISK HUB  RISK is an integrated and independent control function of the BNP Paribas Group. It is the second line of defense on the risk management activities of the Group which are under its direct responsibilities, including credit and counterparty risk, market risk, funding and liquidity risk, interest rate and foreign exchange risks in the banking book, insurance risk, operational risk, and environmental and social risks.  RISK aims at being a partner of the businesses by contributing to their sustainable development, but also a gatekeeper to ensure risks taken remain compatible with the Group´s Risk Appetite and its strategy.  RISK Iberian Hub Madrid is a transversal platform servicing the RISK Function by covering added-value activities around credit risk, market risk, operational risk and data protection. Offering a wide range of services to RISK teams, from consulting to cyber security going through data analysis, modelling or artificial intelligence.  ABOUT THE JOB  Want to help shape the bank of tomorrow today?  How can the Bank leverage data to assess credit risk on its portfolio of existing and new clients  Risk assessment encompasses various elements: how likely is it that a client will not be able to comply with the contractual requirements of his loan? What will be the client´s outstanding balance in this situation? What loss is the bank expected to suffer if a client is no longer able to repay a loan?  As a member of the RISK Models team, you will join a team of experts whose goal is to answer these questions through the development of statistical or expert models.  By analysing historical data, working together with the business lines, IT department, the modelling experts at BNP Paribas group and taking into account the remarks of supervisor representatives, the team creates tools that help the bank calculate the capital requirements for its credit exposure, the risk component of the credit price or that contribute to the approval process of a new credit.  RESPONSIBILITIES  Your personal tasks will be:  • Designing and developing models for credit risk on the scope mainly of companies  • Finding, managing and using the most appropriate data sources for modelling purposes  • Working with expert colleagues and business representatives to examine the results and keep models grounded in reality  • Documenting each step of the development and informing decision makers by presenting them options and results  • Ensuring correct implementation of the tools (together with the IT department)  • Continuously assessing models by means of back-testing  • Answering specific, external requests regarding statistics related to credit risk assessment  • Following-up evolutions in the regulation and in credit risk modelling best-practices  • Potential expansion of responsibilities to encompass HR-related tasks, complementing existing operational duties.  REQUIREMENTS  - Studies  • Master degree or higher in Mathematics, Economy or Econometrics, Statistics or a similar background where analytics and figures prevail.  - Experience  • Work experience of at least 5 years in credit risk modelling (PD/LGD/LGDD/CCF).  - Languages  • You express yourself perfectly in English, in particular in the writing form. You ideally speak French fluently.  SKILLS  - Technical  • You have strong SAS programming skills.  • It is considered an asset if you have some experience with Big Data technologies, ratings & scorings use across the bank or credit products.  - Transversal & Behavioral  • You are able to manage long-term deadlines and plan your work accordingly. • You are creative, you pay attention to details, and you are able to work easily with both technical and business-oriented people.  BENEFITS  • Training programs, career plans and internal mobility opportunities, national and international thanks to our presence in different countries.  • Diversity and Inclusion Committee that ensures an inclusive work environment. In recent years, several employee communities have been created to organize diversity and inclusion awareness actions (PRIDE, We Generations and MixCity).  • Corporate volunteering program (1 Million Hours 2 Help) in which employees can dedicate time out of their working hours to volunteer activities.  • Flexible compensation plan.  • Hybrid telecommuting model (50%).  • 32 vacation days.  Diversity and inclusion commitment  BNPParibas Group in Spain is an equal opportunity employer and proud to provide equal employment opportunity to all job seekers. We are actively committed to ensuring that no individual is discriminated against on the grounds of age, disability, gender reassignment, marriage or civil partnership status, pregnancy and maternity/paternity, race, religion or belief, sex or sexual orientation. Equity and diversity are at the core of our recruitment policy because we believe that they foster creativity and efficiency, which in turn increase performance and productivity. We strive to reflect the society we live in, while keeping with the image of our clients.",https://www.tecnoempleo.com/senior-data-scientist-credit-modelling-bnp-paribas/data/rf-1a211708d29ec373c649,Tecnoempleo,2026-01-20
Data Engineer,"Descripción de la oferta de empleo  Role description  ¡Seguimos buscando talento...y nos encantaría que te unieras a nuestro equipo!  Para que nos conozcas algo mejor, UST es una multinacional norteamericana certificada como Top Employer y Great Place to Work con más de 35.000 empleados a nivel global y con presencia en más de 35 países. Somos líderes en servicios de tecnología digital y proporcionamos soluciones tecnológicas de gran alcance a grandes compañías.  Estamos en búsqueda de un Data Engineer para trabajar en un proyecto de uno de nuestros principales clientes del sector bancario  Modalidad: 100% remoto  Responsabilidades - Participación en las tareas del proyecto AVA-FVA, desempeñando funciones de Data Engineer en la definición y automatización de procesos desarrollados con tecnologías Big Data (Spark / Scala) dentro del área de Market Risk. - Participar en un equipo de trabajo enfocado a tareas comunes de Big Data.  Requisitos Obligatorios - Experiencia en proyectos de índole tecnológica. - Conocimiento avanzado de sentencias SQL. - Conocimiento técnico de Azure Databricks. - Conocimiento de Airflow como workflow/pipelines manager. - Conocimiento técnico de lenguajes de programación (Scala) y plataformas Spark y Hadoop. - Experiencia en diseño de ETL y modelos de datos. - Experiencia en la realización de pruebas y validación de datos. - Nivel de inglés B2/C1. - Conocimiento básico de Shell scripting.  Requisitos Deseables (No obligatorios) - Experiencia en el sector banca, especialmente en áreas relacionadas con Riesgos de Mercado. - Más de 2 años de experiencia en roles similares.  ¿Qué te ofrecemos?  23 días laborables de vacaciones y el 24 y 31 de diciembre.  Numerosos beneficios sociales (seguro médico, ayuda al teletrabajo, seguro de vida y seguro de accidentes).  Programa de Retribución Flexible (tarjeta comida, cheques guardería, tarjeta transporte, clases de inglés online, seguro médico para tu familia...).  Acceso gratuito a varias plataformas de formación.  Estabilidad y carrera profesional.  Tenemos implantado un plan de compensación de referencias internas.  Posibilidad de elección de percibir tu salario en 12 o 14 pagas.  Medidas de conciliación (horario flexible, teletrabajo, asesoramiento de especialistas (psicólogo, nutricionista, entrenador personal), jornada intensiva los viernes y en verano según proyecto).  Plataforma UST Club descuentos y descuentos en gimnasios.  Si quieres conocer más, no dudes en inscribirte y nos pondremos en contacto contigo para ampliarte información de la posición ¡Te estamos esperando!  En UST nos comprometemos con la igualdad de oportunidades en nuestros procesos de selección y no realizamos ningún tipo de discriminación por razón de raza, género, discapacidad, edad, religión, orientación sexual o nacionalidad. Estamos comprometidos con la discapacidad y apostamos por la incorporación de personas con certificado de discapacidad.",https://www.tecnoempleo.com/data-engineer-ust/spark-scala/rf-65d318f3f2af539fbb48,Tecnoempleo,2026-01-20
Data Engineer / Data Processing,"Descripción de la oferta de empleo  En Arelance sabemos que las personas son el activo más importante dentro de una empresa y por tanto invertimos muchos esfuerzos en buscar los mejores profesionales para nuestros clientes, y en ofrecer a nuestros candidatos los mejores proyectos.  En este momento buscamos un/a Data Engineer para participar en la revisión, validación y reconciliación de datos provenientes tanto de soluciones de reporting automatizadas (UDP – Unified Data Platform) como de fuentes de reporting manuales (Excel). El objetivo principal del rol será identificar discrepancias, asegurar la calidad del dato y escalar inconsistencias, garantizando la fiabilidad y precisión de la información reportada, especialmente en datos de ingredientes y packaging.  ¿Qué buscamos en ti? - Experiencia en procesamiento y análisis de datos. - Capacidad para trabajar con grandes volúmenes de datos y múltiples fuentes. - Buen manejo de Excel (validaciones, comparativas, análisis). - Conocimientos en plataformas de datos o reporting automatizado (UDP - Unified Data Platform). - Alta atención al detalle y enfoque en calidad del dato.  ¿Cuáles serán algunas de tus funciones? - Revisar y validar datos procedentes de plataformas de reporting automatizadas (UDP). - Analizar y contrastar información proveniente de fuentes manuales (Excel). - Identificar discrepancias e inconsistencias en los datos. - Escalar incidencias de calidad de datos a los equipos correspondientes. - Asegurar la fiabilidad, precisión y coherencia de los datos reportados. - Colaborar con equipos de datos y negocio para la resolución de problemas de reconciliación. - Documentar hallazgos, procesos y reglas de validación de datos.  ¿Qué ofrecemos en esta posición? - Contrato indefinido en Arelance - Modalidad de trabajo 100% remoto dentro de España - SBA a negociar según experiencia y valía. - Acceso a formación - Contratación indefinida o flexibilidad para contratación freelance - Jornada intensiva en verano y todos los viernes del año.   Si estás interesado/a en una oportunidad como ésta, ¡inscríbete! ¡Queremos conocerte!  ** Solo se valorarán candidaturas con residencia y permiso de trabajo vigente en España **",https://www.tecnoempleo.com/data-engineer-data-processing-arelance/udp-unified-data-platform/rf-1d061fc092c7e35a8545,Tecnoempleo,2026-01-20
Data Engineer Databricks,"Descripción de la oferta de empleo  ´Te imaginas participando en la transformación de las principales organizaciones nacionales e internacionales?  En Deloitte estamos comprometidos con generar un impacto en la sociedad, en nuestros clientes y en ti.  Desde nuestro equipo de Deloitte Engineering Center, estamos buscando personas que se incorporen a nuestra área de Artificial Intelligence & Data.  ¿Cuál es el reto?  Buscamos un Data Engineer con amplio conocimiento de PySpark, Python, AWS y/o Databricks y control de versiones con Git, para participar en proyectos nacionales e internacionales.  ¿Cómo te imaginamos?  - Eres Graduado o posees Máster en Ingeniería Informática, Data Science, o similares. - Posees entre 2-5 años de experiencia como ingeniero de datos trabajando en procesamiento de grandes volúmenes de datos. - Tienes experiencia con PySpark, SparkSQL y Phyton para el desarrollo de procesos ETL y pipelines de datos. - Has desarrollado soluciones de datos utilizando servicios de AWS y/o Databricks (certificaciones valorables). - Posees experiencia con sistemas de control de versiones, preferiblemente Git. - Tienes experiencia en buenas prácticas de desarrollo de software, por ejemplo: pruebas unitarias, arquitectura de aplicaciones de datos, optimización... - Posees conocimientos de los sistemas de bases de datos, modelado de datos y SQL. - Tienes capacidad de trabajo en equipo, resolución de problemas y has trabajado en entornos colaborativos. - Buenas habilidades de comunicación y capacidad para aprender de manera autodidacta. - Nivel avanzado de inglés (B2 o superior), con capacidad para comprender y comunicar ideas técnicas complejas tanto de forma oral como escrita.  ¿Cómo es trabajar en Deloitte? Proyectos de alto impacto donde tendrás un largo recorrido y aprendizaje  Un día a día híbrido-flexible: tendrás horario flexible y un buen equilibrio entre el teletrabajo y el trabajo en equipo en nuestras oficinas o las de nuestros clientes  Buen ambiente dentro y fuera de la oficina: disfrutarás de varios teambuildings al año, actividades culturales y deportivas... ¡y mucho más!  Bienestar integral: cuídate con nuestro programa de salud física, mental y financiera... ¡y con equipo médico en las oficinas!  Impacto social: Podrás apuntarte a una gran cantidad de voluntariados de alcance nacional e internacional y a proyectos pro-bono con los que poner tu tiempo y talento al servicio de quienes más lo necesitan  Cultura del feedback y aprendizaje continuo: crecerás en un entorno inclusivo donde la igualdad de oportunidades y tu plan personalizado de formación impulsarán tu desarrollo. ¿Ya te visualizas en la Deloitte University de París?  Beneficios exclusivos por ser parte de Deloitte: podrás disfrutar de un gran catálogo de beneficios y de un completo plan de retribución flexible  Si te gusta lo que lees, estos son tus próximos pasos: - Aplica a la oferta haciendo clic en ´Enviar candidatura ahora´ y completa tu perfil - Si encajas en el puesto, nuestro equipo de talento te contactará para conocerte mejor  ¡Comienza el proceso! Te iremos guiando por las diferentes fases hasta tu incorporación.",https://www.tecnoempleo.com/data-engineer-databricks-deloitte/pyspark-python/rf-808912e3e22aa3f8534b,Tecnoempleo,2026-01-20
Data Engineer - Talend + PySpark,"Descripción de la oferta de empleo  En serem buscamos un/a Data Engineer con al menos 3 años de experiencia en Talend y PySpark para participar en proyectos de integración y procesamiento de datos a gran escala en entornos distribuidos. Formarás parte de un equipo técnico dinámico, trabajando en soluciones ETL/ELT y plataformas Big Data, con posibilidad de proponer mejoras y trabajar con buenas prácticas de desarrollo. Requisitos: • Mínimo 3 años de experiencia como Data Engineer. • Experiencia sólida en Talend (Data Integration). • Conocimiento avanzado de PySpark y procesamiento distribuido. • Experiencia con procesos ETL y manejo de grandes volúmenes de datos. • Buen manejo de SQL. • Capacidad para trabajar de forma autónoma y en remoto.  Se valorará: • Conocimiento de entornos cloud (AWS, Azure o GCP). • Experiencia en Apache Airflow, Docker, Git. • Nivel intermedio de inglés técnico. Condiciones: • 📍 100% Teletrabajo • 💰 Salario: 42.000 € brutos anuales • 📄 Contrato indefinido • 🕓 Jornada completa con flexibilidad horaria • 🌍 Proyecto estable y de largo recorrido   Fomentamos un ambiente de trabajo multicultural e inclusivo, no discriminamos por edad, género o creencias; así como ofrecemos igualdad de oportunidades a todo el personal. Desarrollamos nuestras actividades bajo los principios del cuidado del medioambiente, la sostenibilidad y la responsabilidad social corporativa; colaborando en proyectos de reforestación y sostenibilidad. Apoyamos los 10 principios del Pacto Mundial y los 17 Objetivos de Desarrollo Sostenible, en materia de derechos humanos, condiciones laborales, medio ambiente y anticorrupción. Los procesos de reclutamiento se desarrollan bajo altos estándares de calidad definiendo la incorporación en base a la experiencia y habilidades del candidato. Somos una empresa española líder en servicios tecnológicos y atracción del talento presente en el mercado desde 1995. Contamos con más de 600 empleados en proyectos tanto nacionales como internacionales en sector TI.",https://www.tecnoempleo.com/data-engineer-talend-pyspark-serem/etl-elt/rf-215d1307b235d377da4a,Tecnoempleo,2026-01-20
Profesor/a Inteligencia Artificial y Big Data,"Descripción de la oferta de empleo  Buscamos un/a profesional con sólida experiencia en Inteligencia Artificial para incorporarse como docente en nuestro Máster de especialización en IA y Big Data, dentro del entorno de la Formación Profesional, Madrid, turno de tarde 16:30 a 21:00 h L a J. El candidato ideal combinará competencias técnicas actualizadas con habilidades pedagógicas para impartir clases presenciales, prácticas y alineadas con las demandas del mercado laboral.  Responsabilidades principales  • Impartir contenidos relacionados con IA y en modalidad presencial, siguiendo el programa formativo oficial. • Desarrollar e impartir sesiones prácticas sobre:  o Machine Learning (ML) y Deep Learning (DL) o Procesamiento de datos masivos (Big Data) o Programación en Python aplicada a IA o Bibliotecas como Scikit-learn, TensorFlow, PyTorch, Pandas o Modelado y análisis de datos con herramientas como Jupyter, Spark o Power BI  • Módulos completos (Ya generada la documentación):  o Modelos de IA o Sistemas de aprendizaje automático o Programación en IA  • Guiar a los estudiantes en proyectos reales o simulados, fomentando la resolución de problemas y el pensamiento crítico. • Evaluar el aprendizaje del alumnado mediante exámenes, actividades prácticas y seguimiento de proyectos. • Participar en la mejora continua del programa formativo y en la coordinación docente. • Acompañar al alumnado en su orientación profesional hacia perfiles de técnico especialista en IA y datos.  Requisitos mínimos  • Formación especializada en Inteligencia Artificial, Ciencia de Datos o Big Data. • Experiencia demostrable como docente o formador en entornos técnicos y/o experiencia en proyectos de IA, Data Science y Big DATA. • Dominio de Python y frameworks de IA. • Capacidad para explicar conceptos complejos de forma didáctica y práctica. • Conocimiento del entorno educativo de Formación Profesional (valorable experiencia previa en FP de grado superior o máster de especialización).  Se valorará positivamente  • Experiencia con plataformas de formación presencial (pizarra digital, herramientas de laboratorio, etc.). • Certificaciones profesionales (Google Cloud AI, Azure AI Engineer, etc.). • Participación en proyectos innovadores, investigación o divulgación técnica. • Capacidad para generar material docente actualizado y orientado a la empleabilidad.  Ofrecemos:  • Clases presenciales Madrid, turno de tarde L a J 16:30 a 21:00h. • Salaria a convenir según valía. • Incorporación a un proyecto educativo innovador, con fuerte conexión con la industria tecnológica. • Entorno de trabajo colaborativo con otros profesionales del sector. • Posibilidad de continuidad o ampliación en otras áreas del centro educativo. • Incorporación a un centro educativo en pleno crecimiento. • Proyecto educativo sólido y orientado al empleo. • Entorno tecnológico y dinámico.",https://www.tecnoempleo.com/profesor-inteligencia-artificial-big-data-gm-quali/inteligencia-artificial/rf-b463148122fe732c7c4f,Tecnoempleo,2026-01-20
Data Engineer,"Descripción de la oferta de empleo  Data Engineer - EY GDS Spain - Hybrid  The opportunity  This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth as you get to work with high quality team to support clients ensuring the stability of global companies through best-in-class solutions, automation and innovation, working with an international team  As a member of our team in the EY GDS Spain office in Malaga, you´ll have a chance to extend your knowledge & experience by working on interesting projects with the newest technologies and approaches. You´ll support clients in choosing the most suitable business solution and take part in digital transformation.  Your key responsibilities  As a Data Engineer, your responsibilities will include: - Design, implement, and test solutions for various Analytics use cases (Batch Analysis; Streaming Analytics; Advanced Analytics or Machine Learning; Generative AI) on major public cloud infrastructures (e.g., Azure, Google Cloud) and cloud-agnostic data warehousing solutions (Snowflake, Databricks). - Lead the design and development of scalable and efficient data pipelines, integrating them into cloud-native architectures. - Research and evaluate innovative technologies in the Data & AI domain. - Collaborate with interdisciplinary teams to ensure project delivery. - Support the management of relationships with clients and technology partners.  Skills and attributes for success  To thrive in this role, key skills and attributes for success include: - Curiosity and commitment to researching and adopting innovative technologies in the Data & AI space. - Excellent collaboration skills to work effectively with cross-functional and interdisciplinary teams. - Strong communication skills for clear stakeholder engagement and client relationship support. - Ability to thrive in consulting or enterprise environments, balancing technical delivery with client-facing responsibilities. - Proactive mindset and team-oriented attitude, contributing to a positive and productive work environment. - Fluent in English.  To qualify for the role, you must have - Degree in engineering or scientific (STEM) disciplines. - 2 years of experience Data & Analytics projects, preferably in consulting or enterprise environments - Experience developing solutions in at least two of the following platforms: Azure, Databricks, Google Cloud (BigQuery), Snowflake. - SQL and Python - Experience in designing and developing modern data architectures (Data Lake, Data Warehouse, Data Mesh). - Good communication skills and a strong team-oriented attitude. - Fluency in English  Ideally, you´ll also have - B2 in Italian is a plus - Experience in Machine Learning. - Knowledge of Data Integration tools (e.g., Informatica, Talend, Data Factory, etc.). - Experience with Generative AI or MLOps projects. - Familiarity with visualization tools (Qlik, Power BI).  What we look for  We seek individuals who are passionate about their work and possess outstanding skills in their field. If You have a highly developed business acumen, exceptional interpersonal skills, and a willingness to embrace new professional challenges, this role is for You.  What we offer  In EY GDS Spain, we´re committed to fostering a vibrant environment where every team member can thrive. We provide a space for continuous learning and the flexibility to define your own success, empowering you to make a meaningful impact in your own way. Our diverse and inclusive culture values who you are and encourages you to help others find their voice.",https://www.tecnoempleo.com/data-engineer-ey/python-sql/rf-3fcd13e3521803bb8445,Tecnoempleo,2026-01-20
Enterprise Data & AI Architect for SAP,"Descripción de la oferta de empleo  We want to welcome a results-driven Data & AI professional with deep SAP background and experience in Enterprise Data & AI Architecture for SAP clients to join our SAP Industry Platforms Team (IPT) in Europe. To ensure success as a professional consultant, you should possess extensive knowledge of Enterprise Data & AI architecture and solutions, incl. Enterprise Reporting, Analytics and AI on SAP data. Upon joining the IPT SAP practice in Europe, you will have the opportunity to develop further your career in SAP across Europe, work with senior SAP experts and drive SAP Data & AI business in Europe.  What`s in it for you: - Work with leading European and global clients on complex SAP Data & AI transformation programs. - Join a senior team focused on thought leadership, origination, and delivery of large-scale SAP initiatives. - Access extensive career development opportunities and a wide range of employee benefits.  Key responsibilities: - Design and shape enterprise-scale Data & AI architectures for SAP clients, ensuring alignment with business goals and transformation programs. - Support pre-sales activities by pitching and shaping SAP Data & AI solutions and acting as a subject matter expert. - Lead delivery workstreams for enterprise reporting and analytics in large SAP S/4HANA transformations. - Communicate complex data and AI concepts clearly to stakeholders using storytelling techniques. - Collaborate with clients, ecosystem partners, and diverse teams to solve challenges and drive successful outcomes.  Necessary Knowledge / Skills: - Deep expertise in SAP Data & AI architecture, including enterprise reporting, analytics, and AI on SAP data. - Strong technical knowledge of SAP platforms (S/4HANA, BW/4HANA, SAP BTP) and modern data platforms (Databricks, Snowflake, Azure, Google Cloud). - Proven experience in shaping and implementing data solutions within large SAP transformation programs. - Excellent communication and collaboration skills, with ability to articulate business value and technical concepts. - Familiarity with agile and waterfall methodologies and experience leading mixed, distributed teams.  About Accenture  Accenture is a global professional services company with leading capabilities in digital, cloud and security. Combining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Interactive, Technology and Operations services-all powered by the world´s largest network of Advanced Technology and Intelligent Operations centers. Our 537,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. We embrace the power of change to create value and shared success for our clients, people, shareholders, partners and communities. Visit us at www.accenture.com.",https://www.tecnoempleo.com/enterprise-data-ai-architect-for-sap-accenture/hana-databricks/rf-890515f0b246c3382846,Tecnoempleo,2026-01-20
Data Governance,"Descripción de la oferta de empleo  Perfil buscado (Hombre/Mujer)  • Implementar estrategias y políticas de Data Governance en el sector inmobiliario. • Supervisar la calidad, integridad y seguridad de los datos en la organización. • Colaborar con el equipo de tecnología para optimizar los procesos de gestión de datos. • Definir y mantener estándares de datos y procedimientos de cumplimiento. • Garantizar la alineación entre los datos y los objetivos estratégicos de la empresa. • Realizar auditorías periódicas de los sistemas de datos. • Proporcionar formación y asesoramiento sobre buenas prácticas en Data Governance. • Participar en la implementación de nuevas herramientas tecnológicas relacionadas con la gestión de datos.  • Importante compañía de servcios en pleno crecimiento internacional. • Grandes posibilidades de crecer profesionalmente dentro de la compañía.  El/la candidato/a seleccionado deberá cumplir los siguientes requisitos:  • Formación académica en áreas relacionadas con tecnología, informática o gestión de datos. • Experiencia previa en proyectos de Data Governance en el sector inmobiliario. • Conocimientos sólidos en herramientas de gestión y análisis de datos. • Capacidad para trabajar en equipo y colaborar con diferentes departamentos. • Habilidades para la resolución de problemas y toma de decisiones. • Dominio del español y nivel profesional de inglés.  Nuestro cliente es una organización de gran tamaño dedicada al sector servicios. Su departamento de tecnología está altamente enfocado en la implementación de soluciones innovadoras para la gestión y análisis de datos.  • Contrato indefinido en una organización del sector inmobiliario de gran tamaño. • Rango salarial competitivo: 50.000 EUR - 60.000 EUR. • Entorno profesional enfocado en el desarrollo tecnológico y la innovación. • Oportunidades de crecimiento profesional en un equipo de alto rendimiento. • Ubicación en una zona accesible y bien comunicada.",https://www.tecnoempleo.com/data-governance-page-personnel/data/rf-ce8f132f3276a3d66c4a,Tecnoempleo,2026-01-20
Global Head of Data Intelligence,"Descripción de la oferta de empleo  Perfil buscado (Hombre/Mujer)  • Liderar y escalar equipos globales de Data Science, Data Engineering y Analytics, fomentando colaboración y alto rendimiento • Definir el roadmap de Inteligencia y Analítica (casos de uso, prioridades, OKRs) alineado con la estrategia del negocio • Orquestar proyectos end-to-end (ideación, diseño, desarrollo, despliegue y escalado), asegurando entregas on-time, on-quality y on-budget • Establecer estándares y gobernanza de datos: calidad, seguridad, privacidad, metodologías y MLOps/LLMOps • Impulsar analítica de marketing multicanal, social listening avanzado y dashboards ejecutivos automatizados • Comunicar impacto y valor mediante storytelling ejecutivo, alineando a stakeholders globales y regionales  • Liderarás la estrategia global de datos e IA con impacto real en negocio • Trabajarás con analítica avanzada e IA aplicada a grandes marcas.  • +7 años liderando equipos de analítica de datos y/o IA en entornos globales o multicountry • Experiencia definiendo metodologías, estándares de servicio y gobernanza de datos • Capacidad para dirigir equipos multidisciplinares (data science, data engineering, BI, martech) • Conocimiento sólido de analítica de marketing, social listening y performance digital • Experiencia trabajando con CRM, ecosistemas martech y herramientas de visualización • Inglés avanzado para interacción con audiencias y stakeholders internacionales  Nuestro cliente es una organización de gran tamaño dentro del sector de los servicios empresariales, con una fuerte presencia internacional y un enfoque en la transformación digital.  • Contrato indefinido en una organización de gran tamaño en Madrid. • Salario competitivo entre 70.000 € y 75.000 € anuales. • Bono adicional basado en rendimiento. • Opciones de teletrabajo flexibles. • Posición estratégica de alto impacto e influencia global • Autonomía para definir visión, roadmap y formas de trabajo • Liderazgo de equipos senior y altamente especializados",https://www.tecnoempleo.com/global-head-of-data-intelligence-page-personnel/bi/rf-1ebc10bfe231a31a6b42,Tecnoempleo,2026-01-20
Programador Big Data. Teletrabajo,"Descripción de la oferta de empleo  Te ofrecemos crecer con nosotros en nuestra unidad tecnológica como Programador Big Data en un puesto muy estable y a largo plazo, y en modalidad TELETRABAJO 100%. Cliente perteneciente al sector bancario   ¿QUÉ NECESITAMOS?  -Experiencia en Desarrollar y gestionar ETL  -Experiencia trabajando con Big Data - Spark y Python  -Experiencia con diferentes estructuras de bases de datos, incluido SQL (Postgres, Oracle)  -Experiencia trabajando en integración continúa ágil/DevOps   Deseables:  -Conocimiento de PowerBl y Databricks R  -Buen nivel de inglés deseable   ¿QUE TE PODEMOS OFRECER?  · Contratación indefinida  . Modalidad de trabajo: TELETRABAJO  · .Rango salarial: 38-40k b/año  · Beneficios sociales: Seguro médico privado y seguro de vida  · Retribución flexible: tickets restaurante, tickets guardería, tarjeta transporte  · 23 días de vacaciones y el día de tu cumpleaños  · Plan de formación personalizado.       Si sientes que podrías encajar y te apetece la experiencia, ¡ponte en contacto con nosotros! Y te daremos toda la información que necesites. ¡Abre una nueva ventana a tu futuro con Second Window! ¡Inscríbete!",https://www.tecnoempleo.com/programador-big-data-teletrabajo-second-window/spark-python-sql-ci-cd-powe/rf-054d17b2d2dbe398984d,Tecnoempleo,2026-01-20
Consultor Senior Data Sector Público,"Descripción de la oferta de empleo  Tu nueva empresa Consultora tecnológica líder en el mundo Data&Analytics  Tu nuevo puesto • Formar parte de un equipo dinámico dentro de una práctica en expansión.  • Brindar asesoramiento experto a clientes sobre soluciones tecnológicas y su implementación en el sector público.  • Participar en la definición técnica y económica de proyectos de Data & Analytics y en iniciativas estratégicas con fuerte componente de transformación digital para administraciones públicas. Esto incluye la gestión de plazos, riesgos, presupuestos y equipos.  • Realizar análisis de necesidades con un enfoque profundo en el conocimiento del sector.  • Liderar la preparación y gestión de propuestas para licitaciones públicas.  • Mantener una relación directa y constante con los clientes.  Qué necesitarás para encajar con el puesto • Experiencia mínima de 4 años en el diseño e implementación de soluciones de Data & Analytics e Inteligencia Artificial en el ámbito público.  • Formación técnica o en áreas como ADE/Economía, con experiencia demostrada en proyectos tecnológicos para administraciones públicas.  • Conocimiento en la elaboración de propuestas para concursos públicos, incluyendo definición de arquitecturas y soluciones de datos.  • Se valorará positivamente experiencia previa en consultoras tecnológicas.  • Nivel nativo de catalán, tanto hablado como escrito.  Qué obtendrás a cambio • Contrato indefinido: buscamos una colaboración a largo plazo.  • Jornada intensiva todos los viernes del año y durante julio y agosto.  • Modalidad híbrida de trabajo.  • Beneficios sociales.  • Plan de desarrollo profesional.  • Salario competitivo acorde a tu experiencia y formación.  • Apoyo económico para facilitar el teletrabajo.",https://www.tecnoempleo.com/consultor-senior-data-sector-publico-hays/data/rf-981b1aa2d2c25391d345,Tecnoempleo,2026-01-20
Technical Expert - Data & AI,"Descripción de la oferta de empleo  Company Description  Talan - Positive Innovation  Talan is an international consulting group specializing in innovation and business transformation through technology. With over 7,200 consultants in 21 countries and a turnover of €850M, we are committed to delivering impactful, future-ready solutions.  Talan at a Glance  Headquartered in Paris and operating globally, Talan combines technology, innovation, and empowerment to deliver measurable results for our clients. Over the past 22 years, we´ve built a strong presence in the IT and consulting landscape, and we´re on track to reach €1 billion in revenue this year.  Our Core Areas of Expertise - Data & Technologies: We design and implement large-scale, end-to-end architecture and data solutions, including data integration, data science, visualization, Big Data, AI, and Generative AI. - Cloud & Application Services: We integrate leading platforms such as SAP, Salesforce, Oracle, Microsoft, AWS, and IBM Maximo, helping clients transition to the cloud and improve operational efficiency. - Management & Innovation Consulting: We lead business and digital transformation initiatives through project and change management best practices (PM, PMO, Agile, Scrum, Product Ownership), and support domains such as Supply Chain, Cybersecurity, and ESG/Low-Carbon strategies.  We work with major global clients across diverse sectors, including Transport & Logistics, Financial Services, Energy & Utilities, Retail, and Media & Telecommunications.  Job Description  The Technical Expert - Data & AI is responsible for providing technical leadership, advanced expertise, and deep knowledge in data and artificial intelligence to design, build, optimize, and support data and AI platforms, pipelines, and architectures. The role acts as a technical reference within the CIO organization, ensuring that data and AI initiatives are robust, scalable, secure, and aligned with business strategy and the group´s data governance framework.  Key Responsibilities  Platform leadership, build, and maintenance: Define standards, best practices, and frameworks for the construction, deployment, and maintenance of data and AI infrastructures (on-premises, cloud, or hybrid).  ML/AI model implementation and operations: Participate in the implementation and deployment of machine learning, deep learning, and AI models, ensuring integrity, performance, monitoring, and ongoing maintenance.  Technical validation and tool evaluation: Evaluate new technologies, tools, and platforms (open source, commercial, cloud) to optimize the data/AI ecosystem; lead proof-of-concepts (PoCs) and benchmarking activities.  Architecture definition and solution design support: Support the design of data and AI technical solutions - including data pipelines, data lakes/warehouses, streaming, MLOps, and analytics platforms - to meet strategic objectives.  Integration and deployment: Coordinate the integration of data and AI solutions with other corporate systems, ensuring compatibility, security, and efficiency.  Governance, security, and compliance: Ensure solutions comply with data governance, security, privacy, and regulatory standards (e.g., data regulations, internal policies).  Technical support and mentoring: Act as a technical point of reference by resolving questions from architects, data engineers, and data scientists; guiding and reviewing technical designs; and promoting best practices and standards.  Cross-functional collaboration: Work closely with business, analytics, cybersecurity, infrastructure, and compliance teams to ensure alignment between business needs, regulations, and technical capabilities.  Documentation and technical communication: Document architectures, processes, and technical decisions; communicate risks, technical decisions, and project status to the CIO and relevant stakeholders.  Continuous innovation: Stay current with emerging trends in AI, big data, MLOps, automation, cost optimization, and performance. Promote piloting of new technologies when appropriate.  Qualifications - Minimum of 5-8 years of relevant experience in advanced technical roles related to data, big data, cloud, AI, ML, or data engineering. - At least 3 years of experience designing and architecting data/AI solutions in complex environments (large-scale data, security/regulatory constraints, corporate environments). - Hands-on experience implementing data pipelines, data lakes/warehouses, ingestion processes, transformation, and batch and/or streaming processing. - Experience deploying ML/AI models into production using MLOps best practices, including monitoring and maintenance.  Strong Technical Knowledge  Programming languages:  Python, SQL. Preferred: Scala, Java, R.  Platforms / Big Data / Cloud: Experience with cloud services (AWS, Azure, GCP) or hybrid/on-prem environments. Knowledge of tools such as Spark, Databricks, Hadoop, Kafka, Airflow, Trino, etc.  Databases and modeling: Relational and dimensional modeling; NoSQL databases (document, key-value, columnar); data lakes and data warehouses.  Machine Learning / AI / MLOps: ML/AI frameworks, training and inference pipelines, orchestration, containers (Docker, Kubernetes), deployment, monitoring, and model versioning.  Infrastructure & automation: Infrastructure as Code (IaC), containers, orchestration, CI/CD pipelines, and automation tools.  Security and compliance: Knowledge of data governance regulations, data protection, encryption, access control, and security best practices.  Additional Information  What do we offer you? - Hybrid position based in Malaga, Spain - Possibility to manage work permits. - Permanent, full-time contract. - Smart Office Pack so that you can work comfortably from home. - Training and career development. - Benefits and perks such as private medical insurance, life insurance, Language lessons, etc - Possibility to be part of a multicultural team and work on international projects.  If you are passionate about data, development & tech, we want to meet you!",https://www.tecnoempleo.com/technical-expert-data-ai-talan/python-sql/rf-1a2b1e7e5250e3dd4043,Tecnoempleo,2026-01-20
Data Engineer (f/m/d),"Descripción de la oferta de empleo  Workload: 100%  Are you ready to shape the future of data digitization and optimization? Join our motivated and experienced Data Platform team as a Data Engineer. In this role, you´ll tackle exciting projects, work with cutting-edge technologies, and contribute to building scalable systems that transform large datasets into actionable insights.  What you will do:  - Design and validate robust data infrastructure using the latest tools and technologies. - Collect, store, process, transform, and analyze large datasets. - Build scalable and understandable software and services to support data-driven decision-making. - Improve code quality through unit tests, automation, and code reviews. - Collaborate in brainstorming sessions to enhance our technology, algorithms, and products. - Navigate, transform, and manage external data sources, analytics, and activity streams. - Develop systems that empower informed decision-making across the organization.  What you bring & who you are:  - At least 3 years of experience in data engineering, with expertise in Databricks, AWS Glue, or Apache Spark. - Strong programming skills in Python or similar languages. - Proficiency in SQL/NoSQL databases (e.g., MySQL, PostgreSQL, MongoDB) and data integration. - Experience with ETL frameworks and building data pipelines. - Familiarity with cloud environments like Azure and their data services (e.g., Databricks, Data Factory). - Knowledge of Agile/Scrum methodologies and continuous delivery/deployment practices. - Strong problem-solving and communication skills, with a collaborative mindset.  About the team: We are a diverse and dynamic team passionate about leveraging data to drive innovation. Collaboration and mutual support are at the core of our culture, and we value every voice and perspective. Together, we tackle challenges, celebrate successes, and continuously strive for excellence.  Benefits:  At our company, we strive to create a culture of continuous learning, personal growth, and inter- national community involvement. We´re passionate about providing our employees with the tools and resources they need to succeed, and we´re confident that you´ll love being part of our team! - Working Hours We offer flexible working hours to accommodate your work schedule. 60% on remote and 40% at our offices in Madrid, Torre Europa. - Meal allowances  You can enjoy delicious meals on us, no matter if you are working remotely or on-site. *Option to use it for public transportation or childcare instead. - Internet Compensation We cover the cost of your home internet connection, as we understand how essential connectivity is in the modern workplace. - Training courses Our company is committed to helping our employees grow and develop their skills, which is why we offer a variety of industry- specific training courses and a learning channel. - Gym Coverage Stay active and healthy with our 90% coverage benefit, which provides access to the nearby gym: Forus Selection to keep you energized throughout the day - Health Insurance We take the health and well-being of our employees seriously, which is why we offer a comprehensive health insurance plan and the option to extend it to your spouse and children.  At Axpo Group, we are dedicated to fostering a culture of non-discrimination, tolerance, and inclusion. As an equal opportunity employer, we welcome applications regardless of race and ethnicity, gender identity and expression, sexual orientation, age, disability, as well as socioeconomic, cultural, and religious background. We are committed to ensuring a respectful and inclusive recruiting process and workplace for everyone.  Department IT / Technology Role Permanent position Locations Madrid Remote status Hybrid",https://www.tecnoempleo.com/data-engineer-f-m-d-axpo-group/big-data-python/rf-826f11e9127b13ca324b,Tecnoempleo,2026-01-20
Data Architect,"Descripción de la oferta de empleo  GFT es una compañía pionera en transformación digital. Diseñamos soluciones de negocio centradas en la inteligencia artificial (AI-Centric), modernizamos infraestructuras de TI y desarrollamos sistemas core de nueva generación para líderes del sector bancario, asegurador e industrial. En estrecha colaboración con nuestros clientes, desafiamos los límites para ayudarles a alcanzar todo su potencial.  ¿Qué estamos buscando?  Actualmente tenemos un puesto vacante para un/a Data Architect que quiera unirse a nuestra compañía. Buscamos una persona con una sólida trayectoria en ciencia de datos, capaz de liderar equipos, diseñar estrategias analíticas y guiar la implementación de soluciones avanzadas para nuestro Centro de Excelencia (CoE).  Tus principales responsabilidades serán:  Aunque dependerán de tus conocimientos y experiencia aportada, en general las principales funciones que llevarías a cabo con nosotros serían:  - Responsable de diseñar, implementar y evolucionar la arquitectura de datos de la organización, asegurando que los sistemas de ingesta, procesamiento, almacenamaiento y consumo de datos sean escalables , seguros y eficientes. - Diseñar y mantener la arquitectura de referencias de datos (en entornos batch y streaming). - Definir estrategias de ingesta (CDC, API, streaming), almacenamiento (Data Lake, Data Warehouse, Lakehouse) y orquestación. - Asegurar la calidad, integridad y disponibilidad de los datos a lo largo de su ciclo de vida. - Liderar la adopción de patrones y frameworks de integración de datos (ETL/ELT, Data Mesh, Event-Driven). - Colaborar con equipos de ingeniería, analítica y negocio para definir modelos de datos y necesidades de explotación. - Supervisar la seguridad, gobernanza y cumplimiento normativo (GDPR, políticas de acceso, catalogación). - Evaluar nuevas tecnologías y proponer mejoras de rendimiento, coste o mantenibilidad. - Liderazgo técnico y coaching.  Requisitos:  - Experiencia profesional de más de 7 años en proyectos como Data Architect. - Diseño de arquitecturas distribuidas y escalables. - Procesamiento batch y streaming. - Integración de datos (CDC, APIs, colas, mensajería, ETL/ELT). - Patrones de Data Lake / Data Warehouse / Lakehouse / Data Mesh. - Principios de seguridad, gobierno y calidad de datos. - Modelado de datos relacional y dimensional. - Familiaridad con metodologías ágiles (Scrum/Kanban). - Valorable nivel de inglés alto (B2/C1) para colaborar en proyectos internacionales.  Competencias personales:  - Trabajo en equipo y colaboración multidisciplinaria. - Habilidades de comunicación, favoreciendo dinámicas que permitan el flujo de conocimiento, con interés tanto en aprender como en enseñar. - Buena comunicación y documentación técnica. - Orientación a resultados y proactividad.  En GFT consideramos que la diversidad es uno de nuestros pilares fundamentales y promovemos un entorno de trabajo inclusivo basado en la cooperación y el respeto mutuo. Ofrecemos igualdad de oportunidades a todas las personas sin tener en cuenta su raza, origen cultural, sexo, edad, orientación sexual, identidad de género, discapacidad o creencias religiosas. GFT dispone y ha registrado un Plan de Igualdad que recoge las medidas a adoptar con el objetivo de alcanzar en la empresa la igualdad de trato y de oportunidades entre mujeres y hombres y a eliminar, si es que la hay, la discriminación por razón de sexo  ¡Únete a nuestro equipo global!  Als Partner für IT-Beratung und Software-Entwicklung sind wir auf die digitale Transformation unserer Kunden aus den Bereichen Finanzen, Versicherungen und Industrie spezialisiert. Unsere rund 700 Talente in Deutschland entwickeln mit modernsten Technologien nachhaltige Lösungen.  Qué ofrecemos - Conciliación y Flexibilidad: Posibilidad de trabajar desde casa híbrido/remoto, jornadas flexibles y viernes intensivos. - Formación y Desarrollo: Plan personalizado, programas formativos. - Beneficios Sociales: Seguro vida, apoyo teletrabajo. - Beneficios Flexibles ""a la carta"": Bolsa corporativa para comida, transporte, seguro médico, guardería y formación, ajustada a tus necesidades y combinada con retribución flexible. - Paquete de Reubicación (si aplica): Apoyo económico, asesoramiento, patrocinio visas. - Programa de Recomendaciones. - Programa de Bienestar: Nutrición, Física, Mental. Descuentos con Wellhub. Servicio de apoyo psicológico gratuito. - Vida en GFT: Oficinas inteligentes, eventos, premios de valores, charlas inspiradoras. - Cultura corporativa internacional.",https://www.tecnoempleo.com/data-architect-gfr-technologies-se/etl/rf-7d7a1e17021543e14c4f,Tecnoempleo,2026-01-20
Analista Programador/Data Scientist/BI,"Descripción de la oferta de empleo  En Grupo INVOIN necesitamos incorporar a nuestra plantilla un Data Scientist para participar en un proyecto estable de ingeniería de tráfico y transporte en Madrid con modalidad híbrida de teletrabajo.  Características del puesto  Salario competitivo y acorde a experiencia aportada. Contratación indefinida, estabilidad y crecimiento profesional. Posibilidad de adquirir beneficios sociales. Incorporación y formación en proyectos desafiantes y tecnológicamente avanzados con un alto componente de Innovación y Desarrollo. Desarrollo de carrera profesional. Agradable ambiente de trabajo, integrándose en un equipo joven. Dedicación: Horarios flexibles (entrada entre las 8h y las 9h). Jornada completa. Jornada intensiva los viernes y en agosto. Festivos adicionales a las vacaciones en 2024. Ubicación: Alcobendas (Madrid). Teletrabajo: 30%. Requisitos  Titulación universitaria en informática, ingeniería informática (grado o máster). 2 años de experiencia en programación de al menos alguno de los siguientes frameworks o entornos: NodeJS, javascript, React, html, css, sql (TSQL o PSQL). Nivel alto de inglés. Mínimo C1. Valorable: Conocimientos de procesos Big Data (Python, Javascript, y RESTful API; Procesos ETL; Apache Spark, Anaconda, Jupyter NB, Tensorflow). Conocimiento de herramientas de BI (Grafana, Power BI). Conocimiento de herramientas Docker, Kubernetes. Gis. Máster en Data Science. Certificaciones AWS. Trabajo con BBDD No SQL. Diseño de Data Lakes. Se valorarán conocimientos en el sector del Transporte, Agua o Medioambiente.",https://www.tecnoempleo.com/analista-programador-data-scientist-bi-hibrido/nodejs-javascript-react-htm/rf-67431d3912e3b39a5c40,Tecnoempleo,2026-01-20
GCP Data Engineer - Sector Moda,"Descripción de la oferta de empleo  Company Description  Devoteam es una consultora líder en Europa centrada en estrategia digital, plataformas tecnológicas, ciberseguridad y transformación empresarial a través de la tecnología. La tecnología está en nuestro ADN y creemos en ella como una palanca capaz de impulsar el cambio a mejor, manteniendo un equilibrio que nos permite ofrecer a nuestra cartera de clientes herramientas tecnológicas de primer nivel pero siempre con la cercanía y profesionalidad de un equipo que actúa como guía en el camino. Devoteam lleva más de 30 años apostando por la tecnología al servicio de las personas. Con más de 12.000 personas en el grupo, en 25 países de Europa, Oriente Medio y África.  Job Description  Desde Devoteam buscamos un Google Cloud Data Engineer para trabajar en multiproyecto, participando en la evolución de sus capacidades de datos. Trabajo no solo en la implementación técnica, sino como perfil cross funcional capaz de entender el negocio, liderar iniciativas y proponer soluciones end-to-end. Este rol requiere una mentalidad resolutiva para transformar requisitos no estructurados en soluciones de datos eficientes y estratégicas. Contacto directo con diferentes equipos, incluyendo desarrollo PBI, ingeniería (back-end) y DPOs.  Requisitos - Experiencia: perfil senior con al menos 5 años de experiencia demostrable en ingeniería de datos. - Stack tecnológico imprescindible:- Google Cloud Platform: dominio de BigQuery, Cloud Run, Cloud Functions, Dataform. - Lenguajes de programación: experiencia sólida en Python y SQL/SQLx (JavaScript).  - Plus valorables: experiencia con CI/CD y Terraform, así como otros conocimientos técnicos relevantes en el ecosistema GCP. - Idiomas: nivel de inglés B2 o superior (conversación fluida), ya que habrá comunicación constante con equipos internacionales.  Responsabilidades clave / Soft skills - Capacidad para trabajar eficazmente en múltiples áreas funcionales. - Fuerte capacidad de liderazgo en iniciativas de datos. - Habilidad para la recogida de requisitos en entornos ambiguos y su materialización. - Visión para la propuesta de soluciones técnicas y su implementación end-to-end. - Adquisición rápida de visión transversal de negocio para la toma de decisiones. - Proactividad, autonomía y madurez técnica para trabajar de forma independiente.  Qualifications - Python (alto): Integración de APIs, ETLs y librería Pandas. - Docker (alto): Construcción de imágenes. - SQL (alto): Optimización de queries, funciones ventana, operaciones merge. - Git (alto): Básicos de trabajo con ramas, pull, push, merge, resolución conflictos,... - Bitbucket o Cloud Source Repositories (alto): Repositorios comerciales de código, tb vale Github o Gitlab como similares. Cloud Source Repositories para mantenimiento ya que la feature está deprecada desde Jun 2024. - BigQuery (alto): Particiones, Clusterización. - Dataform o dbt (alto): Manejar la plataforma, conexión de repos, desarrollo de ETLs, orquestación, tags, incrementales,... - Modelado (alto): Modelado dimensional Kimball (tablas hechos, dimensiones, matriz de bus) y generar un modelo desde un documento de requisitos. - Inglés (alto): B2 o superior (no necesario para el día a día pero sí para comunicación con la sede) - Cloud Run, Cloud Functions (medio): Despliegues desde consola y depuración de errores. - Cloud Storage (medio): Conocimientos básicos de buckets, ACLs, IAM, políticas de lifecycle,... - Asana (bajo): O plataformas similares (Jira, Service Now,...) - Dataplex (bajo): Conocimientos básicos. - Fivetran (bajo): Conocimientos básicos.",https://www.tecnoempleo.com/gcp-data-engineer-sector-moda-devoteam/bigquery-cloud-run/rf-58ee11a0d222231b5d46,Tecnoempleo,2026-01-20
Data Engineer,"Descripción de la oferta de empleo  Descripción de la empresa  Porque trabajar en Sopra Steria, también es sentir Sopra Steria.  Somos un reconocido líder europeo en consultoría, servicios digitales y desarrollo de software, con cerca de 56.000 empleados en casi 30 países y más de 4.000 en España. Nos enfocamos en las personas, en su formación y desarrollo profesional, lo que nos impulsa a crecer y mejorar constantemente.  Tenemos pasión por lo digital y al igual que tú, buscamos la mejor de las aventuras. Queremos que tu día a día se convierta en la mejor de tus inspiraciones. Que aprendas, aportes, te diviertas, crezcas y que, sobre todo, disfrutes al máximo.  Si quieres formar parte de un equipo ""Great Place to Work"", ¡Sigue leyendo!  Descripción del empleo  Buscamos 3 perfiles de Data Engineer para incorporarse en un proyecto estable del sector bancario, concretamente en el área de Pagos y Medios de Pago.  Requisitos  Al menos 3 años de experiencia en: - tareas de análisis, arquitectura, desarrollo de proyectos de Data - Azure Databricks - Stratio (Data Governance) - Python/Pyspark  Información adicional  ¿Qué tenemos para ti? - Contrato indefinido y jornada completa - 23 días de vacaciones - Formación continua: competencias técnicas, transversales y de idiomas. Contamos con acceso a certificaciones, formaciones de los principales Partners Tecnológicos, plataformas online y ¡mucho más! - Seguro de vida y de accidentes - Posibilidad de acogerte a nuestra retribución flexible (seguro médico, cheques guarderías, transporte, comida y formación) - Acceso a Privilege Club, donde encontrarás descuentos interesantes en las principales marcas - Onboarding personalizado y detallado. Te acompañamos en todo momento para que te sientas #soprano desde el primer momento. - Oficina con espacios reservados al ocio. ¡Trabajo y diversión unido! - Compañerismo y buen ambiente, el poder de la unión lo tenemos presente.  Y lo más importante...Tienes la posibilidad de desarrollar tu carrera profesional con nosotros: Crearemos juntos un plan de carrera personalizado. Te formarás, marcaremos objetivos y llevaremos a cabo un seguimiento para asegurarnos de que lo conseguimos juntos. Escuchamos tus prioridades y luchamos por ellas.  ¡Aquí tu voz importa! ¡Únete a nosotros y sé parte de algo más!  The world is how we shape it  Adquirimos el compromiso de respetar la diversidad, creando un ambiente de trabajo inclusivo y aplicando políticas que favorezcan la inclusión y promuevan el respeto social y cultural en cuestiones de género, edad, funcional, orientación sexual y religión con igualdad de oportunidades.",https://www.tecnoempleo.com/data-engineer-sopra-steria/azure-databricks-python/rf-9cfc18bab2e7b3cb9743,Tecnoempleo,2026-01-20
Information Data Architect,"Descripción de la oferta de empleo  Job description: Information Data Architect :: Contract Role :: Contract :: Macclesfield, UK :: 2-3 days onsite/week The (Enterprise Information Architecture) EIA practice is seeking an Information Architect, that aligns to the Operations line of business encompassing Global Supply Chain and Manufacturing.  The Operations Information Architecture team supports the following business capability areas: - • Develop: Development and commercialisation of medicines emerging from R&D • Plan: Supply chain planning and optimisation • Source: Procurement of externally sourced materials and contract manufacturing • Make: Manufacturing and quality release of medicines in a validated (GMP) environment • Delivery: the delivery of medicines to patients The role will focus on the definition and governance of enterprise information architectures, strategies, designs, models and consolidating thinking and artefacts across Operations, one or more projects/programmes, to drive out enterprise thinking and delivery across Required Skills and Experience:  Essential Desirable • Bachelor’s Degree or equivalent number of years of experience in a Computer Science or Data Management related field. • Experience in leading and delivering enterprise data platform architectural thinking, and its practical application. • Experience in the use of conceptual and logical data modelling technologies. • Experience in defining and working with information and data regulatory governances. • The role holder will possess a blend of data/information architecture, analysis, and engineering skills. • Experience in known industry IT architectural patterns and IT architecture ways of working/methodologies (e.g. FAIR data principles, Data Mesh). • Understanding the appropriate data structure and technology based on business use case and completely familiar with data lifecycles. • Experience in a data architect role with practical examples of designing and providing data engineering/architectural blueprints that have been implemented. • Experience of Information and Data Governance frameworks and their application in a commercial organisation • Understands Data Platforms concepts and cloud-based containerization strategies for hybrid cloud environments. • Experience in Agile data definition scrums. • Experience in the use of tooling, e.g. metadata cataloguing tools, data modelling tools, EA tools • Understanding of, or familiarity with, Data Mesh approaches (as distinct from Data Fabric or Data Platform • Experience working in matrix-based environment with multiple stakeholder groups identifying priorities. • Experience of working in the Pharmaceutical industry.",https://www.tecnoempleo.com/information-data-architect-axiom-software-solution/data/rf-fc171340b23e839f604a,Tecnoempleo,2026-01-20
Big Data Consultant,"Descripción de la oferta de empleo  En Accenture creemos en la tecnología como motor de la reinvención total de la empresa. Trabajamos con las plataformas y los partners líderes en el mercado para impulsar los negocios de nuestros clientes a través de la digitalización, la IA y los datos. Si quieres formar parte de un Great Place To Work® y formar parte de un equipo de más de 801.000 profesionales en todo el mundo, sigue leyendo:  Buscamos un/a Consultor/a Big Data con al menos 4 años de experiencia, para incorporarse a nuestro equipo en Barcelona, especializado en proyectos de transformación tecnológica con stack de datos moderno.  Funciones: - Diseño e implementación de soluciones de datos en entornos cloud. - Desarrollo de pipelines de datos utilizando herramientas como DBT y Databricks. - Modelado de datos y optimización de consultas en Snowflake. - Colaboración con equipos multidisciplinares para integrar soluciones de datos en productos digitales.  Responsabilidades: - Experiencia demostrable en el uso de Snowflake, DBT y Databricks. - Capacidad para diseñar arquitecturas de datos escalables y eficientes. - Nivel alto de inglés (mínimo C1) para colaborar en entornos internacionales. - Titulación en Ingeniería Informática o estudios afines. - Capacidad analítica, autonomía y orientación a resultados.  El puesto se desempeña en Barcelona en un modelo de trabajo híbrido realizando algunos días desde tu casa y otros en la oficina donde podrás crear interesantes sinergias con el resto de tu equipo. Es imprescindible residir en España y tener permiso laboral en España.  En Accenture, compañía reconocida como Great Place To Work®, apostamos por un modelo de híbrido de trabajo que, gracias a la tecnología y a nuestras instalaciones, nos permiten mantener la conexión humana esencial para trabajar con nuestros equipos y clientes. Una conexión que nos permite mantener nuestra cultura de inclusión y diversidad y ser, según Refinitiv, la empresa más diversa del mundo. Además, te ofrecemos otros beneficios como: - Seguro médico, de Vida y accidentes - Servicio médico y programas de bienestar - Programa de retribución flexible y compra de acciones - Programas de flexibilidad (horaria, de días libres, vacaciones...) - Itinerario formativo individualizado - Programas de sostenibilidad y Fundación Accenture - Red de empleados por la diversidad - Otros beneficios: Oficina Bankinter con condiciones especiales y reparto de beneficios",https://www.tecnoempleo.com/big-data-consultant-accenture/snowflake-dbt/rf-e4141268d28ce3b9cf40,Tecnoempleo,2026-01-20
Senior Manager (Data Lead),"Descripción de la oferta de empleo  Perfil buscado (Hombre/Mujer)  Estamos buscando un Senior Manager (Data Lead) con sólida experiencia en gestión de proyectos de datos para liderar iniciativas estratégicas orientadas a la transformación digital y la explotación avanzada de información. Este rol será clave para definir la visión, y garantizar la entrega de soluciones que generen valor a negocio.  Funciones:  • Liderar proyectos vinculados al dato • Delivery de producto • Comunicación con Directores de Negocio y/o Tecnológicos C-Level • Realización de presentaciones interpretando métricas de negocio • Experiencia en Análisis de datos de negocio. • Colaborar con otros departamentos para integrar soluciones basadas en datos. • Gestionar proyectos relacionados con datos desde su inicio hasta su implementación. • Participar en la toma de decisiones estratégicas basadas en análisis de datos.  • Compañía tecnológica con producto propio • Senior Manager, delivery de proyectos basado en Datos al más alto nivel  El/la candidato/a seleccionado deberá cumplir los siguientes requisitos:  • Titulación en Ingeniería Informática, Telecomunicaciones, Matemáticas, Estadística o similar. • 7-10 años de experiencia en liderazgo de proyectos de Data. • Capacidad analítica • Conocimientos avanzados en tecnología de datos y herramientas de análisis. • Experiencia gestionando el delivery de proyectos tecnológicos ligados al dato. • Capacidad para trabajar en un entorno dinámico y colaborativo. • Habilidades de comunicación para interactuar con C-Level • Perfecto entendimiento de la base técnica de proyectos de Data • Dominio de herramientas de visualización y analítica • Nivel de inglés C1 • Reporte a Comité de Dirección  Nuestro cliente es una organización del sector de Tecnología. Se caracteriza por su enfoque en la innovación tecnológica y su compromiso con el desarrollo de soluciones avanzadas.  • Contrato indefinido en una organización del sector tecnológico con producto propio. • Ubicación en Madrid, presencialidad con flexibilidad horaria. • Acceso a tecnologías avanzadas.",https://www.tecnoempleo.com/senior-manager-data-lead-michael-page/data/rf-b47f18e5026203a8c542,Tecnoempleo,2026-01-20
Engineer DATA,"Descripción de la oferta de empleo  🚀 Buscamos Ingeniero/a de Datos con experiencia en Azure y arquitecturas de datos modernas, con al menos 3 años de experiencia, para un proyecto de larga duración con un cliente de gran relevancia. Tendrás la oportunidad de trabajar en un proyecto estratégico y estable, con tecnologías punteras y gran impacto en el negocio del cliente.  🕒 Horario: jornada de oficina, de lunes a viernes.  💼 Tipo de incorporación: en proyecto de larga duración.  💶 Salario: entre 45.000 y 46.000 € brutos anuales, según experiencia.  🖥️ Modalidad: 100% remoto — trabaja desde cualquier lugar, con un equipo altamente cualificado y comprometido.    🧠 Sobre el puesto   Como Ingeniero/a de Datos (Cloud & Modern Data Stack), formarás parte de un equipo multidisciplinar encargado de diseñar e implementar soluciones de datos escalables, eficientes y seguras en la nube de Azure.  Tendrás la oportunidad de trabajar en un proyecto estratégico y estable, con tecnologías punteras y gran impacto en el negocio del cliente.   🔧 Responsabilidades principales   Diseñar, construir y mantener arquitecturas de datos escalables y eficientes en la nube de Azure. Desarrollar e implementar soluciones avanzadas de modelado y migración de datos. Colaborar con equipos de análisis y ciencia de datos para comprender y satisfacer sus necesidades. Optimizar el rendimiento y la fiabilidad de las plataformas de datos existentes. Garantizar la calidad e integridad de los datos mediante procesos rigurosos de validación y monitoreo. Mantenerse actualizado/a sobre tendencias y tecnologías emergentes en ingeniería de datos.   💡 Tecnologías que utilizarás   Azure Synapse Analytics Azure Data Factory Azure Databricks Arquitectura Lambda Data Vault dbt (data build tool) Requisitos Experiencia mínima de 3 años en ingeniería de datos. Dominio de herramientas Azure: Azure Synapse, Data Factory, Databricks. Experiencia en modelado de datos, diseño de esquemas y optimización de bases de datos. Experiencia en migración de datos entre diferentes plataformas y entornos. Conocimiento de la arquitectura Lambda y sus componentes. Experiencia con dbt para la transformación de datos. Nivel de inglés fluido (mínimo B2).   🌟 Por qué unirte a Krell Consulting   En Krell Consulting fomentamos un entorno de trabajo colaborativo, innovador y orientado al crecimiento profesional.  Cada miembro del equipo tiene la oportunidad de dejar su huella, enfrentarse a proyectos desafiantes con tecnologías de vanguardia y desarrollar su talento dentro de una compañía en constante expansión🚀",https://www.tecnoempleo.com/engineer-data-krell-consulting-training/azure-synapse/rf-3fa7139d12bd33d43f45,Tecnoempleo,2026-01-20
Data Engineer - EY GDS Spain,"Descripción de la oferta de empleo  Data Engineer  As a Data Engineer you will oversee data ingestion processes and deployment of ML/IA solutions for predictive analysis for an energy sector customer. You will collaborate with Data Scientist and Data Engineers to achieve project and client goals on a very dynamic environment.  The opportunity  As a member of our team in GDS office in Malaga, Spain, you´ll have a chance to extend your knowledge & experience by working on the interesting projects with the newest technologies and approaches. You´ll support clients in choosing the most suitable business solution and take part in digital transformation.  Your key responsibilities  As a Data Engineer, you will work on the design of end-to-end pipelines for enterprise data loading from different sources, deployment of ML/IA solutions for predictive analysis and improvements on quality of data.  You will also collaborate with the product development teams (business analysts, product owners, developers) to deliver high quality solutions for our customers.  To qualify for the role, you must have - Degree on Statistics, Maths, Informatics or similar. - 1-3 years of experience as Data Engineer - Experience in Azure: Databricks, DataFactory, Synapse - Database knowledge, SQL, OLTP/OLAP - Experience of Big Data (i.e Spark, Hadoop) - Very good communication skills in terms of capturing requirements, describing architecture, data flows, etc. - Excellent communication skills in Spanish (C1 or Native) and in English at least at B1 level.  Ideally, you´ll also have - Knowledge of cloud solutions - Experience on Agile and SCRUM methodology.  What we look for  We are a dynamic team of passionate specialists, working in international teams all over the world. As part of the Data team, we look for ""out of the box thinking"" professionals that will build good relationships with our clients. If you want to be a part of this journey, we are looking forward to seeing you on board!  What we offer  EY Global Delivery Services (GDS) is a dynamic and truly global delivery network. We work across eight locations - Argentina, China, India, Philippines, Poland, UK, Hungary and Spain - and with teams from all EY service lines, geographies and sectors, playing a vital role in the delivery of the EY growth strategy. From accountants to coders to advisory consultants, we offer a wide variety of fulfilling career opportunities that span all business disciplines. In GDS, you will collaborate with EY teams on exciting projects and work with well-known brands from across the globe. We´ll introduce you to an ever-expanding ecosystem of people, learning, skills and insights that will stay with you throughout your career. - Continuous learning:You´ll develop the mindset and skills to navigate whatever comes next. - Success as defined by you: We´ll provide the tools and flexibility, so you can make a meaningful impact, your way. - Transformative leadership: We´ll give you the insights, coaching and confidence to be the leader the world needs. - Diverse and inclusive culture:You´ll be embraced for who you are and empowered to use your voice to help others find theirs.",https://www.tecnoempleo.com/data-engineer-ey-gds-spain-ey/databricks-datafactory/rf-58441ccca220433a7449,Tecnoempleo,2026-01-20
"Big Data Engineer Spark, Scala, ELK","Descripción de la oferta de empleo  Ubicación: Preferencia por ciudades con sede (flexible para candidatos deslocalizados si el perfil encaja) Modalidad: A convenir Tarifa: Acorde a experiencia y conocimientos del perfil Nivel de inglés: B2  Descripción del puesto Buscamos un profesional para participar en la creación de un nuevo dashboard en Kibana, incluyendo tareas de preprocesamiento Big Data en el Data Lake (SCIB). Formará parte de un equipo de trabajo especializado en Market Risk, colaborando tanto en el desarrollo de procesos en tecnologías Big Data (Spark, Scala) como en tareas comunes del área.  El rol implica trabajar con tecnologías del ecosistema ELK (Kibana, Elasticsearch, Logstash), procesamiento de datos en entornos distribuidos (Hadoop, Spark), y contribuir a la construcción de soluciones analíticas que ayuden a la gestión de riesgos del mercado.  Responsabilidades Desarrollo y mantenimiento de procesos de ingesta y transformación de datos en Spark (Scala). Diseño y construcción de dashboards en Kibana para la visualización de datos de Market Risk. Preprocesamiento y gestión de datos en el Data Lake (SCIB). Colaboración con el equipo para tareas comunes del área de Big Data. Aplicación de buenas prácticas de desarrollo y documentación de procesos.  Requisitos OBLIGATORIOS Experiencia previa en proyectos tecnológicos, preferentemente de datos o analítica. Conocimiento técnico y experiencia en Scala y Apache Spark. Conocimiento de Hadoop. Manejo de sentencias SQL. Conocimiento básico de Shell scripting. Conocimiento básico de Kibana y del entorno ELK (Elasticsearch, Logstash, Kibana).  Requisitos DESEABLES (no obligatorios) Conocimiento técnico de Azure Databricks. Experiencia previa en sector bancario o en Riesgos de Mercado. Conocimiento de Airflow como gestor de workflows/pipelines.  Condiciones Ubicación: Preferencia por ciudades donde tengamos sedes; posibilidad de valorar perfiles deslocalizados. Tarifa: Se definirá según experiencia y conocimientos. Inglés: Nivel B2 requerido.",https://www.tecnoempleo.com/big-data-engineer-spark-scala-elk-krell-consulting/apache-spark-hadoop/rf-5ade1ec8920d0367cb41,Tecnoempleo,2026-01-20
Data Architect,"Descripción de la oferta de empleo  Role Description: Data Architect – Datamarts & Dashboards MVP Location: Netherlands Dutch is a preferred but not necessary  Key Responsibilities 1. Integration of Internal and External Data 1. Responsible for onboarding and integrating internal and external data onto the data platform. 2. Ensure interoperability with System Integrations. 2. Data Modeling & Preparation According to Standards 1. Structure data into standardized data models and datamarts to enable dashboard development. 2. Ensure consistency, quality, and alignment with enterprise data standards. 3. Access Management Standardization 1. Define and implement a technical standard for access management, aligned with the organization’s IAM (Identity & Access Management) framework. 2. Facilitate secure and controlled access to data assets. 4. Reduction of Technical Impediments 1. Proactively identify and resolve technical bottlenecks to enable TDA dashboard development. 2. Aim to meet a 95% service level for business operations dashboards.  Required Qualifications 1. DP-700: Microsoft Fabric Data Engineer certification 2. DP-600: Microsoft Fabric Analytics Engineer certification 3. At least 2 years of experience integrating diverse data sources for consolidated reporting/dashboarding 4. At least 2 years of hands-on experience with Azure and Microsoft Fabric  Preferred Qualifications 1. Knowledge of and experience with Azure DevOps, including CI/CD pipelines 2. Familiarity with IAM and RBAC (Role-Based Access Control) 3. Proven experience working in Agile teams",https://www.tecnoempleo.com/data-architect-axiom-software-solutions/azure/rf-9cb8109662aeb3b9354e,Tecnoempleo,2026-01-20
Senior Data Scientist Credit Modelling,"Descripción de la oferta de empleo  GROUP BNP PARIBAS  BNP Paribas Group is the top bank in the European Union and a major international banking establishment. It has close to 185,000 employees in 65 countries. In Spain we are more than 5,100 employees within 13 business lines.  RISK HUB  RISK is an integrated and independent control function of the BNP Paribas Group. It is the second line of defense on the risk management activities of the Group which are under its direct responsibilities, including credit and counterparty risk, market risk, funding and liquidity risk, interest rate and foreign exchange risks in the banking book, insurance risk, operational risk, and environmental and social risks.  RISK aims at being a partner of the businesses by contributing to their sustainable development, but also a gatekeeper to ensure risks taken remain compatible with the Group´s Risk Appetite and its strategy.  RISK Iberian Hub Madrid is a transversal platform servicing the RISK Function by covering added-value activities around credit risk, market risk, operational risk and data protection. Offering a wide range of services to RISK teams, from consulting to cyber security going through data analysis, modelling or artificial intelligence.  ABOUT THE JOB  Want to help shape the bank of tomorrow today?  How can the Bank leverage data to assess credit risk on its portfolio of existing and new clients  Risk assessment encompasses various elements: how likely is it that a client will not be able to comply with the contractual requirements of his loan? What will be the client´s outstanding balance in this situation? What loss is the bank expected to suffer if a client is no longer able to repay a loan?  As a member of the RISK Models team, you will join a team of experts whose goal is to answer these questions through the development of statistical or expert models.  By analysing historical data, working together with the business lines, IT department, the modelling experts at BNP Paribas group and taking into account the remarks of supervisor representatives, the team creates tools that help the bank calculate the capital requirements for its credit exposure, the risk component of the credit price or that contribute to the approval process of a new credit.  RESPONSIBILITIES  Your personal tasks will be:  • Designing and developing models for credit risk on the scope mainly of companies  • Finding, managing and using the most appropriate data sources for modelling purposes  • Working with expert colleagues and business representatives to examine the results and keep models grounded in reality  • Documenting each step of the development and informing decision makers by presenting them options and results  • Ensuring correct implementation of the tools (together with the IT department)  • Continuously assessing models by means of back-testing  • Answering specific, external requests regarding statistics related to credit risk assessment  • Following-up evolutions in the regulation and in credit risk modelling best-practices  REQUIREMENTS  - Studies  • Master degree or higher in Mathematics, Economy or Econometrics, Statistics or a similar background where analytics and figures prevail.  - Experience  • Work experience of at least 5 years in credit risk modelling (PD/LGD/LGDD/CCF).  - Languages  • You express yourself perfectly in English, in particular in the writing form. You ideally speak French fluently.  SKILLS  - Technical  • You have strong SAS programming skills.  • It is considered an asset if you have some experience with Big Data technologies, ratings & scorings use across the bank or credit products.  - Transversal & Behavioral  • You are able to manage long-term deadlines and plan your work accordingly. • You are creative, you pay attention to details, and you are able to work easily with both technical and business-oriented people.  BENEFITS  • Training programs, career plans and internal mobility opportunities, national and international thanks to our presence in different countries.  • Diversity and Inclusion Committee that ensures an inclusive work environment. In recent years, several employee communities have been created to organize diversity and inclusion awareness actions (PRIDE, We Generations and MixCity).  • Corporate volunteering program (1 Million Hours 2 Help) in which employees can dedicate time out of their working hours to volunteer activities.  • Flexible compensation plan.  • Hybrid telecommuting model (50%).  • 32 vacation days.  Diversity and inclusion commitment  BNPParibas Group in Spain is an equal opportunity employer and proud to provide equal employment opportunity to all job seekers. We are actively committed to ensuring that no individual is discriminated against on the grounds of age, disability, gender reassignment, marriage or civil partnership status, pregnancy and maternity/paternity, race, religion or belief, sex or sexual orientation. Equity and diversity are at the core of our recruitment policy because we believe that they foster creativity and efficiency, which in turn increase performance and productivity. We strive to reflect the society we live in, while keeping with the image of our clients.",https://www.tecnoempleo.com/senior-data-scientist-credit-modelling-bnp-paribas/data/rf-f9e8186fd2854351874a,Tecnoempleo,2026-01-20
Enterprise Architect Data,"Descripción de la oferta de empleo  ACCENTURE STRATEGY & CONSULTING  Join Accenture Strategy & Consulting and you´ll work alongside fellow industry experts to lead transformational projects, and define cutting edge solutions, solving our client´s most complex issues. And because our clients span the full range of industries - Including 94 of the Fortune 100 - you´ll have the opportunity to pursue your passion, hone your expertise and deepen your knowledge.  As a Strategy & Consulting practitioner you´ll shape the future of top global companies. By joining Accenture, you will embark on a fast-paced career that will allow you to utilise your deep industry experience and specialised skills to design, sell and lead industry defining transformation programs. In this role you´ll use your expertise to drive opportunity-for the company and for yourself-while maintaining the flexibility you need to keep your career ahead of the curve.  EUROPE TECHNOLOGY STRATEGY & ADVISORY TEAM  Are you ready to join our European Technology Strategy & Advisory team to transform how businesses connect with their customers? Our clients are major European multinationals who operate globally and rank highly in the world´s top stock exchanges. They are transforming their business to cope with the new realities and ever evolving market conditions, investing on innovative and cutting-edge technologies to grow and stay ahead of the curve, and rely on our help and support to ensure that these come into fruition and produce the expected returns.  We work at the intersection of business and technology across industries, from Consumer Goods & Services, to Aerospace & Defense, Automotive, Banking, High Tech, Life Sciences, Retail and everything in between. We are a team of highly customer-centric, motivated, skilled and experienced architects devoted to the definition, design, orchestration and delivery of world-class technology strategies and best-of-breed architectures to our clients, ensuring that these underpin their transformational business objectives and exceed their expectations. These often span across multiple business capabilities, from Sales & Commercial, Supply Chain, Finance, Marketing or Human Resources, to Research and Product Development.  Technology-wise, we specialise in ""the New Architectures"": Cloud, Big Data and Analytics, Artificial Intelligence in all of its flavours (Robotics Process Automation, Machine Learning, Deep Learning, etc. ), Internet of Things, Distributed Ledgers, Microservices and Containers, Serverless Architectures, Digital Decoupling, etc., leveraging Design Thinking and Agile methodologies to quickly deliver value to our clients. We operate across Europe: ASGR (Austria, Switzerland, Germany, Russia and Turkey), Gallia (France, Belgium, Luxembourg, Netherlands, Mauritius and Morocco), Iberia (Spain, Portugal and Israel), ICEG (Italy, Central Europe and Greece), Nordics (Denmark, Finland, Latvia, Norway and Sweden) and UKI (United Kingdom and Republic of Ireland).  Due to increased demand from our clients, we are seeking to recruit an Enterprise Architect  YOUR ROLE  As a Enterprise Architect you´ll often: - Design and maintain enterprise architecture aligned with organizational strategy. - Evaluate and select integrated technologies and solutions. - Lead enterprise architecture projects and collaborate with multidisciplinary teams. - Document and communicate the architecture to stakeholders. - Establish architecture policies and standards, ensuring regulatory compliance.  YOUR EXPERIENCE:  You will have experience with most of the following: - Bachelor´s degree in computer science, engineering, business administration, or a related field. - Previous experience in enterprise architecture, software development, or project management. - Knowledge of information technologies and development methodologies. - Analytical, communication, and leadership skills. - Ability to align architecture with organizational strategy and anticipate technological trends.  OUR COMMITMENT TO YOU - We offer a transparent approach career progression, with a focus on your strengths and continuous coaching from senior colleagues. - You´ll benefit from working alongside Accenture experts who are solving some of the biggest industry challenges with innovative thinking and cutting-edge tools. Flexible work arrangements and a range of benefits. - You´ll have access to leading-edge technology that will give you the opportunity to deepen your existing skills even as you help create the latest business trends. - Competitive rewards linked to fast-paced progression. - You´ll also have opportunities to make a difference to the communities in which we work and live.  About Accenture Accenture is a leading global professional services company that helps the world´s leading organizations build their digital core, optimize their operations, accelerate revenue growth and enhance services-creating tangible value at speed and scale. We are a talent- and innovation-led company with 774,000 people serving clients in more than 120 countries. Technology is at the core of change today, and we are one of the world´s leaders in helping drive that change, with strong ecosystem relationships. We combine our strength in technology and leadership in cloud, data and AI with unmatched industry experience, functional expertise and global delivery capability. Our broad range of services, solutions and assets across Strategy & Consulting, Technology, Operations, Industry X and Song, together with our culture of shared success and commitment to creating 360° value, enable us to help our clients reinvent and build trusted, lasting relationships. We measure our success by the 360° value we create for our clients, each other, our shareholders, partners and communities.   Todas las decisiones de empleo se tomarán sin importar la edad, raza, credo, color, religión, sexo, origen nacional, ascendencia, grado de discapacidad, estado de veterano, orientación sexual, identidad o expresión de género, información genética, estado civil, estado de ciudadanía o cualquier otro motivo o circunstancias protegidas por las leyes federales, estatales o locales.",https://www.tecnoempleo.com/enterprise-architect-data-barcelona/data/rf-2be910c8b2f9232aea42,Tecnoempleo,2026-01-20
Senior Data Engineer,"Descripción de la oferta de empleo  The Company  Wizeline is a global digital services company helping mid-size to Fortune 500 companies build, scale, and deliver high-quality digital products and services. We thrive in solving our customer´s challenges through human-centered experiences, digital core modernization, and intelligence everywhere (AI/ML and data). We help them succeed in building digital capabilities that bring technology to the core of their business. Are You a Fit?  Sounds awesome, right? Now, let´s make sure you´re a good fit for the role. Must-have Skills - Have stronger background in software engineering, testing and general software development lifecycle - Proficiency in Python for data processing and analysis. - Experience with Databricks for large-scale data processing. - CI/CD pipelines, ideally using Azure DevOps. - Version control with Git. - Cloud computing, with a focus on Microsoft Azure. - SQL for database interactions and data transformation  Nice to have Skills - NET (C#) development. - Experience with Azure Data Lake. - Kubernetes for container orchestration. - Monitoring and alerting systems. - Infrastructure as Code (e.g., Terraform). - Knowledge of financial or FinTech domains, particularly in regulatory reporting  About us  Wizeline prioritizes a culture of diversity and development for its nearly 2,000 person team spread across the globe. We believe great technology comes from a mix of talents and perspectives. Our core values of ownership, innovation and community are central to our work. Wizeline is invested in its employees´ growth, offering opportunities to create personalized career paths and develop in-demand skills. To help you reach your goals, we have access to LinkedIn Learning and Pluralsight, two top-tier platforms filled with high-quality content. Apply now!",https://www.tecnoempleo.com/senior-data-engineer-wizeline/python-databricks/rf-dc3e17bde2bf1319e840,Tecnoempleo,2026-01-20
Data Engineer - Big Data,"Descripción de la oferta de empleo  En AKKODIS buscamos dos Data Engineers especializados en Big Data para unirse a nuestro equipo. Ambos perfiles trabajarán en un entorno de teletrabajo 100% y estarán involucrados en la migración y optimización de soluciones de procesamiento de datos.  La incorporación es inmediata y el periodo de cobertura del servicio será de alrededor de 6 meses, por lo que si eres autónomo/freelance y buscas un nuevo proyecto, esta es tu oportunidad!!  Requisitos Generales para Ambos Perfiles:  -Experiencia mínima de 2 años en ingeniería de datos.  -Capacidad para trabajar de manera efectiva en entornos ágiles, con un enfoque en entregas continuas y rápidas.  -Habilidades de comunicación efectiva para interactuar con stakeholders técnicos y no técnicos.  -Capacidad de resolución de problemas y optimización de procesos en entornos distribuidos.  -Dominio de herramientas y frameworks relacionados con el procesamiento de datos.  -Experiencia con herramientas de integración continua (CI/CD) y manejo de versiones (Git).  -Disponibilidad para trabajar de lunes a viernes, 8 horas diarias.  Perfil 1: Data Engineer - Big Data (Migración a Databricks)  Responsabilidades:  Migración de jobs y workflows de Cloudera a Databricks, asegurando su funcionalidad, rendimiento y eficiencia.  -Análisis y optimización de procesos de datos existentes. Colaboración con los responsables de las distintas iniciativas a migrar para comprender el estado actual (As Is) y las necesidades del futuro (To Be).  -Revisión, refactorización y reestructuración de scripts de procesamiento de datos, si fuera necesario.  Requisitos Específicos:  -Experiencia demostrable en Databricks, especialmente en optimización de procesos.  -Conocimiento avanzado de Apache Spark y Scala sobre Databricks.  -Experiencia previa en la migración de jobs de Cloudera a plataformas basadas en Spark, preferiblemente a Databricks.  Perfil 2: Data Engineer - Big Data (Procesamiento en Tiempo Real)  Responsabilidades:  -Construcción de arquitecturas escalables y robustas que gestionen grandes volúmenes de datos a través de flujos de eventos y plataformas de procesamiento en tiempo real.  Requisitos Específicos:  -Mínimo 2 años de experiencia en ingeniería de datos, con un fuerte enfoque en Java y soluciones de procesamiento de eventos.  -Profunda experiencia trabajando con Confluent Kafka, idealmente en entornos productivos a gran escala.  -Conocimiento profundo de arquitecturas de microservicios y patrones de integración con Kafka.  -Experiencia en el desarrollo de pipelines de datos (streaming y batch processing).  -Buen entendimiento de las mejores prácticas de diseño, pruebas y optimización de código en Java.  Ambos perfiles son fundamentales para el éxito de nuestras iniciativas de Big Data y se espera que contribuyan de manera significativa al desarrollo y optimización de nuestras soluciones de procesamiento de datos.",https://www.tecnoempleo.com/data-engineer-big-data-akkodis/databricks-spark-scala/rf-cb90142e227e3389d748,Tecnoempleo,2026-01-20
Data Engineer - Big Data,"Descripción de la oferta de empleo  En AKKODIS buscamos dos Data Engineers especializados en Big Data para unirse a nuestro equipo. Ambos perfiles trabajarán en un entorno de teletrabajo 100%y estarán involucrados en la migración y optimización de soluciones de procesamiento de datos.  La incorporación es inmediata y el periodo de cobertura del servicio será de alrededor de 6 meses, por lo que si eres autónomo/freelance y buscas un nuevo proyecto, esta es tu oportunidad!!  Requisitos Generales para Ambos Perfiles:  -Experiencia mínima de 2 años en ingeniería de datos.  -Capacidad para trabajar de manera efectiva en entornos ágiles, con un enfoque en entregas continuas y rápidas.  -Habilidades de comunicación efectiva para interactuar con stakeholders técnicos y no técnicos.  -Capacidad de resolución de problemas y optimización de procesos en entornos distribuidos.  -Dominio de herramientas y frameworks relacionados con el procesamiento de datos.  -Experiencia con herramientas de integración continua (CI/CD) y manejo de versiones (Git).  -Disponibilidad para trabajar de lunes a viernes, 8 horas diarias.  Perfil 1: Data Engineer - Big Data (Migración a Databricks)  Responsabilidades:  Migración de jobs y workflows de Cloudera a Databricks, asegurando su funcionalidad, rendimiento y eficiencia.  -Análisis y optimización de procesos de datos existentes.Colaboración con los responsables de las distintas iniciativas a migrar para comprender el estado actual (As Is) y las necesidades del futuro (To Be).  -Revisión, refactorización y reestructuración de scripts de procesamiento de datos, si fuera necesario.  Requisitos Específicos:  -Experiencia demostrable en Databricks, especialmente en optimización de procesos.  -Conocimiento avanzado de Apache Spark y Scala sobre Databricks.  -Experiencia previa en la migración de jobs de Cloudera a plataformas basadas en Spark, preferiblemente a Databricks.  Perfil 2: Data Engineer - Big Data (Procesamiento en Tiempo Real)  Responsabilidades:  -Construcción de arquitecturas escalables y robustas que gestionen grandes volúmenes de datos a través de flujos de eventos y plataformas de procesamiento en tiempo real.  Requisitos Específicos:  -Mínimo 2 años de experiencia en ingeniería de datos, con un fuerte enfoque en Java y soluciones de procesamiento de eventos.  -Profunda experiencia trabajando con Confluent Kafka, idealmente en entornos productivos a gran escala.  -Conocimiento profundo de arquitecturas de microservicios y patrones de integración con Kafka.  -Experiencia en el desarrollo de pipelines de datos (streaming y batch processing).  -Buen entendimiento de las mejores prácticas de diseño, pruebas y optimización de código en Java.  Ambos perfiles son fundamentales para el éxito de nuestras iniciativas de Big Data y se espera que contribuyan de manera significativa al desarrollo y optimización de nuestras soluciones de procesamiento de datos.  Business Industry  Digital  Profile  Position location  Job location  Europe, Spain  Location  Remoto  Telework  Full-time  Candidate criteria  Level of experience  All levels of experience",https://www.tecnoempleo.com/data-engineer-big-data-akkodis/databricks-spark/rf-f2071587e27843a81d49,Tecnoempleo,2026-01-20
Data Architect,"Descripción de la oferta de empleo  Job Role: Data Architect Duration: B2B - 6+ Months Contract (rolling contract) Location: Leeds, UK Work Mode: Hybrid - should be able to be in the office once every 2/3 weeks.  Job Description: Architect who has worked on Databricks platform with GCP experience. They need to be having Admin mention on the cv as well.  Benefits: Job Role: Data Architect Duration: B2B - 6+ Months Contract (rolling contract) Location: Leeds, UK Work Mode: Hybrid - should be able to be in the office once every 2/3 weeks.  Job Description: Architect who has worked on Databricks platform with GCP experience. They need to be having Admin mention on the cv as well.",https://www.tecnoempleo.com/data-architect-axiom-software-solutions/data-gcp/rf-547911e3f23a338b6242,Tecnoempleo,2026-01-20
Data acquisition lead,"Descripción de la oferta de empleo  Data Acquisition Lead Location: Stockholm, Sweden (Hybrid) Duration: 6-12 months Rate: Open for the right candidate  • Plan and drive the Data Acquisition epic to establish a common Data Acquisition capability that can serve the new data product ways of working • Perform analysis & run workshops together with appointed architect to define target state and transition plan for Data Acquisition • Close collaboration, coordination and requirements to Infra ART to ensure implementation of infrastructure components in accordance with Data Acquisition framework and data architecture • Gather requirements and select first pilot for Data Acquisition • Drive and facilitate RFP analysis • Close collaboration with Platform Modernisation team to ensure alignment of activities, timelines and dependencies",https://www.tecnoempleo.com/data-acquisition-lead-axiom-software-solutions/data/rf-5ab41aeed2abd3c74540,Tecnoempleo,2026-01-20
Data and AI Regulatory Intelligence,"Descripción de la oferta de empleo  Position: Data and AI Regulatory Intelligence Expert Location: Barcelona, Spain (Hybrid 2 days onsite a week) Duration: Long Term Contract  Job Description: • Advise on and support AZ Regulatory intelligence tool implementation, e.g. scope, mapping of requirements, approach • Define and document AZ Enterprise Data and AI Regulatory Intelligence Framework to include: • Op Model for Regulatory Intelligence capability services and consumer groups • Clear roles & accountabilities • Regulatory change impact risk scoring matrix • Align functional regulatory change impact template and map functional requirements to a single enterprise impact regulatory change assessment template for Regulatory Intelligence • Establish regular framework feedback cadence from stakeholders to Regulatory Intelligence • Review horizon scanning processes and make recommendations for centralised process. • Regulatory interpretation and guidance on mandatory requirements • Adherence to compliance monitoring and enforcement with regards to regulatory change processes and procedures • AI and Privacy regulatory knowledge required",https://www.tecnoempleo.com/data-and-ai-regulatory-intelligence-axiom-software/data/rf-134e1209222c23c1cd46,Tecnoempleo,2026-01-20
Pharma Data and AI Regulatory Expert,"Descripción de la oferta de empleo  Pharmaceutical Data and AI Regulatory Intelligence expert. Barcelona based. Target Start: Early May. • Advise on and support AZ Regulatory intelligence tool implementation, e.g. scope, mapping of requirements, approach • Define and document AZ Enterprise Data and AI Regulatory Intelligence Framework to include: • Op Model for Regulatory Intelligence capability services and consumer groups • Clear roles & accountabilities • Regulatory change impact risk scoring matrix • Align functional regulatory change impact template and map functional requirements to a single enterprise impact regulatory change assessment template for Regulatory Intelligence • Establish regular framework feedback cadence from stakeholders to Regulatory Intelligence • Review horizon scanning processes and make recommendations for centralised process. • Regulatory interpretation and guidance on mandatory requirements • Adherence to compliance monitoring and enforcement with regards to regulatory change processes and procedures • AI and Privacy regulatory knowledge required",https://www.tecnoempleo.com/pharma-data-and-ai-regulatory-expert-axiom-softwar/data-ai/rf-b41b1b74724ac38d6c49,Tecnoempleo,2026-01-20
Data Analyst,"Descripción de la oferta de empleo  Join Plexus Tech. We´re looking for a Data Analyst to join us on a major project in the banking sector.  Requirements:  - Analysis and documentation of functional process flows - Identification and documentation of all data used, i.e., inputs, outputs, transformations, and data flows, in EUCs (end user computing), reports, forums, and committees. - Design/document the process to be performed - Create BRDs and technical specifications for the datasets to be implemented, including specification of transformations/mappings and integration with BI tools. - Simplify and automate the data used in the process and report creation. - Technical testing to ensure code meets requirements and manage the UAT process, ensuring all issues are resolved.  With our hybrid model, Flexology lets you work wherever your talent flows best: from any of our 24 work centers in Spain, from home, or a combination of both. The Plexus Tech work ecosystem allows for a collaborative environment within the company.  Work with leading professionals  Access to ongoing training  Career advancement  Flexible compensation for health insurance, meal vouchers, childcare, and transportation",https://www.tecnoempleo.com/data-analyst-plexus/bi/rf-18311a0052639359a441,Tecnoempleo,2026-01-20
Data Engineer with Snowflake,"Descripción de la oferta de empleo  At DAC.digital, we are constantly growing our business. As part of our growth strategy, we are starting a strategic partnership with one of the biggest consulting companies in Germany with a strong focus on Data Management. Their clients include major banking, insurance, retail, telecommunications, and automotive brands.  Key information: Salary: - 4 000 – 5 000 EUR net/month – pure B2B contract  You will be responsible for supporting our team in: - managing and supporting Application Management Services (AMS), including the maintenance and operation of applications in the production environment; - assisting with the ongoing development of projects, ensuring seamless integration and smooth transitions from - development to production stages; - providing operational support for existing applications, ensuring their stability and performance; - collaborating with cross-functional teams to identify and address issues related to the application lifecycle; - contributing to continuous improvement initiatives in application management and development processes.  Technology stack: - Snowflake - dbt - Git - Modelling - Data Management  It is vital that you have: - solid experience with Snowflake and dbt; - knowledge of English (min. B2) - working in agile methodologies (Scrum, Kanban); - good communication skills; - eager to learn and share knowledge; - willing to travel if necessary (conferences, coworking events, etc.)",https://www.tecnoempleo.com/data-engineer-with-snowflake-dacdigital/snowflake-git-agile-data-managemen/rf-dd0a133a32934329774c,Tecnoempleo,2026-01-20
DBA Oracle Exadata OCI,"Descripción de la oferta de empleo  Porque trabajar en Sopra Steria, también es sentir Sopra Steria.  Somos un reconocido líder europeo en consultoría, servicios digitales y desarrollo de software, con cerca de 56.000 empleados en casi 30 países y más de 4.000 en España. Nos enfocamos en las personas, en su formación y desarrollo profesional, lo que nos impulsa a crecer y mejorar constantemente.  Tenemos pasión por lo digital y al igual que tú, buscamos la mejor de las aventuras. Queremos que tu día a día se convierta en la mejor de tus inspiraciones. Que aprendas, aportes, te diviertas, crezcas y que, sobre todo, disfrutes al máximo.  Si quieres formar parte de un equipo ""Great Place to Work"", ¡Sigue leyendo!  Descripción del empleo  ¿Qué reto proponemos? Buscamos un perfil de experto en bases de datos Oracle con experiencia en Exadata y arquitectura OCI (Oracle Cloud Infrastructure) para importante proyecto del sector telecomunicaciones.  Requisitos  ¿Qué buscamos?  Necesaria experiencia en: - Despliegue de Oracle Exadata en arquitecturas OCI (Oracle Cloud Infrastructure) - Virtualización en entornos Oracle Exadata - PDB y CDB - Exadata Virtual Clusters - Parametrización de Oracle Data Guard - Configuración avanzada de Exadata en entornos OCI: implementación de políticas de seguridad, configuración de scripts de autoescalado, virtual cluster networks, Dynamic Routing Networks, configuración de almacenamiento (volúmenes NFS, ACFS)  Información adicional  ¿Qué tenemos para ti? - Contrato indefinido y jornada completa - 23 días de vacaciones - Formación continua: competencias técnicas, transversales y de idiomas. Contamos con acceso a certificaciones, formaciones de los principales Partners Tecnológicos, plataformas online y ¡mucho más! - Seguro de vida y de accidentes - Posibilidad de acogerte a nuestra retribución flexible (seguro médico, cheques guarderías, transporte, comida y formación) - Acceso a Privilege Club, donde encontrarás descuentos interesantes en las principales marcas - Onboarding personalizado y detallado. Te acompañamos en todo momento para que te sientas #soprano desde el primer momento. - Oficina con espacios reservados al ocio. ¡Trabajo y diversión unido! - Compañerismo y buen ambiente, el poder de la unión lo tenemos presente.  Y lo más importante...Tienes la posibilidad de desarrollar tu carrera profesional con nosotros: Crearemos juntos un plan de carrera personalizado. Te formarás, marcaremos objetivos y llevaremos a cabo un seguimiento para asegurarnos de que lo conseguimos juntos. Escuchamos tus prioridades y luchamos por ellas.  ¡Aquí tu voz importa! ¡Únete a nosotros y sé parte de algo más!  The world is how we shape it",https://www.tecnoempleo.com/dba-oracle-exadata-oci-sopra-steria/oracle/rf-bcc91fc46217435e1a44,Tecnoempleo,2026-01-20
Data Engineers - Talent Community,"Descripción de la oferta de empleo  Are you passionate about data, cloud technologies, and building impactful digital solutions?  At BASF Digital Hub Madrid, we´re shaping the future of the chemical industry through innovation, creativity, and collaboration. As we continue to grow, we´re building a talent pipeline for Data Engineers who want to make a difference.  WHY JOIN OUR TALENT COMMUNITY?  We frequently open roles for professionals with strong technical skills and a digital mindset, and we´re always eager to connect with individuals who thrive in collaborative, international environments where creativity and continuous improvement are part of the culture.  WE´RE ESPECIALLY INTERESTED IN PROFILES WITH EXPERIENCE IN:  - Bachelor´s or master´s degree in Computer Science, Engineering, or a related field. - Experience in cloud-based Data warehousing and/or Data Engineering (Azure). - Strong knowledge of Python and SQL. (Power Apps). - Knowledge of Databricks and Databricks Unity Catalog. - Design & Implementation of ETL / ELT data pipelines - Customer-focused with excellent communication and teamwork skills.  WHAT WE OFFER  - A secure work environment because your health, safety and wellbeing is always our top priority. - Flexible work schedule and Home-office options, so that you can balance your working life and private life. - Learning and development opportunities - 23 holiday days per year - 5 additional days (readjustment) - 2 cultural days - A collaborative, trustful and innovative work environment - Being part of an international team and work in global projects - Relocation assistance to Madrid provided  Diversity is our greatest strength!  Become a part of our winning formula for success and develop the future with us -- in a global team that embraces inclusion and equal opportunities irrespective of gender, age, origin, sexual orientation, disability or belief.  Even if there´s no open role today, we´d love to hear from you. Join our talent community and be the first to know when new opportunities arise.  A unique total offer: you@BASF  At BASF you get more than just compensation. Our total offer includes a wide range of elements you need to be your best in every stage of your life. That´s what we call you@BASF. Click here to learn more.  A unique total offer: you@BASF  At BASF you get more than just compensation. Our total offer includes a wide range of elements you need to be your best in every stage of your life. That´s what we call you@BASF. Click here to learn more.  Discover the world of BASF and develop data solutions for the Chemistry 4.0 era - for a sustainable future. Help drive the digital transformation of the chemical industry by harnessing the potential of the latest data science technologies and data sources.",https://www.tecnoempleo.com/data-engineers-talent-community-basf/python-sql/rf-f5f71e8912699308d04d,Tecnoempleo,2026-01-20
Data Engineer,"Descripción de la oferta de empleo  Desarrollar soluciones utilizando Python con enfoque funcional para manejo de datos. Experiencia sólida en bases de datos relacionales y SQL. Creación y mantenimiento de pipelines de datos utilizando REST y SOAP APIs. Experiencia en control de versiones utilizando Git y CI/CD con enfoque multi-rama, Exposición a DBT será altamente valorada.",https://www.tecnoempleo.com/data-engineer-madrid/data-python-sql/rf-77741861e277032bea49,Tecnoempleo,2026-01-20
Senior Data Engineer,"Descripción de la oferta de empleo  Somos un reconocido líder europeo en consultoría, servicios digitales y desarrollo de software, con cerca de 56.000 empleados en casi 30 países y más de 4.000 en España. Nos enfocamos en las personas, en su formación y desarrollo profesional, lo que nos impulsa a crecer y mejorar constantemente.  Tenemos pasión por lo digital y al igual que tú, buscamos la mejor de las aventuras. Queremos que tu día a día se convierta en la mejor de tus inspiraciones. Que aprendas, aportes, te diviertas, crezcas y que, sobre todo, disfrutes al máximo.  Si quieres formar parte de un equipo ""Great Place to Work"", ¡Sigue leyendo!  Descripción del empleo  • Análisis y definición end-to-end de proyectos a implementar en la PTD, desde el punto de vista de la definición y gobernanza de los datos hasta la solución técnica y los informes de visualización.  o Conexión a sistemas externos  o ETLs  o Manipulación de datos  o Integración Datalakehouse  o Automatización workflows  o Monitorización y mantenimiento  o Visualización informes  • Interlocución con la Oficina de la PTD, proveedores y unidades de negocio.  • Soporte técnico a proveedores para la implementación de proyectos con la PTD y, en el caso de proyectos Área TIC, implementación de los mismos.  • Seguimiento y reporting de los proyectos en curso.  • Colaboración en la definición/implementación del Catálogo de Datos del Departamento (fuera de la PTD).""  Requisitos  * Se requiere un perfil técnico del dato con experiencia en databriks; trabajará junto al Arquitecto del proyecto para nutrir la PTD que se ha desarrollado de manera centralizada desde el proyecto.  * Se requiere buenas softkills porque tendrá que interactuar con director@s de las áreas  - Catalán.  Información adicional  ¿Qué tenemos para ti? - Contrato indefinido y jornada completa - 23 días de vacaciones - Formación continua: competencias técnicas, transversales y de idiomas. Contamos con acceso a certificaciones, formaciones de los principales Partners Tecnológicos, plataformas online y ¡mucho más! - Seguro de vida y de accidentes - Posibilidad de acogerte a nuestra retribución flexible (seguro médico, cheques guarderías, transporte, comida y formación) - Acceso a Privilege Club, donde encontrarás descuentos interesantes en las principales marcas - Onboarding personalizado y detallado. Te acompañamos en todo momento para que te sientas #soprano desde el primer momento. - Oficina con espacios reservados al ocio. ¡Trabajo y diversión unido! - Compañerismo y buen ambiente, el poder de la unión lo tenemos presente.  Y lo más importante...Tienes la posibilidad de desarrollar tu carrera profesional con nosotros: Crearemos juntos un plan de carrera personalizado. Te formarás, marcaremos objetivos y llevaremos a cabo un seguimiento para asegurarnos de que lo conseguimos juntos. Escuchamos tus prioridades y luchamos por ellas.  ¡Aquí tu voz importa! ¡Únete a nosotros y sé parte de algo más!",https://www.tecnoempleo.com/senior-data-engineer-sopra-steria/etl-datalakehouse/rf-3cc51df8227023bdfe45,Tecnoempleo,2026-01-20
Senior Data Engineer,"Descripción de la oferta de empleo  Data Engineer  As a Data Engineer you will oversee data ingestion processes and deployment of ML/IA solutions for predictive analysis for an energy sector customer. You will collaborate with Data Scientist and Data Engineers to achieve project and client goals on a very dynamic environment.  The opportunity  As a member of our team in GDS office in Malaga, Spain, you´ll have a chance to extend your knowledge & experience by working on the interesting projects with the newest technologies and approaches. You´ll support clients in choosing the most suitable business solution and take part in digital transformation.  Your key responsibilities  As a Data Engineer, you will work on the design of end-to-end pipelines for enterprise data loading from different sources, deployment of ML/IA solutions for predictive analysis and improvements on quality of data.  You will also collaborate with the product development teams (business analysts, product owners, developers) to deliver high quality solutions for our customers.  To qualify for the role, you must have - Degree on Statistics, Maths, Informatics or similar. - 3-4 years of experience as Data Engineer - Experience in Azure: Databricks, DataFactory, Synapse - Database knowledge, SQL, OLTP/OLAP - Experience of Big Data (i.e Spark, Hadoop) - Very good communication skills in terms of capturing requirements, describing architecture, data flows, etc.  Ideally, you´ll also have - Knowledge of cloud solutions - Experience on Agile and SCRUM methodology.  What we look for  We are a dynamic team of passionate specialists, working in international teams all over the world. As part of the Data team, we look for ""out of the box thinking"" professionals that will build good relationships with our clients. If you want to be a part of this journey, we are looking forward to seeing you on board!  What we offer  EY Global Delivery Services (GDS) is a dynamic and truly global delivery network. We work across eight locations - Argentina, China, India, Philippines, Poland, UK, Hungary and Spain - and with teams from all EY service lines, geographies and sectors, playing a vital role in the delivery of the EY growth strategy. From accountants to coders to advisory consultants, we offer a wide variety of fulfilling career opportunities that span all business disciplines. In GDS, you will collaborate with EY teams on exciting projects and work with well-known brands from across the globe. We´ll introduce you to an ever-expanding ecosystem of people, learning, skills and insights that will stay with you throughout your career. - Continuous learning:You´ll develop the mindset and skills to navigate whatever comes next. - Success as defined by you: We´ll provide the tools and flexibility, so you can make a meaningful impact, your way. - Transformative leadership: We´ll give you the insights, coaching and confidence to be the leader the world needs. - Diverse and inclusive culture:You´ll be embraced for who you are and empowered to use your voice to help others find theirs.",https://www.tecnoempleo.com/senior-data-engineer-ey/sql-databricks-synapse-spark-hadoop/rf-b82f1f66a2bfa3931949,Tecnoempleo,2026-01-20
Data Tranparency DevOps Engineer,"Descripción de la oferta de empleo  ABOUT US  At BASF Digital Hub Madrid we develop innovative digital solutions for BASF, create new exciting customer experiences and business growth, and drive efficiencies in processes, helping to strengthen BASF´s position as the digital leader in the chemical industry. We believe the right path is through creativity, trial and error and great people working and learning together. Become part of our team and develop the future with us - in a global team that embraces diversity and equal opportunities.  JOIN THE TEAM  As part of BASF´s Data & AI Powerhouse, we as Data Transparency team provide an enterprise-wide Data Catalog solution as single-point of truth to share knowledge about data and to find and access relevant documented data in an efficient, convenient, and compliant way. Our goal is to accelerate business decisions and processes by enabling data citizens to connect data with insights.  As part of an agile team, you will independently drive the development of the Data Catalog to bring transparency into the BASF Data Landscape and enable transfer of metadata across systems.  RESPONSIBILITIES  - You will develop new integration processes to populate the Data Catalog with metadata, using Azure Data Factory, Azure Data Flows and Databricks - You will be responsible for both the design and end-to-end implementation of individual microservices and RESTful APIs as well as ensuring their smooth operation - You will ensure code quality by defining coding conventions and development guidelines, ensuring high test coverage - You will contribute to build a stable and secure infrastructure and develop CI/CD pipelines and test frameworks - Within the team, you will use your experience to support a continuous exchange of knowledge and ensure effective collaboration with our internal stakeholders.  QUALIFICATIONS  - Bachelor´s Degree/Diploma in Computer Science, Software Engineering, or comparable technical education. - Minimum of 3+ years of working experience in backend software development. - Hands-on experience in designing, developing and consuming of web services - RESTful APIs, ideally using frameworks like Django. - Experience in implementing and operating containerized microservices (using docker) in cloud environments. - Experience with data transformation pipelines (ETL), ideally using Azure Data Factory, Data Flows, ADLS, and Databricks. - Experience in implementing BPMN workflows is a plus. - High interest in technical innovation and continuous improvement of existing systems. - Ability to communicate clearly and effectively translating sophisticated concepts into easily-to-understand language. - Agile mindset, proactive approach, good self-organization and teamwork in a remote environment, complemented by a strong customer focus.  BENEFITS  - Responsibility from day one in a challenging work environment and ""on-the-job"" training as part of a committed team. - Adequate compensation according to your qualifications and experience - A secure work environment because your health, safety and wellbeing is always our top priority. - Flexible work schedule and Home-office options, so that you can balance your working life and private life. - Learning and development opportunities - 23 holidays per year - Another 5 days (readjustments days) and 2 days (cultural days) - A collaborative, trustful and innovative work environment - Being part of an international team and work in global projects - Relocation assistance to Madrid provided  At BASF, the chemistry is right.  Because we are counting on innovative solutions, on sustainable actions, and on connected thinking. And on you. Become a part of our formula for success and develop the future with us - in a global team that embraces diversity and equal opportunities irrespective of gender, age, origin, sexual orientation, disability or belief.",https://www.tecnoempleo.com/data-tranparency-devops-engineer-basf/azure-data-factory-azure-data-flows-/rf-7df3142082f483bcc444,Tecnoempleo,2026-01-20
Senior Data Analyst,"Descripción de la oferta de empleo  ´Te imaginas participando en la transformación de las principales organizaciones nacionales e internacionales?  En Deloitte estamos comprometidos con generar un impacto en la sociedad, en nuestros clientes y en ti.  Desde nuestro equipo de Growth estamos buscando personas que se incorporen a nuestra área.  ¿Cuál es el reto?  - Participarás en el desarrollo de la iniciativa Voice of Client desde las distintas vertientes de captura de feedback: entrevistas y encuestas a la capa directiva de los clientes (CSA - Client Service Assessment), encuestas por proyecto finalizado (ER - Engagement Review) y entrevistas a los clientes para conocer los motivos por los que se gana o se pierde un proyecto (Win & Loss Analysis), todo ello de forma alineada con el proceso de planificación comercial de cliente. - Recopilarás y analizarás feedback de los clientes utilizando distintas herramientas de análisis de datos: desde BBDD hasta IA generativa. - Prepararás informes detallados y presentaciones para los socios destacando las áreas de mejora y las oportunidades estratégicas que se han detectado en los clientes. - Colaborarás estrechamente con los socios para entender sus necesidades y proporcionar soluciones basadas en los datos obtenidos. - Desarrollarás y mantendrás sistemas automatizados para el análisis de feedback asegurando la eficiencia y precisión en la recopilación de datos. - Propondrás iniciativas y generarás mejores prácticas de análisis de datos en base a las nuevas tendencias basados en la colaboración con equipos multidisciplinares nacionales e internacionales que sirvan para implementar herramientas de optimización de información. - Brindarás soporte a otros miembros del equipo de Growth en el uso de herramientas de análisis de datos e interpretación de resultados. - Generarás KPIs avanzados y tendencias con la información obtenida de los feedbacks de clientes que será necesario interrelacionar con las distintas dimensiones comerciales: posicionamiento relacional, competidores, equipos internos sectoriales, equipos de cuenta, etc... - Tendrás interlocución con el equipo directivo al más alto nivel de la organización. - Contarás con autonomía en las responsabilidades asignadas y podrás desplegar toda tu creatividad y proactividad para aportar ideas y soluciones en las iniciativas que trabajes, siempre bajo la guía y estándares establecidos por la Firma. - Estarás involucrado no sólo en la gestión, soporte, coordinación y planificación de la iniciativa VoC de la firma española si no también en la interacción con el resto de Firmas de Deloitte Global, participando en proyectos comunes y conectando con otros profesionales de diferentes firmas miembro.  ¿Cómo te imaginamos?  Ante todo, buscamos a alguien con un mínimo de 3 años de experiencia en equipos de análisis de datos y desarrollo comercial.  - Titulación en Administración y Dirección de Empresas, Economía, Data Analytics o similar. - Valoraremos positivamente que hayas cursado estudios de posgrado específicos. - Nivel muy alto de inglés (mínimo C1) y dominio del español. - Conocimiento y agilidad con herramientas de análisis de bases de datos, principalmente Excel. Ser un experto en herramientas del paquete office, además de conocimiento en otras herramientas CRM como por ejemplo Salesforce, etc. Conocimiento en herramientas de IA como usuario - Gran capacidad analítica para la toma de decisiones apoyada en datos (tratamiento, análisis y toma de decisiones). - Ser proactivo e interactuar con la capa directiva y sugerir nuevas ideas que faciliten y mejoren la toma de decisiones. - Tener muchas ganas de aprender, con iniciativa para dar solución al día a día y dar respuesta a las necesidades de los distintos responsables con los que trabajes. - Ser capaz de gestionar de forma eficiente tareas y proyectos al mismo tiempo, priorizando los mismos para cumplir con los plazos de entrega con la calidad exigida. - Habilidad para trabajar en equipo, establecer contactos en un entorno global e intercambiar experiencias.  ¿Cómo es trabajar en Deloitte? Proyectos de alto impacto donde tendrás un largo recorrido y aprendizaje  Un día a día híbrido-flexible: tendrás horario flexible y un buen equilibrio entre el teletrabajo y el trabajo en equipo en nuestras oficinas o las de nuestros clientes  Buen ambiente dentro y fuera de la oficina: disfrutarás de varios teambuildings al año, actividades culturales y deportivas. .. ¡y mucho más!  Bienestar integral: cuídate con nuestro programa de salud física, mental y financiera. .. ¡y con equipo médico en las oficinas!  Impacto social: Podrás apuntarte a una gran cantidad de voluntariados de alcance nacional e internacional y a proyectos pro-bono con los que poner tu tiempo y talento al servicio de quienes más lo necesitan  Cultura del feedback y aprendizaje continuo: crecerás en un entorno inclusivo donde la igualdad de oportunidades y tu plan personalizado de formación impulsarán tu desarrollo. ¿Ya te visualizas en la Deloitte University de París?  Beneficios exclusivos por ser parte de Deloitte: podrás disfrutar de un gran catálogo de beneficios y de un completo plan de retribución flexible  Si te gusta lo que lees, estos son tus próximos pasos: - Aplica a la oferta haciendo clic en ´Enviar candidatura ahora´ y completa tu perfil - Si encajas en el puesto, nuestro equipo de talento te contactará para conocerte mejor  ¡Comienza el proceso! Te iremos guiando por las diferentes fases hasta tu incorporación.  Deloitte es una Firma de servicios profesionales firmemente comprometida con la igualdad de oportunidades. En este sentido, la Firma aceptará y tramitará solicitudes de todos los sectores de la sociedad, no discriminando por motivos de sexo, expresión de género, raza, religión o creencias, origen étnico o nacional, discapacidad, enfermedad o condición de salud, predisposición genética a sufrir patologías, edad, ciudadanía, estado civil, orientación o identidad sexual, situación socioeconómica o cualquier otra condición o circunstancia personal o social.",https://www.tecnoempleo.com/senior-data-analyst-deloitte/data/rf-14ad138fb2620387d54d,Tecnoempleo,2026-01-20
Data Engineer - Fintech,"Descripción de la oferta de empleo  Ebury is a leading global fintech company that empowers businesses to trade and grow internationally. It offers a comprehensive suite of products, including international payments and collections, FX risk management, trade finance, and API integrations. Founded in 2009 by Juan Lobato and Salvador García, Ebury is one of the fastest-growing global fintechs, with over 1,700 employees and 38 offices in more than 25 countries.  Data Engineer - Fintech  Madrid Office - Hybrid: 4 days in the office, 1 day working from home  Join Our Data Team at Ebury Madrid Office.  Ebury´s strategic growth plan would not be possible without our Data team and we are seeking a Data Engineer to join our Data Engineering team!  Our data mission is to develop and maintain Ebury´s Data Warehouse and serve it to the whole company, where Data Scientists, Data Engineers, Analytics Engineers and Data Analysts work collaboratively to: - Build ETLs and data pipelines to serve data in our platform - Provide clean, transformed data ready for analysis and used by our BI tool - Develop department and project specific data models and serve these to teams across the company to drive decision making - Automate end solutions so we can all spend time on high-value analysis rather than running data extracts  What we offer: - Competitive salary and benefits package - Discretionary bonus based on performance - Continued personal development through training and certification - We are Open Source friendly, following Open Source principles in our internal projects and encouraging contributions to external projects  Responsibilities: - Be mentored by one of our outstanding performance team member along a 30/60/90 plan designed only for you - Participate in data modelling reviews and discussions to validate the model´s accuracy, completeness, and alignment with business objectives. - Design, develop, deploy and maintain ELT/ETL data pipelines from a variety of data sources (transactional databases, REST APIs, file-based endpoints). - Serve hands-on delivery of data models using solid software engineering practices (eg. version control, testing, CI/CD) - Manage overall pipeline orchestration using Airflow (hosted in Cloud Composer), as well as execution using GCP hosted services such as Container Registry, Artifact Registry, Cloud Run, Cloud Functions, and GKE. - Work on reducing technical debt by addressing code that is outdated, inefficient, or no longer aligned with best practices or business needs. - Collaborate with team members to reinforce best practices across the platform, encouraging a shared commitment to quality. - Help to implement data governance policies, including data quality standards, data access control, and data classification. - Identify opportunities to optimise and refine existing processes.  About you: - 3+ years of data/analytics engineering experience building, maintaining & optimising data pipelines & ETL processes on big data environments - Proficiency in Python, SQL and Airflow - Knowledge of software engineering practices in data (SDLC, RFC...) - Stay informed about the latest developments and industry standards in Data - Fluency in English  If you´re excited about this job opportunity but your background doesn´t match exactly the requirements in the job description, we strongly encourage you to apply anyway. You may be just the right candidate for this or other positions we have.  #LI-CG1  About Us  Ebury is a FinTech success story, positioned among the fastest-growing international companies in its sector.  Founded in 2009, we are headquartered in London and have more than 1700 staff with a presence in more than 25 countries worldwide. Cultural diversity is part of what makes Ebury a special place to be. From Sao Paulo to Dubai, Bucharest to Toronto, we enjoy sharing team experiences and celebrating success across the Ebury family.",https://www.tecnoempleo.com/data-engineer-fintech-ebury/etl-data-bi/rf-8c8519da622583f98d46,Tecnoempleo,2026-01-20
Data & AI Strategy Consultant,"Descripción de la oferta de empleo  We are looking for a Data & AI Strategy Consultant / Manager to join our Data & AI Strategy Consulting team, specializing in Supply Chain & Operations (SC&O). This role serves as a critical interlock between technical teams and the business, ensuring Data & AI solutions drive real business transformation.  As part of our team, you will help clients translate complex data and AI capabilities into business value, guiding them in the end-to-end design and implementation of AI-driven strategies, from value identification and strategic planning to execution and impact measurement. Additionally, you will play a key role in developing our offering, supporting business development, and contributing to team growth and capability building.  Key Responsibilities  - Lead end-to-end AI projects, from opportunity identification to execution and impact measurement.  - Define and implement Data & AI strategies with a focus on Supply Chain & Operations transformation.  - Translate business challenges into AI-powered solutions requirements, ensuring alignment between technical and business teams.  - Develop business cases and value frameworks to drive adoption and measure ROI..  - Support sales and business development, identifying opportunities and crafting proposals.  - Mentor and develop junior team members, fostering a high-performance culture.  Key Requirements  - Bachelor´s or Master´s degree in Business, Engineering, Data Science, AI, or a related field.  - 3+ years of experience in consulting, data strategy, or AI-driven transformation ideally within Supply Chain & Operations.  - Strong expertise in Data & AI strategy, analytics, and AI-powered decision-making.  - Excellent stakeholder management and communication skills with a strategic mindset.  - Fluency in English is a must (C1 level or higher); additional languages are a plus  Additional Benefits: - Comprehensive insurance (medical, life, and accident). - Wellness programs and medical services. - Flexible compensation programs & stock purchase plans. - Sustainability initiatives & Accenture Foundation programs. - Diversity & inclusion networks in a globally recognized company. - Flexibility programs (customized schedules, extra vacation days, etc.).  If you are excited about leading AI-driven transformations in supply chain, we´d love to hear from you!  About Accenture Accenture is a leading global professional services company that helps the world´s leading organizations build their digital core, optimize their operations, accelerate revenue growth and enhance services-creating tangible value at speed and scale. We are a talent- and innovation-led company with 774,000 people serving clients in more than 120 countries. Technology is at the core of change today, and we are one of the world´s leaders in helping drive that change, with strong ecosystem relationships. We combine our strength in technology and leadership in cloud, data and AI with unmatched industry experience, functional expertise and global delivery capability. Our broad range of services, solutions and assets across Strategy & Consulting, Technology, Operations, Industry X and Song, together with our culture of shared success and commitment to creating 360° value, enable us to help our clients reinvent and build trusted, lasting relationships. We measure our success by the 360° value we create for our clients, each other, our shareholders, partners and communities.   Igualdad de Oportunidades en el Empleo  Todas las decisiones de empleo se tomarán sin importar la edad, raza, credo, color, religión, sexo, origen nacional, ascendencia, grado de discapacidad, estado de veterano, orientación sexual, identidad o expresión de género, información genética, estado civil, estado de ciudadanía o cualquier otro motivo o circunstancias protegidas por las leyes federales, estatales o locales.  About Accenture Accenture is a leading global professional services company that helps the world´s leading organizations build their digital core, optimize their operations, accelerate revenue growth and enhance services-creating tangible value at speed and scale. We are a talent- and innovation-led company with 774,000 people serving clients in more than 120 countries. Technology is at the core of change today, and we are one of the world´s leaders in helping drive that change, with strong ecosystem relationships. We combine our strength in technology and leadership in cloud, data and AI with unmatched industry experience, functional expertise and global delivery capability. Our broad range of services, solutions and assets across Strategy & Consulting, Technology, Operations, Industry X and Song, together with our culture of shared success and commitment to creating 360° value, enable us to help our clients reinvent and build trusted, lasting relationships. We measure our success by the 360° value we create for our clients, each other, our shareholders, partners and communities. Visit us at www. accenture. com  Igualdad de Oportunidades en el Empleo  Todas las decisiones de empleo se tomarán sin importar la edad, raza, credo, color, religión, sexo, origen nacional, ascendencia, grado de discapacidad, estado de veterano, orientación sexual, identidad o expresión de género, información genética, estado civil, estado de ciudadanía o cualquier otro motivo o circunstancias protegidas por las leyes federales, estatales o locales.",https://www.tecnoempleo.com/data-ai-strategy-consultant-barcelona/data/rf-af1b130d12455346384e,Tecnoempleo,2026-01-20
Senior Azure Data Engineer,"Descripción de la oferta de empleo  SENIOR AZURE DATA ENGINEER  Location: Spain  Are you passionate about data and looking to make an impact? Join our dynamic team as a Senior Azure Data Engineer where you´ll develop and maintain robust data pipelines using cutting-edge tools like Azure Data Factory, Databricks, and Synapse Analytics. If you´re ready to take your data skills to the next level, we want to hear from you!  Why choose us?  HIGH QUALITY PROJECTS. You will take part in demanding projects focused mainly on digitalization or even start projects from scratch. Show us what you´re made of!  LATEST TECHNOLOGIES. We know you love the fascinating world of Salesforce, which is why you´ll continue to grow in this field by working with the latest technologies.  REMOTE POSITION WITHIN SPAIN. Flexibility, what else do we need? You´ll be able to work from the comfort of your home from any location within Spain.  LEARNING. Your current knowledge is never enough, is it? You´ll have access to learning platforms that will train you to become an expert or even start learning one of those skills you know you´ve been wanting to study.  TEAMWORK. This team will always be there for you! We know you´re tough and have a ""no task too small"" attitude, but you´ll always have a talented teammate to count on if you need to!  INTERNATIONAL TEAM. If you stand out among your peers because you´ve got great English communication skills, you´ll be able to put that to good use! If it´s not your strongest suit, don´t worry! Here´s where you can improve it by working alongside teams distributed all around the world.  CAREER PLAN. It is a fact, here you´ll grow in every direction: vertically towards gaining more responsibilities and increasing in category, and horizontally towards learning new technologies and becoming an expert in your business.  Other benefits that you´ll find: - Restaurant tickets for every working day! - Permanent contract: you are here to grow with us! - Flexible retribution for the Gympass and nursery tickets: take care of your health and your children! - Referral program: it´s time to bring your colleagues to an awesome team and get rewarded for it! - Salary and bonuses: it´s a matter of reaching an agreement. We´ll discuss it on our first call!  What will make you successful in this position? - 5+ years of experience as a Azure Data Engineer. - Experience with Azure data services (Data Factory, Databricks, Synapse). - Proficiency in SQL and data modelling. - Knowledge of programming languages like Python or Scala. - Strong problem-solving and communication skills. - English B2 onwards. - Spanish C1 required.  What will be your mission? - Develop and maintain data pipelines using Azure Data Factory, Databricks, and Synapse Analytics. - Collaborate with stakeholders to understand data needs and deliver solutions. - Implement and optimize data models and schemas in Azure SQL Database and Data Lake. - Ensure data quality and integrity through testing and validation. - Monitor and troubleshoot data pipeline issues for high availability.  To sum up!  Apply for this position if you want to remain a successful professional surrounded by a healthy and trendy environment.  The Cognizant community: We are a high caliber team who appreciate and support one another. Our people uphold an energetic, collaborative and inclusive workplace where everyone can thrive. - Cognizant is a global community with more than 300,000 associates around the world. - We don´t just dream of a better way - we make it happen. - We take care of our people, clients, company, communities and climate by doing what´s right. - We foster an innovative environment where you can build the career path that´s right for you.",https://www.tecnoempleo.com/senior-azure-data-engineer-cognizant-technology-so/azure-databricks-synaps/rf-75f215fa824fa30a364b,Tecnoempleo,2026-01-20
Data Product Manager,"Descripción de la oferta de empleo  Ebury is a hyper-growth FinTech firm, named in 2021 as one of the top 15 European Fintechs to work for by AltFi. We offer a range of products including FX risk management, trade finance, currency accounts, international payments and API integration.  Data Product Manager  Malaga - Office based (4 days in office; 1 wfh)  Responsibilities:  You will be responsible for: - Collaborate on the product strategy for Data, focusing on Domains, streams and enablers where the data team is contributing. - Manage the end-to-end delivery of new initiatives completing the business context, scope and requirements. - Define, track, and monitor initiative and epics that must be following the KPI´s or objectives defined in the data team. Making data-driven decisions and actions based on the results. - Participate in all the agile ceremonies - Collaborate across Data and additionally with Technology, and other stakeholders to define requirements, processes, epics, and user stories.  Expectations:  You will have: - A strong data focus. - Excellent communication skills (verbal and written), enabling clear communication of product needs and requirements to leadership, business, and technical stakeholders. - Strong organisational and project management capabilities.  Must Haves:  Ideal candidates must be able to evidence: - A minimum of 1-2+ years of experience in product and execution, either in corporate or startups. - Experience in product owner role, or experience in a high-growth fintech, or FX firm. - Successful delivery of solutions in a fast-paced, agile organisation. - Hands-on experience using Jira. - Strong analytical abilities, capable of breaking down complex problems into manageable parts. - A history of grit, determination, and resourcefulness, coupled with a strong desire for professional development. - Domain knowledge or a keen interest in Data, FX, Payments and Finance  About Us  Ebury is a FinTech success story, positioned among the fastest-growing international companies in its sector.  Founded in 2009, we are headquartered in London and have more than 1700 staff with a presence in more than 25 countries worldwide. Cultural diversity is part of what makes Ebury a special place to be. From Sao Paulo to Dubai, Bucharest to Toronto, we enjoy sharing team experiences and celebrating success across the Ebury family.  Hard work pays off: in 2019, Ebury received a £350 million investment from Banco Santander and has won internationally recognised awards including Financial Times: 1000 Europe´s Fastest-Growing Companies.  None of this would have been possible without our proudest achievement: our great people. Enthusiastic, innovative and collaborative teams, always ready to disrupt and revolutionise the fast-paced FinTech sector.  We believe in inclusion. We stand against discrimination in all forms and have no tolerance for the intolerance of differences that makes us a modern and successful organisation. At Ebury, you can be whoever you want to be and still feel a sense of belonging no matter your story because we want you and your uniqueness to help write our future.  Please submit your application on the careers website directly, uploading your CV / resume in English.",https://www.tecnoempleo.com/data-product-manager-ebury/data-jira/rf-58f913b7a252a32d9c42,Tecnoempleo,2026-01-20
Data Product Manager,"Descripción de la oferta de empleo  Ebury is a hyper-growth FinTech firm, named in 2021 as one of the top 15 European Fintechs to work for by AltFi. We offer a range of products including FX risk management, trade finance, currency accounts, international payments and API integration.  Data Product Manager  Madrid - Office based (4 days in office; 1 wfh)  Responsibilities:  You will be responsible for: - Collaborate on the product strategy for Data, focusing on Domains, streams and enablers where the data team is contributing. - Manage the end-to-end delivery of new initiatives completing the business context, scope and requirements. - Define, track, and monitor initiative and epics that must be following the KPI´s or objectives defined in the data team. Making data-driven decisions and actions based on the results. - Participate in all the agile ceremonies - Collaborate across Data and additionally with Technology, and other stakeholders to define requirements, processes, epics, and user stories.  Expectations:  You will have: - A strong data focus. - Excellent communication skills (verbal and written), enabling clear communication of product needs and requirements to leadership, business, and technical stakeholders. - Strong organisational and project management capabilities.  Must Haves:  Ideal candidates must be able to evidence: - A minimum of 1-2+ years of experience in product and execution, either in corporate or startups. - Experience in product owner role, or experience in a high-growth fintech, or FX firm. - Successful delivery of solutions in a fast-paced, agile organisation. - Hands-on experience using Jira. - Strong analytical abilities, capable of breaking down complex problems into manageable parts. - A history of grit, determination, and resourcefulness, coupled with a strong desire for professional development. - Domain knowledge or a keen interest in Data, FX, Payments and Finance  About Us  Ebury is a FinTech success story, positioned among the fastest-growing international companies in its sector.  Founded in 2009, we are headquartered in London and have more than 1700 staff with a presence in more than 25 countries worldwide. Cultural diversity is part of what makes Ebury a special place to be. From Sao Paulo to Dubai, Bucharest to Toronto, we enjoy sharing team experiences and celebrating success across the Ebury family.  Hard work pays off: in 2019, Ebury received a £350 million investment from Banco Santander and has won internationally recognised awards including Financial Times: 1000 Europe´s Fastest-Growing Companies.  None of this would have been possible without our proudest achievement: our great people. Enthusiastic, innovative and collaborative teams, always ready to disrupt and revolutionise the fast-paced FinTech sector.  We believe in inclusion. We stand against discrimination in all forms and have no tolerance for the intolerance of differences that makes us a modern and successful organisation. At Ebury, you can be whoever you want to be and still feel a sense of belonging no matter your story because we want you and your uniqueness to help write our future.",https://www.tecnoempleo.com/data-product-manager-madrid/data-fx-jira/rf-b31d19cd2260d3f2e94f,Tecnoempleo,2026-01-20
Data Lead,"Descripción de la oferta de empleo  Green Eagle Solutions is a rapidly growing tech company for the renewable energy sector️🌱⚡accelerating the green energy transition by enabling fully autonomous renewable energy operations. Our SaaS platform, ARSOS, seamlessly integrates with all types of renewables, employing RPA-based remote commands to enhance operational scalability and profitability. Currently handling 30% of all the renewable energy in Spain, this solution allows green energy production to be more efficient and sustainable, bringing closer the goal of achieving a carbon-neutral world. ♻️🌿 Working for Green Eagle means growing along with the company and being part of the game-changer spirit🚀. If you are encouraged to do great things, join our team! 🤝💚  __Job Overview:__ We´re seeking a Data Lead with 5+ years of a proven track record and a strong product focus—someone who can transform business needs into data-driven solutions and play a pivotal role in shaping our product strategy. In this role, you´ll be instrumental in solidifying our data infrastructure and redefining how we use data to drive product growth and innovation.  __What You’ll Be Doing__ Product Strategy & Execution:  - Develop and implement a data strategy that aligns with both product objectives and our overall company vision.  - Collaborate closely with product, design, and development teams to uncover opportunities and build data-based solutions that propel product success.  - Turn data insights and metrics into concrete actions and improvements that enhance the user experience.  Architecture & Processes:  - Establish and refine our data architecture by setting up processes and standards that ensure data quality, integrity, and availability.  - Design and build robust, efficient data pipelines (ETL/ELT) to seamlessly integrate various data sources.  - Continuously assess and integrate new tools and technologies to optimize our data management and analysis processes, with an eye toward maintaining agility and product relevance.  Analysis & Reporting:  - Create and manage dashboards, reports, and analyses that empower strategic decision-making within the product team.  - Define and track key performance indicators (KPIs) to monitor product performance, providing insights that drive continuous improvement.  Innovation & Continuous Improvement:  - Advocate for best practices in data governance and security.  - Cultivate a culture of experimentation and innovation, always exploring new ways to leverage data for product enhancement.  What you need to succeed  - 5+ years of a proven experience in data-focused roles (engineering, analytics, or data architecture) with a clear product-oriented mindset.  - Strong background in data modeling and architectural design.  - Proficiency with relational (SQL) and NoSQL databases.  - Hands-on experience with ETL/ELT processes.  - Ability to translate business needs into effective, user-centered technical solutions.  - Programming skills (e.g., Python, R) are a plus.  - Excellent communication, leadership, and teamwork skills, with a strong drive for results and ongoing improvement.  - Proven ability to thrive in agile, iterative work environments, consistently delivering measurable outcomes and fostering continuous improvement.  - Demonstrated ability to translate data insights into actionable business strategies, effectively communicating with both internal and external stakeholders.  Why work at Green Eagle? 🏆 Voted a Great Place to Work® by our team members 🌍 Contribute to the green energy transition and have a sense a purpose in your work 🖥 Hybrid model: Work 40% from home and 60% from our offices in the center of Madrid or Seville 🏡 Flexible working hours 🤑 Flexible compensation including discounts on childcare, transport, and meals 🏥 Private health insurance 🌱 Annual Training & Development bonus",https://www.tecnoempleo.com/data-lead-green-eagle-solutions-s-l/data-etl-sql/rf-bbe216581206c3aaeb4a,Tecnoempleo,2026-01-20
Data Platform Engineer,"Descripción de la oferta de empleo  Estamos buscando un Data Platform Engineer para nuestros equipos de Madrid. Se trata de un proyecto totalmente en remoto, Se valorarán candidaturas de diferentes proviencias. ¡En nuestra empresa tendrás la oportunidad de combinar todos tus intereses tecnológicos y tus habilidades para ayudarnos a llevar nuestras soluciones a los mercados más avanzados y exigentes del mundo!   Funciones en el proyecto: Crear herramientas que aporten nuevas funcionalidades a nuestra Plataforma Analítica (construida sobre GCP) para ayudar a que los Analistas incrementen sus capacidades. Crear herramientas que ofrezcan una mayor visibilidad y observabilidad a los procesos que se ejecutan de manera que en todo momento se tenga el control absoluto de lo que está ocurriendo.  Conocimientos: Profundos de Apache Airflow (Cloud Composer) Profundos de SQL atendiendo a las particularidades de BigQuery sobre todo desde el punto de vista de rendimiento y coste. Profundos de python para desarrollo de programas y APIs en Cloud Functions y Contenedores Firebase Streamlit   ¿Te consideras la persona ideal para este puesto? ¿Qué estas esperando? ¡No pierdas más tiempo y postula para ser feliz en esta aventura!",https://www.tecnoempleo.com/data-platform-engineer-remoto/data-apache-airflow-sql-bigquery/rf-72bf10a9b237931dc144,Tecnoempleo,2026-01-20
Data Engineer,"Descripción de la oferta de empleo  Data Engineer con SnowFlake & DBT  • 1-3 años de experiencia contrastada en diseño de soluciones y desarrollo de procesos de datos (ingesta, transformación y disponibilización para consumo) en entorno cloud AWS. • 1-3 años de experiencia en Datawarehouse, Modelado multidimensional y conocimiento en Snowflake y DBT. • Alto nivel SQL y NoSQL. • Experiencia con CI/CD framework. • Experiencia con las best practices de desarrollo en entornos Cloud y conocimiento de python",https://www.tecnoempleo.com/data-engineer-remoto/data-snowflake-dbt-cloud-aws-datawarehouse-sql-nosql/rf-ee1a11d0623453a3bd41,Tecnoempleo,2026-01-20
Data Scientist con Conocimientos en MLOps,"Descripción de la oferta de empleo  En IT Partner, estamos en la búsqueda de un Data Scientist con sólidos conocimientos en MLOps para unirse a nuestro equipo. Esta posición es ideal para un profesional apasionado por la ciencia de datos y la implementación de soluciones de machine learning en el sector financiero.  Responsabilidades Desarrollar y desplegar modelos de machine learning para resolver problemas específicos del sector financiero. Implementar y mantener pipelines de MLOps para garantizar la eficiencia en el ciclo de vida de los modelos. Colaborar con equipos multidisciplinarios para integrar soluciones de machine learning en aplicaciones y servicios financieros. Monitorear y optimizar el rendimiento de los modelos en producción. Documentar y comunicar resultados y procesos de manera clara y efectiva.  Experiencia: Mínimo 3 años de experiencia en roles relacionados con Data Science y Machine Learning. Experiencia en el sector financiero es altamente valorada.   Conocimientos Técnicos: Programación en Python o R. Experiencia con frameworks de machine learning como TensorFlow, PyTorch, Scikit-learn. Conocimiento y experiencia en MLOps (CI/CD, Docker, Kubernetes, MLflow, etc.). Manejo de herramientas y plataformas de big data (Hadoop, Spark, etc.). Familiaridad con bases de datos SQL y NoSQL.   Habilidades Blandas: Excelentes habilidades de comunicación y presentación. Capacidad para trabajar en equipo y colaborar con diferentes áreas. Pensamiento analítico y orientación a la solución de problemas.  Beneficios Modalidad de Trabajo: Híbrido para ubicaciones en Jaén, Granada o Sevilla. Remoto para otras ubicaciones.  Flexibilidad Horaria: Para facilitar el equilibrio entre la vida laboral y personal. Desarrollo Profesional: Oportunidades de formación y crecimiento dentro de la empresa. Compensación Competitiva: Salario acorde a la experiencia y beneficios adicionales.",https://www.tecnoempleo.com/data-scientist-con-conocimientos-en-mlops-hibrido/python-r-data-mlops/rf-8d52145a12662316ba4f,Tecnoempleo,2026-01-20
Big data,"Descripción de la oferta de empleo  Estamos seleccionando un Integration Engineer será responsable del desarrollo y mantenimiento de la plataforma Datalake.  Se espera que tenga experiencia en Scala y PowerShell, así como en Big Data y desarrollo de software, con al menos 7 años de experiencia en el campo  Tareas Principales: Desarrollo y mantenimiento de la plataforma Datalake. Entrega de código fuente y pruebas. Ambiente técnico: Ingeniero de Datos.",https://www.tecnoempleo.com/big-data-barcelona/big-data-scala-powershell/rf-5a331b8a52aaf388a042,Tecnoempleo,2026-01-20
SAP Customer Data Platform (CDP),"Descripción de la oferta de empleo  EXPERIENCIA: 2-3 años TITULACION: Ingeniería Técnica INGLES Alto deseable Consultor en la solución SAP CDP  o Utilizar eficazmente las APIs de SAP CDP. o Manejo de errores y la integridad de los datos en el uso de la API. o Monitorear el rendimiento del sistema, soluciona problemas e implementa acciones correctivas según sea necesario. o Generación de documentación técnica y funcional o Entender los diferentes apartados de CDP.",https://www.tecnoempleo.com/sap-customer-data-platform-cdp-remoto/sap-data-cdp/rf-35a41eea827ee3f24a4f,Tecnoempleo,2026-01-20
Data Engineer,"Descripción de la oferta de empleo  Requisitos: Licenciatura en Informática, Ingeniería de Sistemas o carrera afín. Al menos 3 años de experiencia en roles similares. Experiencia con tecnologías como Scala, Python y SQL. Conocimiento de plataformas en la nube, especialmente Azure. Familiaridad con herramientas como Databricks y Azure DevOps. Capacidad para trabajar de manera autónoma y en equipo. Excelentes habilidades de comunicación y resolución de problemas.   Si ves que puedes encajar no dudes en postularte y nos pondremos en contacto contigo lo más rápido posible.",https://www.tecnoempleo.com/data-engineer-remoto/data-scala-python-databricks-sql/rf-2b7e1fd772e8431ef94e,Tecnoempleo,2026-01-20
Arquitecto/a Big Data,"Descripción de la oferta de empleo  MISIÓN.  Participación en el diseño, implantación y soporte de la nueva arquitectura tecnológica BIG DATA. Establecer los pipelines y desarrollos necesarios para permitir integración continua en los diversos entornos.  Soluciones de tratamiento del dato tanto, para soluciones streaming, como batch, dentro de equipos multidisciplinares, conceptualizando la solución, definiendo y aplicando la metodología de uso de la tecnología.  Generación de valor y ventajas competitivas, aplicando propuestas tecnológicas innovadoras, mejorando procesos de gestión y de negocio.    RESPONSABILIDADES DEL PUESTO    Definir, implementar, probar y optimizar la arquitectura BIG DATA para optimizar los procesos de datos en cloud. Evaluación de soluciones BIG DATA. Participación en diseños técnicos y gestión de equipos y de proyectos. Dirección de los equipos de data engineers asegurando la implementación de las directrices definidas. Definir estándares de gestión de datos, proyectos de machine learning, datos no estructurados, etc. Colaborar con Analistas de Negocio, Soluciones y Arquitectos Empresariales y contribuir a la estrategia de datos de la empresa. Negociar y gestionar propuestas con un grado de complejidad técnico elevado. Habilidades:  Buen comunicador y con visión de negocio. Pensamiento crítico, analítico y con actitud proactiva. Adaptación continua al cambio. Gran capacidad de aprendizaje. Habilidades para trabajo en equipo.",https://www.tecnoempleo.com/arquitecto-big-data-hibrido/big-data-datalakes-lakehouse-datamesh-datahubs/rf-5dbe18cb226ff3d2984b,Tecnoempleo,2026-01-20
Junior Tecnología con Discapacidad,"Descripción de la oferta de empleo  Perfil buscado (Hombre/Mujer)  Podrás enfocar tu carrera a uno de los grandes departamentos de tecnología:  • Ciberseguridad. • Soluciones tecnológicas a medida. • Inteligencia artificial y DATA. • Transformación y eficacia de procesos de negocio.  Tu día a día:  • Principalmente, aprender. • Realizar tareas de soporte técnico y mantenimiento de sistemas tecnológicos. • Colaborar en proyectos de desarrollo e implementación de soluciones tecnológicas. • Analizar y resolver incidencias técnicas en los sistemas de la empresa. • Apoyar al equipo en la mejora continua de procesos tecnológicos. • Documentar procedimientos y soluciones técnicas implementadas. • Trabajar en estrecha colaboración con otros departamentos para garantizar la correcta integración de sistemas. • Participar en la formación y capacitación técnica de usuarios internos. • Proponer mejoras y optimizaciones en los sistemas tecnológicos existentes.  #lgd, #impactopositivo • Poseer certificado de discapacidad (Obligatorio). • Posiciones junior en una de las consultoras más importantes (Big4).  El/la candidato/a seleccionado deberá cumplir los siguientes requisitos:  • Poseer certificado de discapacidad (Obligatorio). • Formación en áreas relacionadas con la tecnología, como informática, ingeniería, ciencias puras (matemáticas, estadística, física...) o similares. • Habilidad para trabajar en equipo y colaborar con diferentes departamentos. • Conocimientos básicos en herramientas y sistemas tecnológicos. • Capacidad para analizar y resolver problemas técnicos de forma eficiente. • Interés en el aprendizaje continuo y en el desarrollo profesional en el sector de la tecnología. • Nivel de inglés B2-C1 (habrá prueba de inglés en entrevista).  #lgd, #impactopositivo  Nuestro cliente es una BIG4, una organización de gran tamaño que opera en el sector de los servicios profesionales, comprometida con la inclusión y la diversidad en su entorno laboral.  #lgd, #impactopositivo  • Contrato indefinido en una empresa líder en el sector de los servicios profesionales a jornada completa. • Rango salarial competitivo: 21.000 EUR - 26.000 EUR. • Oportunidad de teletrabajo para mayor flexibilidad. • Ambiente laboral inclusivo y orientado al desarrollo profesional. • Acceso a formación continua y oportunidades de crecimiento en el sector de la tecnología.  #lgd, #impactopositivo",https://www.tecnoempleo.com/junior-tecnologia-con-discapacidad-page-personnel/ciberseguridad-data/rf-2fba1ee9020f936fe241,Tecnoempleo,2026-01-20
SEM & Performance Marketing Specialist,"Descripción de la oferta de empleo  Somos una agencia de marketing digital 360º que combina estrategia, creatividad, desarrollo web, analítica y performance. Trabajamos con marcas de múltiples sectores, pero una parte muy relevante de nuestros proyectos está centrada en e‑commerce, donde gestionamos campañas orientadas a ventas, optimización de catálogos y escalado de resultados.  Buscamos un/a SEM & Performance Marketing Specialist con una base técnica sólida y especial interés en el mundo e‑commerce.  🎯 Responsabilidades principales: Gestionar y optimizar campañas de Google Ads para e‑commerce: Shopping, Performance Max, Search orientado a conversión. Optimización de feeds, atributos y calidad del catálogo. Ejecutar campañas de Meta Ads y otras plataformas (TikTok, LinkedIn) cuando el proyecto lo requiera. Implementar y revisar conversiones, eventos y etiquetas mediante Google Tag Manager. Analizar resultados en GA4 y elaborar informes técnicos en Looker Studio. Realizar auditorías técnicas de cuentas: estructura, concordancias, extensiones, calidad de anuncios, tracking, etc. Participar en la definición de estrategias de segmentación, audiencias y remarketing dinámico. Monitorizar KPIs clave (ROAS, CPA, CVR, AOV, CPC, CTR) y proponer optimizaciones basadas en datos. Colaborar con equipos de SEO, diseño, desarrollo y contenidos para asegurar coherencia en proyectos 360º. Mantenerse actualizado/a sobre nuevas funcionalidades de Google Ads, PMax, GA4 y tendencias en e‑commerce.  🧩 Requisitos: Mínimos 2–3 años gestionando campañas en Google Ads, especialmente para e‑commerce. Conocimientos sólidos de GTM, GA4 y medición de conversiones. Experiencia creando informes en Looker Studio. Experiencia trabajando en agencia o entornos multiproyecto. Conocimientos básicos de feeds, Merchant Center y Performance Max. Perfil analítico, metódico y orientado a resultados.  Valorable: Certificaciones de Google Ads. Experiencia con Meta Ads para e‑commerce (catálogos, remarketing dinámico). Conocimientos de Data Layer, debugging con Tag Assistant o herramientas similares. nociones de HTML/CSS para entender implementaciones técnicas. Experiencia en proyectos de marketplaces o integraciones con plataformas como Shopify, WooCommerce o Prestashop.  ✨ Qué ofrecemos: Proyectos variados y técnicamente desafiantes, especialmente en entornos e‑commerce. Mentorización y plan de crecimiento hacia roles más técnicos o estratégicos. Teletrabajo 100% y flexibilidad horaria. Retribución competitiva acorde a experiencia. Equipo multidisciplinar, colaborativo y orientado a la mejora continua.",https://www.tecnoempleo.com/sem-performance-marketing-specialist-social-you/google-ads-ga4/rf-10741665425233c4f44c,Tecnoempleo,2026-01-20
Senior MLOps Engineer,"Descripción de la oferta de empleo  ¿Te imaginas escalar modelos de Inteligencia Artificial que impactan en millones de clientes en todo el mundo?  En SocialYou estamos seleccionando un/a Senior MLOps Engineer para unirse al hub tecnológico de una de las mayores multinacionales del sector moda. No buscamos solo a alguien que mantenga infraestructura, sino a un arquitecto/a capaz de industrializar el Machine Learning en un entorno de Retail de alta intensidad, donde la agilidad y la escala son críticas.  🚀 Tu Misión en el Hub de Moda Industrialización de IA: Transformar los modelos de Data Science (recomendadores, predicción de demanda, optimización de stock) en servicios productivos y escalables.  Ecosistema AWS & Databricks: Liderar la implementación de infraestructura cloud robusta, automatizando la seguridad y el rendimiento.  Orquestación a Gran Escala: Desplegar y operar clústeres en Kubernetes y gestionar flujos de trabajo complejos con Apache Airflow.  ML Lifecycle: Garantizar la trazabilidad y monitorización total con MLflow/Kubeflow, asegurando que los modelos en tienda y online funcionen con precisión quirúrgica.  Bridge Role: Trabajar codo con codo con Data Scientists para que el “time-to-market” de las nuevas soluciones de IA sea mínimo.  🎯 ¿Qué necesitamos de ti? (Must Have) Experiencia: 3–5 años en roles de MLOps en entornos de producción real (preferiblemente enfrentando grandes volúmenes de datos).  Expertise en AWS: Gestión sólida de infraestructura, automatización y seguridad cloud.  Dominio de Kubernetes: Despliegue y operación de aplicaciones contenedorizadas.  Power User de Databricks: Optimización de pipelines y experiencia con Model Serving / AI Gateway.  Stack Tecnológico: Dominio de MLflow, Kubeflow, TFX y Apache Airflow.  Ingeniería de Software: Sólida capacidad de programación y cultura de versionado/monitorización.  ✨ El “Perfect Match” (Nice to Have) Experiencia previa en el sector Retail o E-commerce de gran escala.  Capacidad para optimizar costes y eficiencia en nubes públicas (FinOps).  Haber actuado como referente técnico dentro de un equipo, guiando las mejores prácticas de ingeniería.  Visión de arquitectura para plataformas de datos globales.  💎 ¿Por qué te encantará esta posición? Entorno Multinacional: Trabajarás en una compañía donde la tecnología define la moda del futuro.  Impacto Visible: Tus pipelines alimentarán los algoritmos que deciden qué se vende y cómo en mercados internacionales.  Cultura de Innovación: Acceso a las últimas versiones de herramientas y formación continua en un entorno altamente profesionalizado.  ✨ Lo que te ofrecemos Flexibilidad Total: Posición en remoto. Valoramos positivamente si resides cerca de Barcelona para poder disfrutar de momentos presenciales con el equipo y fortalecer vínculos, pero la prioridad es tu talento, no tu silla.  Retribución Competitiva: Salario acorde a la expertise técnica y seniority aportado.  Impacto Global: Trabajar en una compañía líder donde la tecnología define el futuro del Retail.",https://www.tecnoempleo.com/senior-mlops-engineer-social-you/aws-databricks/rf-b2191c23222b63b1f447,Tecnoempleo,2026-01-20
Arquitecto de Datos AZURE,"Descripción de la oferta de empleo  Descripción Arquitecto/a de Datos Azure - Remoto ✨ Descripción de la empresaMultinacional del sector TIC, referente en soluciones cloud y proyectos de transformación digital, busca incorporar un/a Arquitecto/a de Datos Azure para un proyecto estable y de largo recorrido.  🕗 Horario y modalidad Modalidad 100% remota. Horario de oficina: Lunes a jueves: mañana y tarde. Viernes, y julio y agosto: jornada intensiva de 7 horas. 🎯 Requisitos mínimosFormación académica (excluyente) Formación universitaria (en España o convalidada) correspondiente al Nivel 2 del Marco Español de Cualificaciones para la Educación Superior, en áreas como: Tecnologías de la Información y Comunicaciones Matemáticas Física O disciplinas afines Certificación (imprescindible) Certificación de especialidad en la plataforma cloud ofertada como Arquitecto/a de Soluciones. Idealmente certificación alineada con Microsoft Azure. Experiencia 5 años como Arquitecto/a de Soluciones de Datos. Al menos 2 años desarrollando proyectos en Microsoft Azure. Experiencia previa colaborando como Arquitecto/a de Datos Azure durante al menos 1 año. Conocimientos técnicos imprescindibles Ecosistema Microsoft Azure aplicado a arquitectura de datos. Diseño de soluciones cloud escalables, seguras y orientadas a analítica. Buen entendimiento de pipelines, ingesta, modelado y gobierno del dato. ✨ Requisitos deseables Experiencia en proyectos de analítica avanzada o Machine Learning. Conocimientos en automatización, orquestación y optimización de arquitecturas cloud. Familiaridad con entornos multinacionales y metodologías ágiles. 🛠️ Funciones principales Definir y diseñar arquitecturas de datos en Microsoft Azure. Liderar la construcción de soluciones cloud escalables y de alto rendimiento. Supervisar pipelines de datos, procesos de ingesta, transformación y modelado. Colaborar con equipos de ingeniería, analítica y negocio. Garantizar buenas prácticas en seguridad, gobierno del dato y optimización de costes. Participar en proyectos estratégicos de transformación digital basados en Azure. 🌟 Qué ofrece el cliente final Contratación directa con multinacional TIC. Proyecto estable y de largo recorrido. Modalidad remota con horario estructurado. Desarrollo profesional en entornos cloud avanzados. Formación continua y participación en proyectos de alto nivel tecnológico. 🤝 Compromiso con la igualdadEn Zemsania, creemos en la igualdad de oportunidades y en la diversidad como valores fundamentales para el éxito de nuestra organización. Por ello, garantizamos un proceso de selección basado en el mérito y sin discriminación por motivos de género, edad, discapacidad, orientación sexual, raza, religión o cualquier otra condición personal o social.",https://www.tecnoempleo.com/arquitecto-datos-azure-digital-talent-agency/data-architecture/rf-f3c3148dc21423c10d4b,Tecnoempleo,2026-01-20
Senior DBA Oracle,"Descripción de la oferta de empleo  Desde Second Window estamos en búsqueda de un perfil de DBA ORACLE para incorporar a un proyecto muy estable y a largo plazo en modalidad Híbrida en Madrid (asistir a oficina 2 días y teletrabajar 3 días) para importante entidad financiera  ¿Qué buscamos?  -Experiencia mínima de 4 años como DBA Oracle en modelado de datos, con capacidades analíticas para la mejora continua del performance y BBDD Oracle Exadata  -Experiencia en PL/SQL  -Experiencia en Data modeling   ¿Qué te podemos ofrecer?  · Contratación indefinida  . Salario: 36-38K bruto/año  . Modalidad: Híbrido  (2 días oficina en Madrid y 3 días teletrabajo)  · Beneficios sociales: Seguro médico privado y seguro de vida  · Retribución flexible: tickets restaurante, tickets guardería, tarjeta transporte  · 23 días de vacaciones y el día de tu cumpleaños (24 días)  · Plan de carrera y formación personalizado.    Si sientes que podrías encajar y te apetece la experiencia, ¡ponte en contacto con nosotros! Y te daremos toda la información que necesites. ¡Abre una nueva ventana a tu futuro con Second Window! ¡Inscríbete!",https://www.tecnoempleo.com/senior-dba-oracle-second-window/oracle-exadata-pl-sql/rf-4546116fe2d273436d48,Tecnoempleo,2026-01-20
Senior Cloud & Platform Engineer (Azure),"Descripción de la oferta de empleo  ¿Te gustaría formar parte de una multinacional líder del sector energético, con proyectos de gran escala, enfoque en innovación y una plataforma cloud crítica para millones de usuarios? Buscamos un Senior Cloud & Platform Engineer con un fuerte dominio de Azure, IaC y automatización, capaz de asumir ownership total de la plataforma y contribuir a su evolución tecnológica.  La posición es 100% remota, con equipo distribuido y alto nivel técnico.  🎯 Rol y Responsabilidades Como Senior Cloud & Platform Engineer, serás responsable de:  Diseñar, desplegar y operar infraestructuras cloud en Azure con un enfoque IaC. Automatizar procesos, entornos y despliegues mediante Ansible, Terraform y scripting. Gestionar y optimizar clusters AKS, pipelines CI/CD y servicios Data/AI. Implementar observabilidad avanzada y estrategias de coste eficientes. Colaborar con equipos de Desarrollo, Data y QA para garantizar una plataforma estable, segura y escalable. Aportar visión técnica, proactividad y capacidad de mejora continua en un entorno de alta criticidad.  🔧 Requerimientos Técnicos – MUST HAVE (70%) Ansible: Automatización de entornos, inventarios y playbooks reutilizables (IaC). Azure Cloud: Networking, Storage, IAM, Monitor y servicios Data & AI (Databricks, Data Factory, OpenAI, AzureML). AKS: Despliegue y operación de contenedores, Helm charts y orquestación. Infraestructura como Código (IaC): Terraform o ARM Templates. Scripting: Bash, PowerShell o Python para automatización y pipelines. CI/CD con Azure DevOps: Pipelines, repos, SonarQube, gates de calidad. Cloud Networking & Security: Políticas de red, identidades, roles y seguridad cloud. Observabilidad: Prometheus, Grafana, Azure Monitor, alertas y métricas. Optimización de Costes Cloud: Análisis, tuning, reservas y escalado eficiente.  🌟 Nice to Have (30%) Experiencia en entornos Data/AI y prácticas MLOps (AzureML, Databricks). Conocimientos en FinOps o control presupuestario cloud. Familiaridad con herramientas de calidad y seguridad: SonarCloud, Trivy. Experiencia en entornos híbridos o migraciones cloud. Trabajo en metodologías ágiles y colaboración con equipos multidisciplinares.  🧪 Validación Técnica – Qué Evaluaremos Pruebas técnicas Diseño de infraestructura reproducible con Ansible y Terraform. Despliegue y operación de contenedores en AKS con Helm. Construcción de pipelines CI/CD en Azure DevOps con testing y gates. Implementación de observabilidad unificada (Prometheus, Grafana, Azure Monitor). Estrategias de optimización de costes y escalabilidad. Soft Skills clave Autonomía total y capacidad de asumir la operación y evolución de la plataforma. Proactividad técnica y ownership real. Mentalidad analítica orientada a eficiencia, automatización y control de costes. Comunicación clara y colaboración fluida con equipos técnicos. Foco en estabilidad, seguridad y escalabilidad.  💼 Qué ofrece la posición Incorporación a una multinacional del sector energético, referente en innovación y transformación digital. Rol estratégico en una plataforma cloud crítica y de gran escala. Trabajo 100% remoto desde cualquier ubicación dentro de España. Equipo técnico senior, cultura de ingeniería y autonomía real. Proyectos de largo recorrido y alto impacto.",https://www.tecnoempleo.com/senior-cloud-platform-engineer-azure-social-you/ansible-azure-cloud/rf-adf81689528e5325f441,Tecnoempleo,2026-01-20
AI Engineer,"Descripción de la oferta de empleo  En WayOps buscamos un perfil AI Engineer que quiera desarrollar su carrera profesional formando parte de un equipo Data & AI de primer nivel y trabajando en proyectos cloud con las últimas tecnologías.  CONTEXTO & RESPONSABILIDADES  La persona seleccionada se incorporará dentro de un equipo de nueva formación que tendrá como misión automatizar mediante MLOps la creación responsable de modelos en la plataforma analítica. Junto al AI Architect, el AI Engineer deberá desarrollar librerías Python que permitan la integración del código científico con el proceso de MLOps y arquetipos de código que utilicen estas librerías. Será imprescindible contar con un background técnico en programación y familiaridad tanto con DevOps, como con el ciclo de vida de los modelos científicos.  PROYECTO & EQUIPO El proyecto persigue la adaptación de la plataforma analítica existente para integrar la creación responsable de modelos y automatizar su despliegue mediante MLOps. Como quiera que la base tecnológica ya incluye Azure Databricks y Azure Machine Learning Services, se quiere realizar la implementación del proceso gobernado desde Azure DevOps integrando a través de SDK con el resto de servicios para la creación automática de recursos o implementar las pipelines de despliegue.  Para el éxito del proyecto, resulta imprescindible contar con especialistas que además de tener visión de la arquitectura puedan realizar la configuración de las pipelines y crear los arquetipos en código que integren con los diferentes servicios de Azure Machine Learning. La configuración de cada iniciativa debe permitir el desarrollo local o remoto contra un clúster en Databricks o un Compute en Azure Machine Learning. Toda la configuración del proyecto y despliegue deben ser automatizados.  El equipo designado para el proyecto incluirá ingenieros de automatización MLOps (MLOps Engineer) e ingenieros de industrialización IA (AI Engineer) que serán supervisados por el líder técnico (Team Lead). El AI Architect trabajará de la mano del líder técnico y deberá liderar las tareas del equipo, especialmente los ingenieros de industrialización AI. Además, el proyecto contará con la supervisión del arquitecto empresarial y el apoyo del especialista de la plataforma. En total el equipo del proyecto serán unas ocho personas.  EXPERIENCIA & CONOCIMIENTOS  El perfil a incorporar deberá contar con 2-3 años de experiencia como Ingeniero de IA participando en la industrialización de modelos científicos y desarrollo de librerías Python de referencia en entornos productivos. Además, deberá contar con un background de 3-5 años de experiencia como Ingeniero de Software desarrollando aplicaciones y programas orientados a la transformación de datos o operacionalización de modelos científicos.  Se valorará experiencia previa como científico y/o ingeniero de datos, así como experiencia en la definición de mejores prácticas de programación, conocimientos y experiencia con CI/CD en Azure DevOps y cualquier experiencia previa en torno al SDK v2 de Azure Machine Learning.  Será necesario tener experiencia previa con tecnologías: - Azure (Databricks, Azure Machine Learning, Storage, Data Factory) - Azure Machine Learning (Experiment Tracking, Model Registry, AML Studio, AML SDK v2, MLflow) - Azure DevOps (Boards) - Databricks (PySpark, Dataframes, Delta Tables, Unity Catalog, Databricks Connect) - Desarrollo Python (Click, Poetry, Pipx, Opencensus, Black, Pdb+, fastAPI) - QA & Testing (Kiuwan, JMeter, PyTest) - Herramientas (Visual Studio Code, Git)  Además se valorará positivamente contar con experiencia o conocimientos en: - Azure (Cosmos DB, SQL Databases, Application Insights, Azure Monitor, App Service) - Azure Machine Learning (AML Pipelines, AML Endpoints, AML Environments, AML Compute) - Azure DevOps (Pipelines, Repos, Test Plans, Artifacts) - Machine Learning (sklearn, mllib, h2o, tensorflow, keras) - Responsible AI (AML RAI SDK, Fairlearn, InterpretML, DiCE, EconML)  CONTRATACIÓN & UBICACIÓN  La contratación será mediante contrato anual prorrogable como autónomo en jornada completa. El trabajo se desarrollará en remoto preferentemente dentro del horario de oficina del cliente para facilitar la coordinación con el resto del equipo. Banda salarial negociable en función de la experiencia aportada. Incorporación inmediata.",https://www.tecnoempleo.com/ai-engineer-wayops/databricks-machine-learning/rf-b69b147ae2ebe33fc048,Tecnoempleo,2026-01-20
Industrial Project Manager,"Descripción de la oferta de empleo  Buscamos un/a profesional para liderar e impulsar proyectos de digitalización e Industria 4.0. La persona seleccionada será el enlace entre los equipos de producción, mantenimiento y calidad, y la sostenibilidad de los procesos.  Funciones: • Identificar, planificar y coordinar proyectos de sensórica, IoT, Big Data, automatización y mantenimiento predictivo. • Colaborar con distintas áreas para implementar mejoras tecnológicas. • Gestionar proveedores y evaluar soluciones técnicas. • Garantizar el cumplimiento de estándares de ciberseguridad e interoperabilidad. • Elaborar documentación e informes para dirección.  Requisitos: • Titulación universitaria en Ingeniería, Tecnologías de la Información, Telecomunicaciones o afines. • Mínimo 2 años de experiencia en entornos industriales (metalurgia, fundición, automoción, etc.). • Experiencia en gestión de proyectos tecnológicos o de mejora de procesos. • Conocimientos en MES, SCADA, ERP, sensores industriales, mantenimiento predictivo y analítica de datos. • Manejo de herramientas de BI (SQL, PowerBI). • Nivel medio/alto de inglés técnico. • Proactividad, visión estratégica, comunicación efectiva y capacidad de coordinación transversal.  Ofrecemos: • Incorporación a un proyecto estratégico de transformación digital. • Entorno dinámico e innovador. • Posibilidades de desarrollo profesional. 📩 Inscríbete y forma parte de la transformación digital industrial.",https://www.tecnoempleo.com/industrial-project-manager-inkoova/iot-big-data/rf-d1c51c55f237a3584642,Tecnoempleo,2026-01-20
Developer Spark Scala AWS (Sector Banca),"Descripción de la oferta de empleo  🚀 ¡Estamos creciendo! ¿Te apasiona el mundo Big Data y quieres formar parte de un proyecto estratégico en el sector bancario? ¡Esta es tu oportunidad!  🔍 Buscamos 8 profesionales con experiencia en desarrollo Spark Scala para unirse a nuestro equipo en Málaga.  ✅ Lo que necesitamos de ti 2-3 años de experiencia como Developer Spark Scala Conocimientos sólidos en AWS Experiencia en entornos Big Data Residencia en Málaga o alrededores Trabajo en equipo, proactividad y orientación a la calidad  ➕ Sumará puntos si tienes Experiencia en proyectos bancarios/financieros Conocimiento de arquitecturas de datos complejas Familiaridad con metodologías y estándares corporativos  📍 Ubicación: Modelo híbrido (Málaga) 🏢 Modalidad: Asistencia ocasional a oficina  🔧 ¿Qué harás? Desarrollo y evolución de soluciones Big Data con Apache Spark y Scala Diseño y optimización de procesos de datos Integración y operación en entornos AWS Colaboración con equipos multidisciplinares en un contexto regulado  🌐 ¿Qué ofrecemos? Proyecto estable y de alto impacto en banca Modelo híbrido Entorno tecnológico avanzado Desarrollo profesional en un contexto corporativo sólido  📩 ¿Te interesa? Aplica tu perfil y ¡hablemos! #SparkScala #BigData #AWS #EmpleoTech #HiringNow #SectorBancario #Málaga #TrabajoHíbridocario #Málaga #TrabajoHíbrido",https://www.tecnoempleo.com/developer-spark-scala-aws-sector-banca-panel-siste/sql-dataframes/rf-f4811db6322fb31a4946,Tecnoempleo,2026-01-20
Scrum Master,"Descripción de la oferta de empleo  Buscamos un Scrum Master con sólida experiencia en Data Engineering para unirse a nuestro equipo. Esta posición requiere a un profesional con un fuerte enfoque en la entrega ágil, combinado con conocimientos prácticos en plataformas de datos como AWS y Databricks.  Requisitos imprescindibles: 5-7+ años de experiencia como Scrum Master en entornos ágiles. Experiencia significativa en Data Warehouse, Data Engineering o Analytics. Conocimiento práctico de los servicios de AWS (S3, Glue, Lambda, Redshift) y Databricks (Spark, Delta Lake, Workflows). Conocimientos sólidos sobre el ciclo de vida de los datos, procesos ETL/ELT y arquitectura de datos empresarial. Experiencia trabajando con equipos distribuidos a nivel global y multicuulturales. Fuertes habilidades de comunicación, facilitación y gestión de stakeholders. Experiencia con Jira, Azure DevOps y Confluence.  Responsabilidades: Liderar equipos ágiles en la entrega de plataformas de datos e ingeniería de datos, garantizando el cumplimiento de los plazos y la calidad. Facilitar la adopción de prácticas ágiles y Scrum, promoviendo la mejora continua en el equipo. Alinear los objetivos del equipo con las necesidades de los stakeholders, asegurando la correcta entrega y el cumplimiento de las expectativas del cliente. Colaborar estrechamente con los equipos de Data Engineering y Analytics para asegurar la integración fluida de soluciones tecnológicas y mejorar la eficiencia operativa. Gestionar el backlog, asegurando que los equipos se mantengan enfocados en las prioridades adecuadas.  Se valorará: Experiencia en la implementación de soluciones de Data Platform. Capacidad de liderar y fomentar la excelencia operativa y la mejora continua dentro de los equipos ágiles. Conocimiento avanzado en plataformas de datos y herramientas de integración.  Fomentamos un ambiente de trabajo multicultural e inclusivo, no discriminamos por edad, género o creencias; así como ofrecemos igualdad de oportunidades a todo el personal.  Desarrollamos nuestras actividades bajo los principios del cuidado del medioambiente, la sostenibilidad y la responsabilidad social corporativa; colaborando en proyectos de reforestación y sostenibilidad.  Apoyamos los 10 principios del Pacto Mundial y los 17 Objetivos de Desarrollo Sostenible, en materia de derechos humanos, condiciones laborales, medio ambiente y anticorrupción.  Los procesos de reclutamiento se desarrollan bajo altos estándares de calidad definiendo la incorporación en base a la experiencia y habilidades del candidato.  Somos una empresa española líder en servicios tecnológicos y atracción del talento presente en el mercado desde 1995. Contamos con más de 600 empleados en proyectos tanto nacionales como internacionales en sector TI.",https://www.tecnoempleo.com/scrum-master-serem/azure-devops/rf-e0901dac220eb3aedf48,Tecnoempleo,2026-01-20
Líder trazabilidad y calidad datos,"Descripción de la oferta de empleo  Personal Líder-Ingeniería en trazabilidad y calidad de dato en Almería, Madrid, Salamanca, Sevilla, Valencia, Granada o Murcia  Descripción del puesto:  Promover e impulsar planes estratégicos de trazabilidad y calidad de Datos, garantizando la confiabilidad de la información para la toma de decisiones, con datos trazados desde orígenes reputados y con controles de calidad que aseguren la integridad de datos, supervisando que los equipos de desarrollo cumplen con el Ciclo de Vida de Datos. Asegurar los procesos regulatorios RDA y alineamiento con las políticas de Gobierno del Dato.  ¿Qué funciones realizarás?  - Liderar aplicaciones de datos del Grupo Cooperativo Cajamar. - Definición y establecimiento de estrategias, normas y políticas de datos orientadas a la gestión y calidad de los datos que ayuden a nuestros clientes avanzando en su transformación hacia una organización Data-Driven. - Implementar políticas y acciones que garanticen la protección y seguridad del dato en todo su ciclo de vida. - Definir datos maestros y establecer las relaciones entre las entidades de datos y funciones. Crear y mantener los modelos de relación en la suite de gobierno. - Identificar y clasificar los niveles de acceso a los datos. - Creación del catálogo de datos, diccionario de datos, o la definición de términos de negocio para gobierno. - Identificar y proponer mejoras en los sistemas y herramientas para asegurar la calidad de los datos.  ¿Qué necesitamos de ti?  - Estudios en informática: Ingeniería - Ingles nivel avanzado - Experiencia en trazabilidad y su importancia en los sistemas de gestión, estando familiarizado con los principios de control de calidad, aseguramiento de la calidad y mejora continua. - Experiencia en el uso de herramientas como bases de datos, hojas de cálculo y software específico, así como conocimiento en ciencia de datos para evaluar la calidad y detección de tendencias o desviaciones. - Experiencia en el manejo de Normativas y Regulaciones específicas relacionadas con la trazabilidad y la calidad en el sector. - Experiencia en la Suite de Informática de gobierno de datos.  ¿Qué te ofrecemos?  - Oportunidad de integrarte en un equipo de profesionales, comprometidos en un proyecto de presente y futuro cuyo entorno de trabajo colaborativo y dinámico te facilitará diversidad de posibilidades de crecimiento y desarrollo profesional. - Formación continua y disponibilidad de itinerario personalizado. - Posibilidad de Jornada y Horario flexible, según proyecto. - Compensación y beneficios sociales: Retribución flexible (Seguros de Salud, Cheque Guardería, etc.), y condiciones financieras especiales. - Programas de acompañamiento y Bienestar atendiendo a tus necesidades personales. - Integración en una empresa comprometida con la Igualdad de trato y oportunidades entre mujeres y hombres, así como con la lucha contra la discriminación en todas sus formas. - Acceso a diversos Programas de Voluntariado donde podrás involucrarte dejando una huella positiva - Posibilidad de trabajo híbrido. - Contrato indefinido en un proyecto confiable y en continua evolución con una remuneración acorde a tu experiencia y aportación de valor.  ¿Qué aspectos valoramos de ti?  - Actitud innovadora en cuanto a la gestión del cambio. - Liderazgo técnico para gestionar expectativas tanto del equipo técnico como clientes. - Capacidades autodidactas y aprendizaje continuo para entender el negocio y a los clientes y adaptarse rápida y ágilmente a las novedades del mercado. - Autoliderazgo para valorar y seleccionar procedimientos y enfoques de trabajo adecuados para supera retos con el equipo. - Fomentar una visión de negocio clara, emocionante e integradora entre sus equipos para aplicar soluciones de datos efectivas.  Entidad: Cajamar Tecnología Centro de Trabajo: Almería, Madrid, Salamanca, Sevilla, Valencia, Granada, Murcia Fecha prevista incorporación: Inmediata  ¡Por todo esto y muchas cosas más, te esperamos!",https://www.tecnoempleo.com/lider-trazabilidad-calidad-datos-cajamar-tecnologi/azure-sql/rf-5cfb10bf5228e3ff1741,Tecnoempleo,2026-01-20
Ingeniero/a de Datos Azure,"Descripción de la oferta de empleo  Descripción Ingeniero/a de Datos Azure | Multinacional TIC | Remoto✨ Descripción de la empresaMultinacional del sector TIC, líder en soluciones tecnológicas y proyectos de transformación digital a gran escala, busca incorporar un/a Ingeniero/a de Datos Azure para un proyecto estable y de alto impacto.  🕗 Horario y modalidad Modalidad 100% remota. Horario de oficina: Lunes a jueves: mañana y tarde. Viernes, y julio y agosto: jornada intensiva de 7 horas. 🎯 Requisitos mínimosFormación (excluyente) Formación universitaria (en España o convalidada) correspondiente al Nivel 2 del Marco Español de Cualificaciones para la Educación Superior, en áreas como: Tecnologías de la Información y Comunicaciones Matemáticas Física Ingeniería O disciplinas afines Certificación (muy valorada / ideal) Certificación especializada en analítica avanzada o Machine Learning en la plataforma cloud ofertada. Idealmente Microsoft Azure Data Scientist Associate (DP-100) o certificación equivalente. Experiencia Mínimo 4 años como Ingeniero/a de Datos. Al menos 2 años desarrollando proyectos en Microsoft Azure o plataforma cloud equivalente. Conocimientos técnicos imprescindibles Ecosistema Microsoft Azure aplicado a datos. Procesos de ingesta, transformación y modelado de datos. Buen entendimiento de arquitecturas cloud orientadas a analítica. ✨ Requisitos deseables Experiencia en proyectos de analítica avanzada o ML. Conocimientos en herramientas de orquestación, automatización o pipelines de datos. Familiaridad con entornos multinacionales y metodologías ágiles.  🛠️ Funciones principales Diseño, administración y desarrollo de soluciones de datos en Microsoft Azure. Construcción y mantenimiento de pipelines de ingesta, transformación y procesamiento. Implementación de arquitecturas de datos escalables y seguras. Colaboración con equipos de analítica, ciencia de datos y negocio. Optimización de rendimiento, costes y eficiencia en entornos cloud. Participación en proyectos de analítica avanzada y ML dentro de la plataforma Azure. 🌟 Qué ofrece el cliente. Contratación directa con multinacional TIC. Proyecto estable y de largo recorrido. Modalidad remota con horario estructurado. Desarrollo profesional en entornos cloud avanzados. Formación continua y participación en proyectos de alto nivel tecnológico.  🤝 Compromiso con la igualdadEn Zemsania, creemos en la igualdad de oportunidades y en la diversidad como valores fundamentales para el éxito de nuestra organización. Por ello, garantizamos un proceso de selección basado en el mérito y sin discriminación por motivos de género, edad, discapacidad, orientación sexual, raza, religión o cualquier otra condición personal o social.",https://www.tecnoempleo.com/ingeniero-datos-azure-digital-talent-agency/data-ingestion/rf-cb3d16bc021713efa54d,Tecnoempleo,2026-01-20
Analista de Datos Microstrategy,"Descripción de la oferta de empleo  En Serem buscamos un perfil Analista de Datos con experiencia en Microstrategy para importante cliente ubicado en Barcelona.  Se requiere experiencia en:  MicroStrategy (Filtros, mapeo atributos y métricas), SQL (Estructura de tablas, queries) Tareas: Mantenimiento correctivo (Soporte N2 y N3): Análisis y resolución de incidencias, formación de usuarios, reportes de estado, administración básica (accesos, etc.) Inglés Alto.  Disponibilidad para trabajar modelo híbrido en Barcelona.",https://www.tecnoempleo.com/analista-datos-microstrategy-serem/sql-data/rf-4d731e0012c61353eb4c,Tecnoempleo,2026-01-20
Ingeniero/a de Datos,"Descripción de la oferta de empleo  🚀 ¡Estamos ampliando nuestro equipo de Data Engineering! 🚀 Buscamos profesionales apasionados por los datos, con experiencia en procesos ETL / DEI, y con la capacidad de diseñar e implementar soluciones de integración y transformación de alto impacto.  🔍 📈 Perfiles que estamos incorporando: 🔸 10 Data Engineers Senior — (+8 años de experiencia) 🔸 4 Data Engineers Semi Senior — (3 a 8 años de experiencia) 🔸 2 Data Engineers Junior — (hasta 3 años de experiencia)  Si te apasiona la ingeniería de datos y quieres sumarte a proyectos desafiantes con tecnología de punta, ¡queremos conocerte! 💡  🧠 Aptitudes clave que valoramos: Capacidad de análisis y diseño de soluciones de datos. Experiencia en desarrollo de procesos ETL / DEI (Informatica, DBT, SQL, Python). Planificación, estimación y gestión técnica de proyectos (Jira, Confluence). Nivel de inglés B1 o superior  ⚙️ 🧩 Tecnologías y herramientas que valoramos: 🔹 ETL / DEI: Informatica | DBT | Talend | Pentaho | SSIS | Apache NiFi | Airbyte 🔹 Data Warehousing & Storage: Snowflake | BigQuery | Redshift | Synapse | PostgreSQL | Oracle | S3 🔹 Lenguajes: SQL | Python | (Opcional: Scala / Java) 🔹 Big Data & Streaming: Apache Spark | Databricks | Kafka | Hive | Hadoop 🔹 Orquestación: Airflow | Prefect | Dagster 🔹 Cloud & DevOps: AWS (Glue, Lambda, S3, Redshift) | Azure (Data Factory, Synapse) | GCP (BigQuery, Dataflow) | Docker | Kubernetes 🔹 Colaboración y gestión: Jira | Confluence | Git / GitHub / GitLab  ⚙️ 🧩 Tecnologías principales que utilizamos: Informatica, DBT, SQL, Python, Apache Spark, Databricks, Snowflake, Google BigQuery, Amazon Redshift, Airflow, Jira, Confluence, Git, Docker, Kubernetes  🌟 ¿Qué buscamos en ti? Pasión por los datos y la automatización 🔄 Capacidad de análisis y comunicación 👂💬 Enfoque en la calidad, la eficiencia y la mejora continua 🧩 Deseo de trabajar en proyectos innovadores de alto impacto 💥  💬 ¿Qué te ofrecemos? Participar en proyectos innovadores de ingeniería y gestión de datos. Entornos colaborativos con metodologías ágiles. Oportunidades de aprendizaje, desarrollo profesional y crecimiento continuo. Modalidad: 100% Remoto   💼 #OportunidadLaboral | #DataEngineer | #ETL | #Informatica | #DBT | #BigData | #DataIntegration | #DEI | #SQL | #Python | #Jira | #Confluence | #TrabajoEnData | #TransformacionDigital | #EmpleoTech",https://www.tecnoempleo.com/ingeniero-datos-panel-sistemas-informaticos/etl-dbt/rf-308614d702ab33c53846,Tecnoempleo,2026-01-20
Arquitecto de Datos,"Descripción de la oferta de empleo  📢 ¡Estamos contratando Arquitecto de Datos! 📍 Modalidad: Remoto | Perfil Senior (7+ años)  ✅ ¿Qué buscamos? 🔹 Experiencia en Cloud Platforms (Azure, AWS o Google Cloud) 🔹 Conocimiento en herramientas de gobierno y catálogo (Purview, Collibra, Alation, Informatica, Amundsen, DataHub, Atlan) 🔹 Manejo de Data Warehouses modernos: Snowflake, Databricks, BigQuery 🔹 Bases de datos SQL (PostgreSQL, SQL Server) y NoSQL (MongoDB, CosmosDB) 🔹 ETL/ELT: Talend, Matillion, dbt (muy valorable) 🔹 Lenguajes: SQL avanzado (obligatorio) y Python (deseable) 🔹 Visualización: Power BI, Tableau o Looker 🔹 Estrategia de Gobierno del Dato (DAMA-DMBOK) 🔹 Modelado avanzado: Estrella, Copo de Nieve, Data Vault 2.0 🔹 Conocimiento en Data Mesh, Data Fabric, Lakehouse 🔹 Normativas: GDPR/RGPD y seguridad por diseño  🌟 Skills clave: ✔ Gestión multi-proyecto ✔ Evangelización y comunicación para cultura data-driven ✔ Visión estratégica y arquitecturas modernas ¿Te interesa? ¡Únete a nuestro equipo!  #ArquitecturaDeDatos #DataGovernance #Cloud #Azure #AWS #GoogleCloud #Snowflake #Databricks #BigQuery #SQL #Python #ETL #dbt #PowerBI #Tableau #DataMesh #DataFabric #Lakehouse #RemoteJobs #TechJobs #Hiring",https://www.tecnoempleo.com/arquitecto-datos-panel-sistemas-informaticos/azure-synapse-data-factory/rf-65fd1debb2f96326ab48,Tecnoempleo,2026-01-20
Solution Architect,"Descripción de la oferta de empleo  Solution Architect Location: Stockholm, Sweden Duration: 6-12 months Hybrid 2-3 days/week at client location  • Designs detailed technical solutions to achieve project goals for the Data Product Pilot • Ensures alignment of data product framework, overall business strategy and technology tech/standards and translate to implementation instructions for the team • Collaborate closely with development team to oversee solution implementation. • Secure alignment with Data Enablement team and Framework guidelines • Work with Data Product owner and Lead Data Architect for Data Product Framework to contribute to design and build of re-usable code artifacts • Evaluate project constraints to identify alternatives, mitigate risks, and potentially re-engineer processes. • Act as a liaison between technical and non-technical stakeholders",https://www.tecnoempleo.com/solution-architect-axiom-software-solutions/data-architect/rf-56b01ae7c29ae3a8644e,Tecnoempleo,2026-01-20
Leader Plataforma Gobierno IT,"Descripción de la oferta de empleo  En Krell Consulting, nos encontramos en la búsqueda de un Technical leader Plataforma Gobierno Informática, para trabajar en nuestro equipo en Madrid, en modalidad híbrida.   PERFIL: Technical leader Plataforma Gobierno Informática.  SECTOR: Banca  HORARIO: Lunes a jueves de 8.30 a 18h, Viernes de 8 a 15h.  LOCALIZACIÓN: Madrid   MODALIDAD DE TRABAJO: híbrido, principalmente en Madrid ya que probablemente se requiera asistencia a oficina de cliente.  FUNCIONES:  - Tareas de administración y configuración de la plataforma de Informática (AXON, EDC, IDQ).  - Gestión de proyectos básicos para realizar pruebas de concepto sobre la plataforma.  - Gestión de demanda de cambios de configuración sobre la plataforma.  REQUISITOS:  - Perfil técnico experto en plataforma de gobierno de Informática.  - Debe tener conocimiento de las herramientas de la suite onpremise de Informática (AXON, Enterprise Data Catalog e Informatica Data Quality).  Si estás interesad@ y cumples con los requisitos, no dudes en aplicar a la posición.  ¡Te esperamos! 🎉",https://www.tecnoempleo.com/leader-plataforma-gobierno-it-krell-consulting-tra/axon-enterprise-data-ca/rf-3f5219f582708324ac46,Tecnoempleo,2026-01-20
Programa Step Up! Beca Datos,"Descripción de la oferta de empleo  iHola! Somos Aegon y creemos que después de conocer nuestro Programa Step Up! tendrás un flechazo.  Probablemente estarás buscando tu primera experiencia laboral y una aseguradora no es que sea lo más apetecible, we know... Pero las apariencias engañan: digamos que la semana pasada se nos estropeó el fax y la máquina de escribir del siglo pasado , así que nos hemos puesto a actualizar cosas y hemos tirado la casa por la ventana. Dos ejemplos rápidos: hemos renovado totalmente nuestras oficinas para adaptadas a un modelo de trabajo híbrido (eso de trabajar dos días por semana desde la ofi para compartir tiempo con tu equipo y el resto de los días desde donde tú quieras ). Y también, como hemos evolucionado nuestra cultura colaborativa, la Lista Forbes nos ha reconocido como una de las 100 Mejores Empresas para Trabajar en España . Si has llegado hasta aquí probablemente te interesemos un poquito, iasí que nosotros también estamos interesados en ti!  Formarás parte de la comunidad de becarios del Programa ""Step Up!"". Durante tu incorporación, te familiarizarás con Aegon y con las diferentes áreas de la compañía, se te asignará un Buddy (empleado actual de la empresa que te ayuda cuando eres nuevo) y, por supuesto, tendrás la oportunidad de conocer a tu equipo y al CEO. ¿Aún no hay match? Sigue leyendo para conocer si quieres acercarte al equipo Aegonita un poco más:  - Valoramos que quieras formarte y nos ayudes en nuestro día a día, por eso nuestra beca es remunerada - Compartimos unos valores muy claros: aquí los directores también se remangan y te traen el café si es necesario. Todos somos iguales - Serás parte activa de proyectos reales y tu opinión se tendrá en cuenta igual que la de los demás. Además, tendrás la oportunidad de aprender de la mano de profesionales del sector. Tenemos preparado un plan formativo que te ayudará en tus primeros pasos - Apostamos por la flexibilidad a través de nuestro modelo de trabajo híbrido: contamos con la posibilidad de teletrabajar al menos tres días por semana y también de compartir tiempo en unas oficinas adaptadas a la metodología ágil. - Si ya te aburren las plataformas de streaming no te preocupes, hemos creado nuestra plataforma formativa con el objetivo de ayudarte en tu plan de desarrollo - No tenemos dress code, ven como tú seas a nuestras oficinas",https://www.tecnoempleo.com/programa-step-up-beca-datos-aegon-nv/data/rf-c72718c6d28c939f1442,Tecnoempleo,2026-01-20
BI Consultant/Engineer,"Descripción de la oferta de empleo  Join Plexus Tech. We are looking for a BI Consultant/Engineer.  Requirements: - Senior engineering degree - Degree in engineering - University diploma in computer science - Technical engineering in computer science - Bachelor´s degree in physical sciences  With our hybrid model, Flexology, you can work from wherever your talent flows best: from any of the 24 work centers we have in Spain, from your home, or combining both modalities. Plexus Tech´s work ecosystem allows for a collaborative environment to be maintained in the company. - - Work with leading professionals. - Access to ongoing training. - Professional development. - Flexible remuneration in health insurance, restaurant vouchers, childcare, transportation.",https://www.tecnoempleo.com/bi-consultant-engineer-plexus/bi-data/rf-a1e71b2cc245b3135345,Tecnoempleo,2026-01-20
Arquitecto/a Técnico,"Descripción de la oferta de empleo  Buscamos un perfil con conocimientos funcionales del sector bancario y a nivel de arquitectura empresarial en el ámbito de canales digitales, tanto no asistidos como presenciales (web, app móvil, Contact Center y ATMs) . -Conocimiento/Experiencia en definición de arquitecturas basadas en eventos (Kafka, Confluent), microservicios/APIs (Srpingboot, APIConnect, Apigee), microfrontends (Angular, React). -Conocimiento/Experiencia en arquitecturas Big Data (Databriks, Spark, Cloudera, ...) -Conocimiento/Experiencia en Procesos/BPM y Gestión Documental(Appian, Filenet, Content OnDemand) -Conocimiento a nivel de arqutiectura de Azure Cloud. -Conceptos afianzados relacionados con resiliencia, alta disponiblidad, seguridad y comunicaciones en el ámbito de soluciones de SW. -Experiencia en metodologías Lean Kanban, Scrum y ceremonias agile. -Skills de comunicación y negociación avanzados -Ingles nivel fluido.",https://www.tecnoempleo.com/arquitecto-tecnico-remoto/kafka-microservicios-microfrontends-big-data/rf-c5871f8d420113dea446,Tecnoempleo,2026-01-20
IT Business developer,"Descripción de la oferta de empleo  ¿Te sientes como pez en el agua vendiendo tecnología? ¿Tu palabra favorita en inglés es networking? Estamos ampliando nuestro equipo de Business Developers en el sector IT para establecer relaciones con nuevos clientes de los sectores Retail, Seguros, Media y Telco, y esta posición es para ti. Nos gusta ir al grano, te vamos a contar lo que no está en la red. Si quieres saber más sobre nosotros, accede a la web de GMV.   ¿A QUÉ RETO TE VAS A ENFRENTAR? GMV tiene en sus espaldas más de 35 años de excelente trato con clientes dentro y fuera de España, entregando productos y servicios con la máxima calidad. Desarrollamos soluciones de Ciberseguridad, Big Data, Inteligencia Artificial o infraestructuras IT, y queremos contar contigo para llegar más lejos. En nuestro equipo participarás en las labores de desarrollo comercial, abriendo nuevas cuentas con clientes de los sectores Telco, Media, Seguros y Retail (entre otros), además de fidelizar nuestros clientes actuales.   ¿QUÉ NECESITAMOS EN NUESTRO EQUIPO? Para este puesto buscamos expertos en desarrollo de negocio IT, con experiencia previa ofreciendo soluciones y servicios de Ciberseguridad, Big Data, Inteligencia Artificial o infraestructuras IT. Para ayudarnos a seguir creciendo, nos gustaría que trajeras una cartera de cuentas de potenciales clientes.Además será valorable aportar un background técnico, con conocimientos sobre ciberseguridad y tecnología en general. También será valorable tener inglés B2 o superior.    ¿QUÉ TE OFRECEMOS? 💻 Modelo de trabajo híbrido y 8 semanas al año de teletrabajo fuera de tu área geográfica habitual🕑 Horario flexible de entrada y salida, y jornada intensiva viernes y verano. 🚀 Desarrollo de plan de carrera personalizado, formación y ayuda para el aprendizaje de idiomas.🌍 Movilidad nacional e internacional. ¿Vienes de otro país? Te ofrecemos un relocation package. 💰 Retribución competitiva con revisiones continuas, retribución flexible y descuento en marcas. 💪Programa Wellbeing: seguro médico, dental y de accidentes; fruta y café gratis, formación en salud física, mental y económica, y ¡mucho más!⚠️ En nuestros procesos de selección siempre tendrás contacto telefónico y personal, presencial u online, con nuestro equipo de talent acquisition. Además, jamás se solicitarán transferencias ni tarjetas bancarias.  Si contactan contigo siguiendo otro proceso, escribe a nuestro equipo a la dirección de correo privacy@gmv.com❤️Promovemos la igualdad de oportunidades en la contratación comprometidos con la inclusión y la diversidad        ¿A QUE ESPERAS? ÚNETE",https://www.tecnoempleo.com/it-business-developer-hibrido/ciberseguridad-big-data-inteligencia-artific/rf-bef316c2424073210d4b,Tecnoempleo,2026-01-20
Data Specialist,"Descripción de la oferta de empleo  ¿Te apasiona transformar datos brutos en decisiones estratégicas? Buscamos un Data Specialist para convertirse en el motor analítico de una compañía en plena expansión.  Este no es un puesto de análisis convencional; serás una pieza clave en un proyecto estratégico de migración de ERP y en la creación de una cultura de Business Intelligence desde cero. Si buscas un entorno donde tu capacidad proactiva y tu agilidad mental tengan un impacto directo en el negocio, y quieres liderar la digitalización de procesos operativos, este proyecto en Coslada es para ti.  nuestro cliente  Nuestro cliente es una compañía líder en innovación y tecnología aplicada al sector alimentario. Con una sólida trayectoria en el mercado, la empresa se encuentra en un proceso de modernización tecnológica y optimización de procesos. Se distinguen por su enfoque en la mejora continua y por ofrecer un entorno de trabajo dinámico donde se valora la iniciativa personal y el pensamiento analítico.  tus funciones  Business Intelligence: Diseño, desarrollo y mantenimiento de cuadros de mando (dashboards) e informes críticos para la dirección.  Análisis Estratégico: Interpretación de grandes volúmenes de datos para identificar tendencias, ineficiencias y oportunidades de negocio.  Transformación Digital: Colaboración directa en el proyecto de migración, implantación y optimización del nuevo sistema ERP de la compañía.  Soporte Técnico Especializado: Garantizar el correcto funcionamiento de las herramientas de software y hardware necesarias para la gestión de datos.  requisitos del puesto - Formación: FP Grado Superior - Conocimientos: erp - Experiencia: 2 años  Formación: FP de Grado Superior en áreas informáticas, análisis de datos o similares.  Experiencia: Mínimo 2 años desempeñando funciones de Analista de Datos o BI.  Habilidades Técnicas: * Dominio experto en herramientas de Business Intelligence (Power BI, Tableau o similares).  Experiencia demostrable en la creación de dashboards operativos y ejecutivos.  Se valorará muy positivamente la experiencia previa en implantaciones o gestión de sistemas ERP.  Competencias Personales: Buscamos a una persona ""espabilada"", con gran agilidad mental, autonomía para resolver problemas y excelentes habilidades de comunicación para trabajar en equipo.  tus beneficios  Equilibrio vida-trabajo: * Horario de invierno: Lunes a jueves (08:00h - 17:00h) y viernes intensivo (08:00h - 15:00h).  Jornada Intensiva de Verano: 3 meses al año con horario de 08:00h a 15:00h.  Ubicación: Oficinas centrales en Coslada (Madrid), con excelentes comunicaciones.  Desarrollo Profesional: Incorporación a una empresa con proyectos innovadores y un plan de formación continua.  ¿por qué con randstad digital?  En Randstad Digital estamos enfocados en ayudarte a encontrar el puesto de trabajo que mejor se adapte a ti y a tus expectativas.  Sabemos que los perfiles profesionales IT son unos de los más demandados en el mercado laboral actual. Randstad Digital somos una división encargada de la selección profesional y especializada de perfiles IT tanto para su contratación directa como para su contratación temporal.  Usamos nuestra propia metodología de análisis y selección que nos permite garantizarte un puesto de trabajo 100% ajustado a tu perfil profesional.  Además estamos siempre cerca de ti, realizamos un seguimiento personalizado de tu incorporación para facilitarte la adaptación a tu nuevo puesto de trabajo. Y hacemos uso de nuestra tecnología para brindarte una experiencia excelente en tu búsqueda de empleo, proceso de selección y como trabajador.  ¿A qué estás esperando?",https://www.tecnoempleo.com/data-specialist-randstad-es/power-bi-tableau/rf-87bb1468a2f233b3d847,Tecnoempleo,2026-01-20
Ingeniero Junior Big Data,"Descripción de la oferta de empleo  Accenture, reconocida como Great Place To Work®, una compañía líder mundial en servicios profesionales que ayuda a las principales empresas, administraciones públicas y otras organizaciones del mundo a desarrollar su core digital, optimizar sus operaciones, acelerar el crecimiento de sus ingresos y mejorar los servicios para los ciudadanos, creando valor tangible a velocidad y escala. Únete a un equipo de más de 801.000 profesionales que forman parte de una compañía Great Place To Work® y ayúdanos a analizar cómo funciona el negocio de nuestros clientes hoy y asesorarles sobre cómo podrían mejorar mañana.  Buscamos para el área de Technology un perfil de Ingeniero Big Data Junior que trabajará para interesantes proyectos del sector tecnológico.  El puesto se desempeña en Gijón, Madrid o Coruña en un modelo de trabajo híbrido realizando algunos días desde tu casa y otros en la oficina donde podrás crear interesantes sinergias con el resto de tu equipo. Es imprescindible residir en España y tener permiso laboral en España.  ´Te sumas al reto?  Funciones a realizar  - Analizar datos complejos para identificar oportunidades estratégicas en proyectos de transformación digital. - Diseñar soluciones basadas en tecnologías Big Data y Cloud (principalmente AWS) para optimizar procesos de negocio. - Implementar modelos de IA y algoritmos en Python y SQL para mejorar la toma de decisiones. - Colaborar con equipos multidisciplinares para definir estrategias tecnológicas orientadas al cliente.  Responsabilidades - Aplicar conocimientos avanzados en ingeniería de datos, incluyendo lenguajes Big Data y entornos Cloud. - Garantizar la calidad y seguridad de los datos en todas las fases del proyecto. - Mantenerse actualizado en tendencias de IA y tecnologías emergentes para proponer mejoras innovadoras. - Comunicar resultados y recomendaciones estratégicas en español e inglés a stakeholders internos y externos.  - Experiencia de 2 a 3 años en proyectos relacionados con datos, IA y Cloud. - Conocimientos sólidos en Python, SQL, lenguajes Big Data y plataformas Cloud (AWS). - Título en Ingeniería Informática. - Nivel alto de español e inglés.  Beneficios y compensaciones  En Accenture, compañía reconocida como Great Place To Work®, apostamos por un modelo híbrido de trabajo que, gracias a la tecnología y a nuestras instalaciones, nos permite mantener la conexión humana esencial para trabajar con nuestros equipos y clientes. Una conexión que nos permite mantener nuestra cultura de inclusión y diversidad y ser, según Refinitiv, la empresa más diversa del mundo. Además, te ofrecemos otros beneficios como: - Seguro médico, de Vida y accidentes - Servicio médico y programas de bienestar - Programa de retribución flexible y compra de acciones - Programas de flexibilidad (horaria, de días libres, vacaciones...) - Itinerario formativo individualizado - Programas de sostenibilidad y Fundación Accenture - Red de empleados por la diversidad - Otros beneficios: Oficina Bankinter con condiciones especiales y reparto de beneficios  About Accenture Accenture is a leading global professional services company that helps the world´s leading businesses, governments and other organizations build their digital core, optimize their operations, accelerate revenue growth and enhance citizen services-creating tangible value at speed and scale. We are a talent- and innovation-led company with approximately 791,000 people serving clients in more than 120 countries. Technology is at the core of change today, and we are one of the world´s leaders in helping drive that change, with strong ecosystem relationships. We combine our strength in technology and leadership in cloud, data and AI with unmatched industry experience, functional expertise and global delivery capability. Our broad range of services, solutions and assets across Strategy & Consulting, Technology, Operations, Industry X and Song, together with our culture of shared success and commitment to creating 360° value, enable us to help our clients reinvent and build trusted, lasting relationships. We measure our success by the 360° value we create for our clients, each other, our shareholders, partners and communities.",https://www.tecnoempleo.com/ingeniero-junior-big-data-accenture/python-sql/rf-7540147962c1f3ee7342,Tecnoempleo,2026-01-20
Senior Data Engineer / Tech Lead_Python,"Descripción de la oferta de empleo  ¿Cómo vas a afrontar tu desarrollo profesional? Acompañado o en solitario, con vistas al futuro o sólo en el presente, con entusiasmo o sin ilusión. En Arelance sabemos que las personas son el activo más importante dentro de una empresa, por ello invertimos tiempo y dedicación para encontrar los mejores profesionales de hoy y de mañana. No empleamos menos tiempo en escoger en nuestros clientes los mejores proyectos con proyección y en donde aportar realmente valor. Formarás parte de un entorno cercano, joven y dinámico. Deberás estar preparado para poder adaptarte a los continuos cambios que supone trabajar en una compañía cuya constante es la Innovación, orientación al logro y el crecimiento profesional.  Seleccionamos un Senior Data Engineer con experiencia en liderazgo técnico y análisis de datos para incorporación en un equipo dinámico en un entorno de datos avanzado para Sector Bancario, siendo responsable tanto del desarrollo de software y procesamiento de datos como de la gestión técnica y operativa.  REQUISITOS:  -Experiencia previa liderando equipos de desarrollo técnico. -Sólidos conocimientos de desarrollo en Python. -Experiencia con SQL. -Experiencia en plataformas Cloudera (Hadoop, Hive, Impala,...). -Control de versiones Git. -Familiaridad con herramientas de orquestación como Control-M. -Experiencia en herramienta de gestión de proyectos con Jira. -Mentalidad analítica, orientación al detalle y capacidad de comunicación. -Deseable experiencia con herramientas de transformación de datos (DBT). -Deseable conocimiento en PySpark.  ¿QUÉ OFRECEMOS?  -Incorporación a un proyecto en continuo desarrollo. -Condiciones salariales a negociar en función de la experiencia aportada. -Modalidad: remoto. -Integración en un proyecto colaborativo en expansión.  Si estás interesado/a en una gran oportunidad como ésta, inscríbete! Queremos conocerte!",https://www.tecnoempleo.com/senior-data-engineer-tech-lead-python-arelance/pyspark-sql/rf-ed0a1e7482adc31ef342,Tecnoempleo,2026-01-20
Data Analyst,"Descripción de la oferta de empleo  Para proyecto estable se requiere un perfil DATA ANALYST.   Responsabilidades:  Recopilar, procesar y analizar grandes conjuntos de datos. Desarrollar y mantener bases de datos y sistemas de datos. Identificar, analizar e interpretar tendencias o patrones en conjuntos de datos complejos. Generar informes y visualizaciones de datos para comunicar hallazgos a las partes interesadas. Colaborar con equipos de TI y de negocio para definir y priorizar requisitos de datos. Asegurar la calidad y precisión de los datos.   Requisitos:  Título en Estadística, Matemáticas, Informática o un campo relacionado. ETL (Extract Transform Load) Experiencia en análisis de datos y uso de herramientas de análisis (por ejemplo, SQL, Excel, R, Python). Habilidades en visualización de datos (por ejemplo, Tableau, Power BI). Capacidad para trabajar con grandes volúmenes de datos y realizar análisis complejos. Excelentes habilidades de comunicación para presentar datos de manera clara y concisa. Atención al detalle y habilidades analíticas.   Beneficios:  Oportunidades de desarrollo profesional y formación continua. Ambiente de trabajo colaborativo y dinámico. Paquete de compensación competitivo.",https://www.tecnoempleo.com/data-analyst-social-you/sql-python-excel-power-bi-etl-erp-tableau-power-bi/rf-bcdf1ef4f284336b8641,Tecnoempleo,2026-01-20
Data Engineer/Talend & PySpark,"Descripción de la oferta de empleo  🚀 Desde CAS Training buscamos incorporar un/a Data Engineer con experiencia en Talend y PySpark para un proyecto activo que se ha reabierto recientemente. El perfil seleccionado se integrará en un equipo técnico orientado al desarrollo y mantenimiento de pipelines de datos, trabajando en entornos distribuidos y con grandes volúmenes de información.  🏡 Modalidad: 100% Teletrabajo  🎯 Responsabilidades principales: • Desarrollo y mantenimiento de procesos ETL utilizando Talend. • Desarrollo de procesos de transformación de datos con PySpark. • Optimización de flujos de datos en entornos distribuidos. • Colaboración con otros perfiles técnicos (data engineers, arquitectos, analistas). • Soporte en tareas de mantenimiento y evolución de soluciones de datos.  🧩 Requisitos técnicos (Must Have): • Al menos 3 años de experiencia como Data Engineer. • Experiencia demostrable en: o Talend. o PySpark. • Conocimiento de entornos de procesamiento de datos a gran escala. • Capacidad para trabajar de forma autónoma en entornos remotos.  🎁 Ofrecemos: • Contrato indefinido con CAS Training • Formar parte de un equipo europeo de alto nivel técnico en un entorno innovador • Paquete retributivo atractivo y flexible, negociado según tu experiencia • Acceso gratuito a nuestro Catálogo Anual de Formación con fabricantes top:Microsoft, Linux, Oracle, ITIL, ¡y muchos más!",https://www.tecnoempleo.com/data-engineer-talend-pyspark-cas-training/etl/rf-9538175562d2133cf643,Tecnoempleo,2026-01-20
"Network Technician, Data Center","Descripción de la oferta de empleo  AWS Infrastructure Services owns the design, planning, delivery, and operation of all AWS global infrastructure. In other words, we´re the people who keep the cloud running. We support all AWS data centers and all of the servers, storage, networking, power, and cooling equipment that ensure our customers have continual access to the innovation they rely on. We work on the most challenging problems, with thousands of variables impacting the supply chain - and we´re looking for talented people who want to help.  You´ll join a diverse team of software, hardware, and network engineers, supply chain specialists, security experts, operations managers, and other vital roles. You´ll collaborate with people across AWS to help us deliver the highest standards for safety and security while providing seemingly infinite capacity at the lowest possible cost for our customers. And you´ll experience an inclusive culture that welcomes bold ideas and empowers you to own them to completion.  We are looking to hire a highly motivated, best-in-class Network Technician to join our growing team within Networking. The position responsibilities involve delivering the hardware, configuration and fiber connectivity of interdependent scaling projects across several data center locations. The Network Technician will work closely with both internal customers and external vendors to facilitate smooth project execution in association with Technical Program Managers.  Our ideal candidate is highly autonomous, very detail oriented, possesses strong written and verbal communication skills and has significant experience in supporting large scale, enterprise class networks. They will be highly competent in all aspects of installation and troubleshooting of networking hardware, software and fiber connectivity, all combined with a proven project delivery methodology. This position will work with minimum supervision to drive the stability and sustainability of our next-generation networks and to assist in the development of innovative ways to automate and scale our network as we expand.  Network Technicians are expected to work with established best practices to refine operational procedures, develop new tooling and constantly think proactively and innovatively. The desire and ability to work in an ambiguous, collaborative environment is essential for success.  **Must be fluent or at least advanced level in English  *Please submit CV in English  Key job responsibilities  • Working closely with our Network Engineering & Network Technical Project Manager teams to ensure fast, smooth rollout of established designs and products.  • Managing work and priorities through ticketing system and workflows.  • Collaborating with various stake holders to remove project obstacles.  • Traveling within geographical work area is required, some travel outside traditional work area may be requested.  • Troubleshooting networking, routing and inter connectivity issues, including troubleshooting of network device configuration and low level application interaction.  • Troubleshooting cabling infrastructure connectivity issues, including patch panels and patch cords.  • Specifying Power and Cooling requirements and ensuring Hardware Racking/Stacking completed for new equipment.  • Completing customer requests via Remedy trouble ticketing system and project management workflows.  • Participating in the migration, basic configuration and rollout of new or upgraded hardware.  A day in the life  You will play a pivotal part in scaling the network of several data center locations and be responsible for day to day assistance with capacity management. Working closely with both internal customers and external vendors, you will facilitate smooth project execution as directed by Technical Program Managers.  You will be required to travel, up to 20% travel outside traditional work area may be required possibly including international travel.",https://www.tecnoempleo.com/network-technician-data-center-amazon/aws/rf-eb961a37f2fd8315c045,Tecnoempleo,2026-01-20
Data & AI Engineer Intern,"Descripción de la oferta de empleo  About AstraZeneca  AstraZeneca is an innovation-driven global biopharmaceutical company focused on the discovery, development and commercialization of prescription medicines, primarily for the treatment of cardiovascular, renal and metabolic, respiratory and immunological, oncological and rare diseases.  Our Barcelona hub has been created to achieve the next wave of breakthroughs that help us do what´s never been done before, as we expand our global footprint. Harnessing data and using the best technology solutions available allow us to positively impact science.  In line with our firm commitment to training and developing exceptional talent, this person will join one of the platforms within the Data, Analytics & AI department (R&D IT org) to learn and grow through active collaboration with the team. The mission of this platform is to accelerate scientific innovation by providing streamlined access to integrated data through advanced virtualization, and secure, compliant data management solutions leveraging state-of-the-art AI technology.  Conditions:  - Duration:6-9 months  - Hours per day: Full time  - Location: Barcelona  - Focus area: Data & AI Engineering  Training through practical experience:  This internship is designed to provide a supportive learning environment, allowing the intern to gain practical experience in data & AI Engineering tasks. The focus will be on learning and adapting to the role, with active involvement in supporting various engineering and operational activities related to data & AI initiatives.  Tasks will include but are not limited to:  - Assisting with pipeline automation and CI/CD processes  - Supporting data wrangling and data analysis tasks  - Basic Python coding  - Collaborating on cloud infrastructure deployment projects (AWS)  - Exploring and leveraging agentic and other AI technologies for their federated usage by different domains  - Applying safe, scalable deployment of intelligent AI agents across R&D IT platforms  - Adhering to Agile ceremonies and processes  Requirements:  - Currently enrolled as a master´s student at a Spanish accredited university or educational institution  - STEM (Science, Technology, Engineering, and Mathematics) or related degrees preferred  - Basic understanding of data & AI concepts  - Basic Python knowledge  - Basic software versioning knowledge (git)  - Basic cloud infrastructure knowledge (AWS)  - Excellent communication and teamwork skills  - Ability to adapt to a fast-paced environment  - Interest or knowledge in the pharma industry would be a plus  #EarlyTalent  AstraZeneca is a company that promotes equal opportunities. AstraZeneca will consider all eligible persons, without discrimination based on disability, sex or sexual orientation, pregnancy or maternity/paternity period, race or origin (national or ethnic), age, religion or belief, identity of gender, marital or de facto partnership status and/or any other characteristic protected by law.",https://www.tecnoempleo.com/data-ai-engineer-intern-astrazeneca/python/rf-6f701bb002dec3122d44,Tecnoempleo,2026-01-20
